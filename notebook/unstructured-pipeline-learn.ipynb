{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a1c535c",
   "metadata": {},
   "source": [
    "## **Unstructured Document Retrieval Pipline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "739da2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured[all-docs] in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (0.18.27)\n",
      "Requirement already satisfied: charset-normalizer in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (3.4.4)\n",
      "Requirement already satisfied: filetype in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (1.2.0)\n",
      "Requirement already satisfied: python-magic in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (0.4.27)\n",
      "Requirement already satisfied: lxml in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (6.0.2)\n",
      "Requirement already satisfied: nltk in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (3.9.2)\n",
      "Requirement already satisfied: requests in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (2.32.5)\n",
      "Requirement already satisfied: beautifulsoup4 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (4.14.3)\n",
      "Requirement already satisfied: emoji in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (2.15.0)\n",
      "Requirement already satisfied: dataclasses-json in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (0.6.7)\n",
      "Requirement already satisfied: python-iso639 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (2025.11.16)\n",
      "Requirement already satisfied: langdetect in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (1.0.9)\n",
      "Requirement already satisfied: numpy in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (2.3.5)\n",
      "Requirement already satisfied: rapidfuzz in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (3.14.3)\n",
      "Requirement already satisfied: backoff in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (4.15.0)\n",
      "Requirement already satisfied: unstructured-client in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (0.42.8)\n",
      "Requirement already satisfied: wrapt in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (2.0.1)\n",
      "Requirement already satisfied: tqdm in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (4.67.1)\n",
      "Requirement already satisfied: psutil in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (7.2.1)\n",
      "Requirement already satisfied: python-oxmsg in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (0.0.2)\n",
      "Requirement already satisfied: html5lib in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (1.1)\n",
      "Requirement already satisfied: markdown in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (3.10.1)\n",
      "Requirement already satisfied: openpyxl in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (3.1.5)\n",
      "Requirement already satisfied: python-pptx>=1.0.1 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (1.0.2)\n",
      "Requirement already satisfied: python-docx>=1.1.2 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (1.2.0)\n",
      "Requirement already satisfied: pypdf in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (6.6.0)\n",
      "Requirement already satisfied: onnx>=1.17.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (1.20.1)\n",
      "Requirement already satisfied: google-cloud-vision in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (3.12.0)\n",
      "Requirement already satisfied: pi_heif in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (1.2.0)\n",
      "Requirement already satisfied: pdf2image in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (1.17.0)\n",
      "Requirement already satisfied: effdet in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (0.4.1)\n",
      "Requirement already satisfied: networkx in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (3.6.1)\n",
      "Requirement already satisfied: pdfminer.six in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (20260107)\n",
      "Requirement already satisfied: xlrd in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (2.0.2)\n",
      "Requirement already satisfied: onnxruntime>=1.19.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (1.23.2)\n",
      "Requirement already satisfied: unstructured.pytesseract>=0.3.12 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (0.3.15)\n",
      "Requirement already satisfied: pandas in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (3.0.0)\n",
      "Requirement already satisfied: pikepdf in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (10.2.0)\n",
      "Requirement already satisfied: unstructured-inference>=1.1.1 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (1.1.7)\n",
      "Requirement already satisfied: msoffcrypto-tool in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (6.0.0)\n",
      "Requirement already satisfied: pypandoc in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured[all-docs]) (1.16.2)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from onnx>=1.17.0->unstructured[all-docs]) (6.33.4)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from onnx>=1.17.0->unstructured[all-docs]) (0.5.4)\n",
      "Requirement already satisfied: coloredlogs in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from onnxruntime>=1.19.0->unstructured[all-docs]) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from onnxruntime>=1.19.0->unstructured[all-docs]) (25.12.19)\n",
      "Requirement already satisfied: packaging in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from onnxruntime>=1.19.0->unstructured[all-docs]) (25.0)\n",
      "Requirement already satisfied: sympy in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from onnxruntime>=1.19.0->unstructured[all-docs]) (1.13.1)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from python-pptx>=1.0.1->unstructured[all-docs]) (12.1.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from python-pptx>=1.0.1->unstructured[all-docs]) (3.2.9)\n",
      "Requirement already satisfied: python-multipart in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured-inference>=1.1.1->unstructured[all-docs]) (0.0.21)\n",
      "Requirement already satisfied: huggingface-hub in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured-inference>=1.1.1->unstructured[all-docs]) (0.36.0)\n",
      "Requirement already satisfied: opencv-python>=4.13.0.90 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured-inference>=1.1.1->unstructured[all-docs]) (4.13.0.90)\n",
      "Requirement already satisfied: matplotlib in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured-inference>=1.1.1->unstructured[all-docs]) (3.10.8)\n",
      "Requirement already satisfied: torch in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured-inference>=1.1.1->unstructured[all-docs]) (2.5.1+cu121)\n",
      "Requirement already satisfied: timm in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured-inference>=1.1.1->unstructured[all-docs]) (1.0.24)\n",
      "Requirement already satisfied: transformers>=4.25.1 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured-inference>=1.1.1->unstructured[all-docs]) (4.57.6)\n",
      "Requirement already satisfied: accelerate in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured-inference>=1.1.1->unstructured[all-docs]) (1.12.0)\n",
      "Requirement already satisfied: scipy in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured-inference>=1.1.1->unstructured[all-docs]) (1.17.0)\n",
      "Requirement already satisfied: pypdfium2 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured-inference>=1.1.1->unstructured[all-docs]) (5.3.0)\n",
      "Requirement already satisfied: filelock in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from transformers>=4.25.1->unstructured-inference>=1.1.1->unstructured[all-docs]) (3.20.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from transformers>=4.25.1->unstructured-inference>=1.1.1->unstructured[all-docs]) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from transformers>=4.25.1->unstructured-inference>=1.1.1->unstructured[all-docs]) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from transformers>=4.25.1->unstructured-inference>=1.1.1->unstructured[all-docs]) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from transformers>=4.25.1->unstructured-inference>=1.1.1->unstructured[all-docs]) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from huggingface-hub->unstructured-inference>=1.1.1->unstructured[all-docs]) (2025.12.0)\n",
      "Requirement already satisfied: colorama in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from tqdm->unstructured[all-docs]) (0.4.6)\n",
      "Requirement already satisfied: jinja2 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from torch->unstructured-inference>=1.1.1->unstructured[all-docs]) (3.1.6)\n",
      "Requirement already satisfied: setuptools in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from torch->unstructured-inference>=1.1.1->unstructured[all-docs]) (70.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from sympy->onnxruntime>=1.19.0->unstructured[all-docs]) (1.3.0)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from beautifulsoup4->unstructured[all-docs]) (2.8.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.19.0->unstructured[all-docs]) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.19.0->unstructured[all-docs]) (3.5.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from dataclasses-json->unstructured[all-docs]) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from dataclasses-json->unstructured[all-docs]) (0.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured[all-docs]) (1.1.0)\n",
      "Requirement already satisfied: torchvision in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from effdet->unstructured[all-docs]) (0.20.1+cu121)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from effdet->unstructured[all-docs]) (2.0.11)\n",
      "Requirement already satisfied: omegaconf>=2.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from effdet->unstructured[all-docs]) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from omegaconf>=2.0->effdet->unstructured[all-docs]) (4.9.3)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (2.29.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from google-cloud-vision->unstructured[all-docs]) (2.47.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from google-cloud-vision->unstructured[all-docs]) (1.76.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from google-cloud-vision->unstructured[all-docs]) (1.27.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (1.72.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[all-docs]) (1.76.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (4.9.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from requests->unstructured[all-docs]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from requests->unstructured[all-docs]) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from requests->unstructured[all-docs]) (2026.1.4)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[all-docs]) (0.6.2)\n",
      "Requirement already satisfied: six>=1.9 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from html5lib->unstructured[all-docs]) (1.17.0)\n",
      "Requirement already satisfied: webencodings in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from html5lib->unstructured[all-docs]) (0.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from jinja2->torch->unstructured-inference>=1.1.1->unstructured[all-docs]) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from matplotlib->unstructured-inference>=1.1.1->unstructured[all-docs]) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from matplotlib->unstructured-inference>=1.1.1->unstructured[all-docs]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from matplotlib->unstructured-inference>=1.1.1->unstructured[all-docs]) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from matplotlib->unstructured-inference>=1.1.1->unstructured[all-docs]) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=3 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from matplotlib->unstructured-inference>=1.1.1->unstructured[all-docs]) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from matplotlib->unstructured-inference>=1.1.1->unstructured[all-docs]) (2.9.0.post0)\n",
      "Requirement already satisfied: cryptography>=39.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from msoffcrypto-tool->unstructured[all-docs]) (46.0.3)\n",
      "Requirement already satisfied: olefile>=0.46 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from msoffcrypto-tool->unstructured[all-docs]) (0.47)\n",
      "Requirement already satisfied: cffi>=2.0.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from cryptography>=39.0->msoffcrypto-tool->unstructured[all-docs]) (2.0.0)\n",
      "Requirement already satisfied: pycparser in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from cffi>=2.0.0->cryptography>=39.0->msoffcrypto-tool->unstructured[all-docs]) (3.0)\n",
      "Requirement already satisfied: click in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from nltk->unstructured[all-docs]) (8.3.1)\n",
      "Requirement already satisfied: joblib in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from nltk->unstructured[all-docs]) (1.5.3)\n",
      "Requirement already satisfied: et-xmlfile in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from openpyxl->unstructured[all-docs]) (2.0.0)\n",
      "Requirement already satisfied: tzdata in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from pandas->unstructured[all-docs]) (2025.3)\n",
      "Requirement already satisfied: Deprecated in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from pikepdf->unstructured[all-docs]) (1.3.1)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured-client->unstructured[all-docs]) (25.1.0)\n",
      "Requirement already satisfied: httpcore>=1.0.9 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured-client->unstructured[all-docs]) (1.0.9)\n",
      "Requirement already satisfied: httpx>=0.27.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured-client->unstructured[all-docs]) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.11.2 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured-client->unstructured[all-docs]) (2.12.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from unstructured-client->unstructured[all-docs]) (1.0.0)\n",
      "Requirement already satisfied: h11>=0.16 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from httpcore>=1.0.9->unstructured-client->unstructured[all-docs]) (0.16.0)\n",
      "Requirement already satisfied: anyio in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from httpx>=0.27.0->unstructured-client->unstructured[all-docs]) (4.12.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from pydantic>=2.11.2->unstructured-client->unstructured[all-docs]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from pydantic>=2.11.2->unstructured-client->unstructured[all-docs]) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from pydantic>=2.11.2->unstructured-client->unstructured[all-docs]) (0.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Setup unstructured for all document types\n",
    "\n",
    "%pip install \"unstructured[all-docs]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e28ad4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "854d65fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.chunking.title import chunk_by_title\n",
    "from unstructured.partition.md import partition_md\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.staging.base import dict_to_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "054c73b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: watermark in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: ipython>=6.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from watermark) (9.9.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from watermark) (8.7.1)\n",
      "Requirement already satisfied: setuptools in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from watermark) (70.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from importlib-metadata>=1.4->watermark) (3.23.0)\n",
      "Requirement already satisfied: colorama>=0.4.4 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from ipython>=6.0->watermark) (0.4.6)\n",
      "Requirement already satisfied: decorator>=4.3.2 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from ipython>=6.0->watermark) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from ipython>=6.0->watermark) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from ipython>=6.0->watermark) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from ipython>=6.0->watermark) (0.2.1)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from ipython>=6.0->watermark) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from ipython>=6.0->watermark) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from ipython>=6.0->watermark) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from ipython>=6.0->watermark) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.0->watermark) (0.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from jedi>=0.18.1->ipython>=6.0->watermark) (0.8.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from stack_data>=0.6.0->ipython>=6.0->watermark) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from stack_data>=0.6.0->ipython>=6.0->watermark) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages (from stack_data>=0.6.0->ipython>=6.0->watermark) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "unstructured: 0.18.27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Watermark = Secret invisible signature in AI-generated text\n",
    "\n",
    "%pip install watermark\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad248d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package unstructured.partition in unstructured:\n",
      "\n",
      "NAME\n",
      "    unstructured.partition\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    api\n",
      "    auto\n",
      "    common (package)\n",
      "    csv\n",
      "    doc\n",
      "    docx\n",
      "    email\n",
      "    epub\n",
      "    html (package)\n",
      "    image\n",
      "    json\n",
      "    md\n",
      "    model_init\n",
      "    msg\n",
      "    ndjson\n",
      "    odt\n",
      "    org\n",
      "    pdf\n",
      "    pdf_image (package)\n",
      "    ppt\n",
      "    pptx\n",
      "    rst\n",
      "    rtf\n",
      "    strategies\n",
      "    text\n",
      "    text_type\n",
      "    tsv\n",
      "    utils (package)\n",
      "    xlsx\n",
      "    xml\n",
      "\n",
      "FILE\n",
      "    e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages\\unstructured\\partition\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import unstructured.partition\n",
    "\n",
    "help(unstructured.partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccc3a0f",
   "metadata": {},
   "source": [
    "### Preprocessing the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aabccc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "partition_pdf(\n",
      "    filename: \u001b[33m'Optional[str]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    file: \u001b[33m'Optional[IO[bytes]]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    include_page_breaks: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    strategy: \u001b[33m'str'\u001b[39m = \u001b[33m'auto'\u001b[39m,\n",
      "    infer_table_structure: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    ocr_languages: \u001b[33m'Optional[str]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    languages: \u001b[33m'Optional[list[str]]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    detect_language_per_element: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    metadata_last_modified: \u001b[33m'Optional[str]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    chunking_strategy: \u001b[33m'Optional[str]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    hi_res_model_name: \u001b[33m'Optional[str]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    extract_images_in_pdf: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    extract_image_block_types: \u001b[33m'Optional[list[str]]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    extract_image_block_output_dir: \u001b[33m'Optional[str]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    extract_image_block_to_payload: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    starting_page_number: \u001b[33m'int'\u001b[39m = \u001b[32m1\u001b[39m,\n",
      "    extract_forms: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    form_extraction_skip_tables: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    password: \u001b[33m'Optional[str]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    pdfminer_line_margin: \u001b[33m'Optional[float]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    pdfminer_char_margin: \u001b[33m'Optional[float]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    pdfminer_line_overlap: \u001b[33m'Optional[float]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    pdfminer_word_margin: \u001b[33m'Optional[float]'\u001b[39m = \u001b[32m0.185\u001b[39m,\n",
      "    **kwargs: \u001b[33m'Any'\u001b[39m,\n",
      ") -> \u001b[33m'list[Element]'\u001b[39m\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Parses a pdf document into a list of interpreted elements.\n",
      "    Parameters\n",
      "    ----------\n",
      "    filename\n",
      "        A string defining the target filename path.\n",
      "    file\n",
      "        A file-like object as bytes --> open(filename, \"rb\").\n",
      "    strategy\n",
      "        The strategy to use for partitioning the PDF. Valid strategies are \"hi_res\",\n",
      "        \"ocr_only\", and \"fast\". When using the \"hi_res\" strategy, the function uses\n",
      "        a layout detection model to identify document elements. When using the\n",
      "        \"ocr_only\" strategy, partition_pdf simply extracts the text from the\n",
      "        document using OCR and processes it. If the \"fast\" strategy is used, the text\n",
      "        is extracted directly from the PDF. The default strategy `auto` will determine\n",
      "        when a page can be extracted using `fast` mode, otherwise it will fall back to `hi_res`.\n",
      "    infer_table_structure\n",
      "        Only applicable if `strategy=hi_res`.\n",
      "        If True, any Table elements that are extracted will also have a metadata field\n",
      "        named \"text_as_html\" where the table's text content is rendered into an html string.\n",
      "        I.e., rows and cells are preserved.\n",
      "        Whether True or False, the \"text\" field is always present in any Table element\n",
      "        and is the text content of the table (no structure).\n",
      "    languages\n",
      "        The languages present in the document, for use in partitioning and/or OCR. To use a language\n",
      "        with Tesseract, you'll first need to install the appropriate Tesseract language pack.\n",
      "    metadata_last_modified\n",
      "        The last modified date for the document.\n",
      "    hi_res_model_name\n",
      "        The layout detection model used when partitioning strategy is set to `hi_res`.\n",
      "    extract_images_in_pdf\n",
      "        Only applicable if `strategy=hi_res`.\n",
      "        If True, any detected images will be saved in the path specified by\n",
      "        'extract_image_block_output_dir' or stored as base64 encoded data within metadata fields.\n",
      "        Deprecation Note: This parameter is marked for deprecation. Future versions will use\n",
      "        'extract_image_block_types' for broader extraction capabilities.\n",
      "    extract_image_block_types\n",
      "        Only applicable if `strategy=hi_res`.\n",
      "        Images of the element type(s) specified in this list (e.g., [\"Image\", \"Table\"]) will be\n",
      "        saved in the path specified by 'extract_image_block_output_dir' or stored as base64\n",
      "        encoded data within metadata fields.\n",
      "    extract_image_block_to_payload\n",
      "        Only applicable if `strategy=hi_res`.\n",
      "        If True, images of the element type(s) defined in 'extract_image_block_types' will be\n",
      "        encoded as base64 data and stored in two metadata fields: 'image_base64' and\n",
      "        'image_mime_type'.\n",
      "        This parameter facilitates the inclusion of element data directly within the payload,\n",
      "        especially for web-based applications or APIs.\n",
      "    extract_image_block_output_dir\n",
      "        Only applicable if `strategy=hi_res` and `extract_image_block_to_payload=False`.\n",
      "        The filesystem path for saving images of the element type(s)\n",
      "        specified in 'extract_image_block_types'.\n",
      "    extract_forms\n",
      "        Whether the form extraction logic should be run\n",
      "        (results in adding FormKeysValues elements to output).\n",
      "    form_extraction_skip_tables\n",
      "        Whether the form extraction logic should ignore regions designated as Tables.\n",
      "    pdfminer_line_margin\n",
      "        If two lines are close together they are considered to be part of the same paragraph.\n",
      "        The margin is specified relative to the height of a line.\n",
      "    pdfminer_char_margin\n",
      "        If two characters are closer together than this margin they are considered part of\n",
      "        the same line. The margin is specified relative to the width of the character.\n",
      "    pdfminer_line_overlap\n",
      "        If two characters have more overlap than this they are considered to be on the same line.\n",
      "        The overlap is specified relative to the minimum height of both characters.\n",
      "    pdfminer_word_margin\n",
      "        If two characters on the same line are further apart than this margin then they are\n",
      "        considered to be two separate words, and an intermediate space will be added for\n",
      "        readability. The margin is specified relative to the width of the character.\n",
      "    \n",
      "chunking_strategy\n",
      "        Strategy used for chunking text into larger or smaller elements.\n",
      "        Defaults to `None` with optional arg of 'basic' or 'by_title'.\n",
      "        Additional Parameters:\n",
      "                multipage_sections\n",
      "                        If True, sections can span multiple pages. Defaults to True.\n",
      "                combine_text_under_n_chars\n",
      "                        Combines elements (for example a series of titles) until a section\n",
      "                        reaches a length of n characters. Only applies to 'by_title' strategy.\n",
      "                new_after_n_chars\n",
      "                        Cuts off chunks once they reach a length of n characters; a soft max.\n",
      "                max_characters\n",
      "                        Chunks elements text and text_as_html (if present) into chunks\n",
      "                        of length n characters, a hard max.\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "@apply_metadata(FileType.PDF)\n",
      "@add_chunking_strategy\n",
      "\u001b[38;5;28;01mdef\u001b[39;00m partition_pdf(\n",
      "    filename: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    file: Optional[IO[bytes]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    include_page_breaks: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    strategy: str = PartitionStrategy.AUTO,\n",
      "    infer_table_structure: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    ocr_languages: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# changing to optional for deprecation\u001b[39;00m\n",
      "    languages: Optional[list[str]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    detect_language_per_element: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    metadata_last_modified: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    chunking_strategy: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# used by decorator\u001b[39;00m\n",
      "    hi_res_model_name: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    extract_images_in_pdf: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    extract_image_block_types: Optional[list[str]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    extract_image_block_output_dir: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    extract_image_block_to_payload: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    starting_page_number: int = \u001b[32m1\u001b[39m,\n",
      "    extract_forms: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    form_extraction_skip_tables: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    password: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    pdfminer_line_margin: Optional[float] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    pdfminer_char_margin: Optional[float] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    pdfminer_line_overlap: Optional[float] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    pdfminer_word_margin: Optional[float] = \u001b[32m0.185\u001b[39m,\n",
      "    **kwargs: Any,\n",
      ") -> list[Element]:\n",
      "    \u001b[33m\"\"\"Parses a pdf document into a list of interpreted elements.\u001b[39m\n",
      "\u001b[33m    Parameters\u001b[39m\n",
      "\u001b[33m    ----------\u001b[39m\n",
      "\u001b[33m    filename\u001b[39m\n",
      "\u001b[33m        A string defining the target filename path.\u001b[39m\n",
      "\u001b[33m    file\u001b[39m\n",
      "\u001b[33m        A file-like object as bytes --> open(filename, \"rb\").\u001b[39m\n",
      "\u001b[33m    strategy\u001b[39m\n",
      "\u001b[33m        The strategy to use for partitioning the PDF. Valid strategies are \"hi_res\",\u001b[39m\n",
      "\u001b[33m        \"ocr_only\", and \"fast\". When using the \"hi_res\" strategy, the function uses\u001b[39m\n",
      "\u001b[33m        a layout detection model to identify document elements. When using the\u001b[39m\n",
      "\u001b[33m        \"ocr_only\" strategy, partition_pdf simply extracts the text from the\u001b[39m\n",
      "\u001b[33m        document using OCR and processes it. If the \"fast\" strategy is used, the text\u001b[39m\n",
      "\u001b[33m        is extracted directly from the PDF. The default strategy `auto` will determine\u001b[39m\n",
      "\u001b[33m        when a page can be extracted using `fast` mode, otherwise it will fall back to `hi_res`.\u001b[39m\n",
      "\u001b[33m    infer_table_structure\u001b[39m\n",
      "\u001b[33m        Only applicable if `strategy=hi_res`.\u001b[39m\n",
      "\u001b[33m        If True, any Table elements that are extracted will also have a metadata field\u001b[39m\n",
      "\u001b[33m        named \"text_as_html\" where the table's text content is rendered into an html string.\u001b[39m\n",
      "\u001b[33m        I.e., rows and cells are preserved.\u001b[39m\n",
      "\u001b[33m        Whether True or False, the \"text\" field is always present in any Table element\u001b[39m\n",
      "\u001b[33m        and is the text content of the table (no structure).\u001b[39m\n",
      "\u001b[33m    languages\u001b[39m\n",
      "\u001b[33m        The languages present in the document, for use in partitioning and/or OCR. To use a language\u001b[39m\n",
      "\u001b[33m        with Tesseract, you'll first need to install the appropriate Tesseract language pack.\u001b[39m\n",
      "\u001b[33m    metadata_last_modified\u001b[39m\n",
      "\u001b[33m        The last modified date for the document.\u001b[39m\n",
      "\u001b[33m    hi_res_model_name\u001b[39m\n",
      "\u001b[33m        The layout detection model used when partitioning strategy is set to `hi_res`.\u001b[39m\n",
      "\u001b[33m    extract_images_in_pdf\u001b[39m\n",
      "\u001b[33m        Only applicable if `strategy=hi_res`.\u001b[39m\n",
      "\u001b[33m        If True, any detected images will be saved in the path specified by\u001b[39m\n",
      "\u001b[33m        'extract_image_block_output_dir' or stored as base64 encoded data within metadata fields.\u001b[39m\n",
      "\u001b[33m        Deprecation Note: This parameter is marked for deprecation. Future versions will use\u001b[39m\n",
      "\u001b[33m        'extract_image_block_types' for broader extraction capabilities.\u001b[39m\n",
      "\u001b[33m    extract_image_block_types\u001b[39m\n",
      "\u001b[33m        Only applicable if `strategy=hi_res`.\u001b[39m\n",
      "\u001b[33m        Images of the element type(s) specified in this list (e.g., [\"Image\", \"Table\"]) will be\u001b[39m\n",
      "\u001b[33m        saved in the path specified by 'extract_image_block_output_dir' or stored as base64\u001b[39m\n",
      "\u001b[33m        encoded data within metadata fields.\u001b[39m\n",
      "\u001b[33m    extract_image_block_to_payload\u001b[39m\n",
      "\u001b[33m        Only applicable if `strategy=hi_res`.\u001b[39m\n",
      "\u001b[33m        If True, images of the element type(s) defined in 'extract_image_block_types' will be\u001b[39m\n",
      "\u001b[33m        encoded as base64 data and stored in two metadata fields: 'image_base64' and\u001b[39m\n",
      "\u001b[33m        'image_mime_type'.\u001b[39m\n",
      "\u001b[33m        This parameter facilitates the inclusion of element data directly within the payload,\u001b[39m\n",
      "\u001b[33m        especially for web-based applications or APIs.\u001b[39m\n",
      "\u001b[33m    extract_image_block_output_dir\u001b[39m\n",
      "\u001b[33m        Only applicable if `strategy=hi_res` and `extract_image_block_to_payload=False`.\u001b[39m\n",
      "\u001b[33m        The filesystem path for saving images of the element type(s)\u001b[39m\n",
      "\u001b[33m        specified in 'extract_image_block_types'.\u001b[39m\n",
      "\u001b[33m    extract_forms\u001b[39m\n",
      "\u001b[33m        Whether the form extraction logic should be run\u001b[39m\n",
      "\u001b[33m        (results in adding FormKeysValues elements to output).\u001b[39m\n",
      "\u001b[33m    form_extraction_skip_tables\u001b[39m\n",
      "\u001b[33m        Whether the form extraction logic should ignore regions designated as Tables.\u001b[39m\n",
      "\u001b[33m    pdfminer_line_margin\u001b[39m\n",
      "\u001b[33m        If two lines are close together they are considered to be part of the same paragraph.\u001b[39m\n",
      "\u001b[33m        The margin is specified relative to the height of a line.\u001b[39m\n",
      "\u001b[33m    pdfminer_char_margin\u001b[39m\n",
      "\u001b[33m        If two characters are closer together than this margin they are considered part of\u001b[39m\n",
      "\u001b[33m        the same line. The margin is specified relative to the width of the character.\u001b[39m\n",
      "\u001b[33m    pdfminer_line_overlap\u001b[39m\n",
      "\u001b[33m        If two characters have more overlap than this they are considered to be on the same line.\u001b[39m\n",
      "\u001b[33m        The overlap is specified relative to the minimum height of both characters.\u001b[39m\n",
      "\u001b[33m    pdfminer_word_margin\u001b[39m\n",
      "\u001b[33m        If two characters on the same line are further apart than this margin then they are\u001b[39m\n",
      "\u001b[33m        considered to be two separate words, and an intermediate space will be added for\u001b[39m\n",
      "\u001b[33m        readability. The margin is specified relative to the width of the character.\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "\n",
      "    exactly_one(filename=filename, file=file)\n",
      "\n",
      "    languages = check_language_args(languages \u001b[38;5;28;01mor\u001b[39;00m [], ocr_languages)\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m partition_pdf_or_image(\n",
      "        filename=filename,\n",
      "        file=file,\n",
      "        include_page_breaks=include_page_breaks,\n",
      "        strategy=strategy,\n",
      "        infer_table_structure=infer_table_structure,\n",
      "        languages=languages,\n",
      "        detect_language_per_element=detect_language_per_element,\n",
      "        metadata_last_modified=metadata_last_modified,\n",
      "        hi_res_model_name=hi_res_model_name,\n",
      "        extract_images_in_pdf=extract_images_in_pdf,\n",
      "        extract_image_block_types=extract_image_block_types,\n",
      "        extract_image_block_output_dir=extract_image_block_output_dir,\n",
      "        extract_image_block_to_payload=extract_image_block_to_payload,\n",
      "        starting_page_number=starting_page_number,\n",
      "        extract_forms=extract_forms,\n",
      "        form_extraction_skip_tables=form_extraction_skip_tables,\n",
      "        password=password,\n",
      "        pdfminer_line_margin=pdfminer_line_margin,\n",
      "        pdfminer_char_margin=pdfminer_char_margin,\n",
      "        pdfminer_line_overlap=pdfminer_line_overlap,\n",
      "        pdfminer_word_margin=pdfminer_word_margin,\n",
      "        **kwargs,\n",
      "    )\n",
      "\u001b[31mFile:\u001b[39m      e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages\\unstructured\\partition\\pdf.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "partition_pdf??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24322176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set non-stroke color because expected 3 components but got [0.9]\n",
      "Cannot set non-stroke color because expected 3 components but got [0.9]\n",
      "Cannot set non-stroke color because expected 3 components but got [0.9]\n",
      "Cannot set non-stroke color because expected 3 components but got [0.9]\n",
      "Cannot set non-stroke color because expected 3 components but got [0.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# Specify the path to your PDF file\n",
    "filename = \"../data/pdf/F-62.pdf\"\n",
    "\n",
    "# Extract images, tables, and chunk text\n",
    "pdf_elements = partition_pdf(\n",
    "    filename=filename,\n",
    "    extract_images_in_pdf=False,\n",
    "    #strategy = \"hi_res\",\n",
    "    strategy = \"fast\",\n",
    "    hi_res_model_name=\"yolox\",\n",
    "    infer_table_structure=True,\n",
    "    chunking_strategy=\"by_title\",\n",
    "    max_characters=3000,\n",
    "    #new_after_n_chars=3800,\n",
    "    combine_text_under_n_chars=200,\n",
    "    #extract_image_block_output_dir=path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1f11f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.CompositeElement at 0x2598b8b9ee0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b8ba3c0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b975d90>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b9754c0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b9753d0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b977470>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598ba3adb0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598ba399d0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598ba3a5d0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598ba3b1a0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598ba2d310>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598ba2f290>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598ba2cfe0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598ba2c410>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598ba2ed20>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598ba6f380>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b9a96d0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598ba77560>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598ba77440>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598ba3a450>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b994aa0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b997680>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b994d70>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b996a20>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b994290>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b9b35f0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b9b3770>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b9b0470>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b9b1d60>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b9b0230>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b9b32f0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b9b1f40>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b9b1b80>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b9b1dc0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b9b00e0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b9b0830>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b9b22d0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b9b0140>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b9b3620>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b9b0980>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b9b0bf0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b9b2210>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b9b3b90>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598ba27080>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598ba27140>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598a67cef0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99050bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.CompositeElement at 0x2598b8b9ee0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b8ba3c0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b975d90>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b9754c0>,\n",
       " <unstructured.documents.elements.CompositeElement at 0x2598b9753d0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_elements[:5]  # Display the first 5 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c3cd5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"<class 'unstructured.documents.elements.CompositeElement'>\": 46}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to store counts of each type\n",
    "category_counts = {}\n",
    "\n",
    "for element in pdf_elements:\n",
    "    category = str(type(element))\n",
    "    if category in category_counts:\n",
    "        category_counts[category] += 1\n",
    "    else:\n",
    "        category_counts[category] = 1\n",
    "\n",
    "# Unique_categories will have unique elements\n",
    "unique_categories = set(category_counts.keys())\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "add56741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CompositeElement'}\n"
     ]
    }
   ],
   "source": [
    "element_dict = [el.to_dict() for el in pdf_elements]\n",
    "\n",
    "unique_types = set()\n",
    "\n",
    "for item in element_dict:\n",
    "    unique_types.add(item['type'])\n",
    "\n",
    "print(unique_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adfdc753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set non-stroke color because expected 3 components but got [0.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set non-stroke color because expected 3 components but got [0.9]\n",
      "Cannot set non-stroke color because expected 3 components but got [0.9]\n",
      "Cannot set non-stroke color because expected 3 components but got [0.9]\n",
      "Cannot set non-stroke color because expected 3 components but got [0.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n",
      "{\"<class 'unstructured.documents.elements.CompositeElement'>\": 46, \"<class 'unstructured.documents.elements.Title'>\": 129, \"<class 'unstructured.documents.elements.NarrativeText'>\": 89, \"<class 'unstructured.documents.elements.ListItem'>\": 18, \"<class 'unstructured.documents.elements.Text'>\": 31, \"<class 'unstructured.documents.elements.Header'>\": 6, \"<class 'unstructured.documents.elements.Footer'>\": 3}\n",
      "{'Title', 'Header', 'ListItem', 'NarrativeText', 'Footer', 'UncategorizedText'}\n"
     ]
    }
   ],
   "source": [
    "# Extract images, tables, and chunk text\n",
    "pdf_elements = partition_pdf(\n",
    "    filename=filename,\n",
    "    extract_images_in_pdf=False,\n",
    "    strategy = \"fast\",\n",
    "    hi_res_model_name=\"yolox\",\n",
    "    infer_table_structure=True,\n",
    "    #chunking_strategy=\"by_title\",\n",
    "    max_characters=3000,\n",
    "    #new_after_n_chars=3800,\n",
    "    combine_text_under_n_chars=200,\n",
    "    #extract_image_block_output_dir=path,\n",
    ")\n",
    "\n",
    "for element in pdf_elements:\n",
    "    category = str(type(element))\n",
    "    if category in category_counts:\n",
    "        category_counts[category] += 1\n",
    "    else:\n",
    "        category_counts[category] = 1\n",
    "\n",
    "# Unique_categories will have unique elements\n",
    "unique_categories = set(category_counts.keys())\n",
    "print(category_counts)\n",
    "\n",
    "element_dict = [el.to_dict() for el in pdf_elements]\n",
    "\n",
    "unique_types = set()\n",
    "\n",
    "for item in element_dict:\n",
    "    unique_types.add(item['type'])\n",
    "\n",
    "print(unique_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21959f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Title',\n",
       " 'element_id': 'c61a9b38a9d6298964b86638210a4622',\n",
       " 'text': 'QUALITY MEASURES FOR HUMANITARIAN DATA',\n",
       " 'metadata': {'coordinates': {'points': ((83.5767, 330.3082),\n",
       "    (83.5767, 396.9582),\n",
       "    (537.5593000000001, 396.9582),\n",
       "    (537.5593000000001, 330.3082)),\n",
       "   'system': 'PixelSpace',\n",
       "   'layout_width': 612.0,\n",
       "   'layout_height': 792.0},\n",
       "  'file_directory': '../data/pdf',\n",
       "  'filename': 'F-62.pdf',\n",
       "  'last_modified': '2026-01-19T15:23:02',\n",
       "  'page_number': 1,\n",
       "  'languages': ['eng'],\n",
       "  'filetype': 'application/pdf'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_elements[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cc76341",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [el for el in pdf_elements if el.category == \"Table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4559ee3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c6d5c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#table_html = tables[0].metadata.text_as_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8dcb5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.Title at 0x2598babeab0>,\n",
       " <unstructured.documents.elements.Title at 0x2598babd880>,\n",
       " <unstructured.documents.elements.Title at 0x2598babe900>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba81460>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba804d0>,\n",
       " <unstructured.documents.elements.Title at 0x2598b9f3950>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba2ce60>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba2ec60>,\n",
       " <unstructured.documents.elements.Title at 0x2598b8a78c0>,\n",
       " <unstructured.documents.elements.Title at 0x2598b8b9820>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba2fdd0>,\n",
       " <unstructured.documents.elements.Title at 0x2598b8c4b90>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba2cd40>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba95f70>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba96240>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba94b90>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba95550>,\n",
       " <unstructured.documents.elements.Title at 0x2598b9f3a10>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba6eae0>,\n",
       " <unstructured.documents.elements.Title at 0x2598b9e7e60>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba892e0>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba89760>,\n",
       " <unstructured.documents.elements.Title at 0x2598b974d10>,\n",
       " <unstructured.documents.elements.Title at 0x2598b9dc9e0>,\n",
       " <unstructured.documents.elements.Title at 0x2598b9dcaa0>,\n",
       " <unstructured.documents.elements.Title at 0x2598b9deb70>,\n",
       " <unstructured.documents.elements.Title at 0x2598bbc47a0>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba9cef0>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba76540>,\n",
       " <unstructured.documents.elements.Title at 0x2598b9942f0>,\n",
       " <unstructured.documents.elements.Title at 0x2598b9d25d0>,\n",
       " <unstructured.documents.elements.Title at 0x2598b968b90>,\n",
       " <unstructured.documents.elements.Title at 0x2598b96ae70>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba75790>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba19c70>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba744a0>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba74bc0>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba76570>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba767b0>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba18e30>,\n",
       " <unstructured.documents.elements.Title at 0x2598a67cc80>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba18b60>,\n",
       " <unstructured.documents.elements.Title at 0x2598b896060>,\n",
       " <unstructured.documents.elements.Title at 0x2598b896780>,\n",
       " <unstructured.documents.elements.Title at 0x2598babeea0>,\n",
       " <unstructured.documents.elements.Title at 0x2598b8bc200>,\n",
       " <unstructured.documents.elements.Title at 0x2598b8bd100>,\n",
       " <unstructured.documents.elements.Title at 0x2598b8bd640>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba425a0>,\n",
       " <unstructured.documents.elements.Title at 0x2598bb56480>,\n",
       " <unstructured.documents.elements.Title at 0x2598b896990>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba4e060>,\n",
       " <unstructured.documents.elements.Title at 0x2598b9b2d20>,\n",
       " <unstructured.documents.elements.Title at 0x2598e8455e0>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba9e360>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba6f0e0>,\n",
       " <unstructured.documents.elements.Title at 0x2598e844ef0>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba6da00>,\n",
       " <unstructured.documents.elements.Title at 0x2598e83d970>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba6f6e0>,\n",
       " <unstructured.documents.elements.Title at 0x2598e569a90>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba6ce90>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba6d2e0>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba6f440>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba6eff0>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba26660>,\n",
       " <unstructured.documents.elements.Title at 0x2598b896a50>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba6e480>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba6e240>,\n",
       " <unstructured.documents.elements.Title at 0x2598bb9e5a0>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba6c590>,\n",
       " <unstructured.documents.elements.Title at 0x2598baabbc0>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba05070>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba6fb90>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba6c8c0>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba05100>,\n",
       " <unstructured.documents.elements.Title at 0x2598bb9fe90>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba04a10>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba04fe0>,\n",
       " <unstructured.documents.elements.Title at 0x2598bb9fda0>,\n",
       " <unstructured.documents.elements.Title at 0x2598bb57bf0>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba07a10>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba6ff50>,\n",
       " <unstructured.documents.elements.Title at 0x2598bb9f740>,\n",
       " <unstructured.documents.elements.Title at 0x2598bb9f170>,\n",
       " <unstructured.documents.elements.Title at 0x2598bb22e70>,\n",
       " <unstructured.documents.elements.Title at 0x2598bb9e810>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba9cd70>,\n",
       " <unstructured.documents.elements.Title at 0x2598bb9d220>,\n",
       " <unstructured.documents.elements.Title at 0x2598bb9cda0>,\n",
       " <unstructured.documents.elements.Title at 0x2598bb9e6c0>,\n",
       " <unstructured.documents.elements.Title at 0x2598bba7950>,\n",
       " <unstructured.documents.elements.Title at 0x2598bb346e0>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba81f70>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba83830>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba821b0>,\n",
       " <unstructured.documents.elements.Title at 0x2598b96b290>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba81f10>,\n",
       " <unstructured.documents.elements.Title at 0x2598e574890>,\n",
       " <unstructured.documents.elements.Title at 0x2598e574b30>,\n",
       " <unstructured.documents.elements.Title at 0x2598e577980>,\n",
       " <unstructured.documents.elements.Title at 0x2598b9f3d40>,\n",
       " <unstructured.documents.elements.Title at 0x2598e576390>,\n",
       " <unstructured.documents.elements.Title at 0x2598e577a70>,\n",
       " <unstructured.documents.elements.Title at 0x2598e5754f0>,\n",
       " <unstructured.documents.elements.Title at 0x2598e5766c0>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba75fa0>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba751c0>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba77f80>,\n",
       " <unstructured.documents.elements.Title at 0x2598bbc6b10>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba774d0>,\n",
       " <unstructured.documents.elements.Title at 0x2598bbc7f20>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba77e00>,\n",
       " <unstructured.documents.elements.Title at 0x2598b8be900>,\n",
       " <unstructured.documents.elements.Title at 0x2598baaa330>,\n",
       " <unstructured.documents.elements.Title at 0x2598baaade0>,\n",
       " <unstructured.documents.elements.Title at 0x2598baab140>,\n",
       " <unstructured.documents.elements.Title at 0x2598baa8110>,\n",
       " <unstructured.documents.elements.Title at 0x2598bb2cef0>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba2cc50>,\n",
       " <unstructured.documents.elements.Title at 0x2598baab440>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba2fb30>,\n",
       " <unstructured.documents.elements.Title at 0x2598bbba720>,\n",
       " <unstructured.documents.elements.Title at 0x2598badce90>,\n",
       " <unstructured.documents.elements.Title at 0x2598ba2c6e0>,\n",
       " <unstructured.documents.elements.Title at 0x2598badda00>,\n",
       " <unstructured.documents.elements.Title at 0x2598bbb3800>,\n",
       " <unstructured.documents.elements.Title at 0x2598bbb2a80>,\n",
       " <unstructured.documents.elements.Title at 0x2598e575730>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = [el for el in pdf_elements if el.category == \"Title\"]\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4c5c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_html = titles[0].metadata.text_as_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7030ec18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<unstructured.documents.elements.Title at 0x2598babeab0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d1f051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUALITY MEASURES FOR HUMANITARIAN DATA\n",
      "Title\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# See what's in the Title element\n",
    "print(titles[0].text)              # Title text content\n",
    "print(titles[0].category)          # \"Title\"\n",
    "print(titles[0].metadata.text_as_html)  # None for Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25dbf823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tables found in PDF\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO \n",
    "from lxml import etree\n",
    "\n",
    "# 1. Get tables from PDF\n",
    "tables = [el for el in pdf_elements if el.category == \"Table\"]\n",
    "\n",
    "if tables:\n",
    "    # 2. Get HTML from FIRST table\n",
    "    table_html = tables[0].metadata.text_as_html\n",
    "    \n",
    "    if table_html:  # Check if not None\n",
    "        # 3. Parse HTML\n",
    "        parser = etree.XMLParser(remove_blank_text=True)\n",
    "        file_obj = StringIO(table_html)\n",
    "        tree = etree.parse(file_obj, parser)\n",
    "        print(etree.tostring(tree, pretty_print=True).decode())\n",
    "    else:\n",
    "        print(\"No HTML available - use infer_table_structure=True\")\n",
    "else:\n",
    "    print(\"No tables found in PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d8122a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: QUALITY MEASURES FOR HUMANITARIAN DATA\n",
      "Page: 1\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: SPRINT REPORT\n",
      "Page: 1\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: APRIL 2023\n",
      "Page: 1\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: QUALITY MEASURES FOR HUMANITARIAN DATA\n",
      "Page: 2\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: SPRINT REPORT\n",
      "Page: 2\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: APRIL 2023\n",
      "Page: 2\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: MEET THE TEAM\n",
      "Page: 3\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Lead Kasia Chmielinski\n",
      "Page: 3\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Technology Matt Taylor\n",
      "Page: 3\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Research Sarah Newman\n",
      "Page: 3\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Design Jessica Yurkofsky\n",
      "Page: 3\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Design Chelsea Qiu\n",
      "Page: 3\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: i\n",
      "Page: 3\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: I. BACKGROUND 1\n",
      "Page: 4\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: II. CHALLENGES 2\n",
      "Page: 4\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: III. KEY FINDINGS 4\n",
      "Page: 4\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: IV. APPROACH & DIRECTIONS 6\n",
      "Page: 4\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: V. RECOMMENDATIONS & DESIGNS 11\n",
      "Page: 4\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: VI. ROADMAP & IMPLEMENTATION 15\n",
      "Page: 4\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: VII. ADDITIONAL CONSIDERATIONS 19\n",
      "Page: 4\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: VIII. CONCLUSION 21\n",
      "Page: 4\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: IX. APPENDIX 22\n",
      "Page: 4\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: ii\n",
      "Page: 4\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: I. BACKGROUND\n",
      "Page: 5\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Goals\n",
      "Page: 5\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Philosophy\n",
      "Page: 5\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: II. CHALLENGES\n",
      "Page: 6\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: III. KEY FINDINGS\n",
      "Page: 8\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: IV. APPROACH & DIRECTIONS\n",
      "Page: 10\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Research\n",
      "Page: 10\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: quality principles across several\n",
      "Page: 10\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: organizations, with HDX in blue.\n",
      "Page: 10\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: appendix.\n",
      "Page: 10\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Prototype directions\n",
      "Page: 11\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Figure 2. Prototype\n",
      "Page: 11\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: sketches of features to\n",
      "Page: 11\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: support the comparing and\n",
      "Page: 11\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: contrasting of metadata on\n",
      "Page: 11\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: similar datasets.\n",
      "Page: 11\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: quality.\n",
      "Page: 12\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Figure 4. Prototype sketches of a dataset with a\n",
      "Page: 12\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: level 3 trust organization indicator as a proxy\n",
      "Page: 12\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: for the data quality principle of credibility.\n",
      "Page: 12\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: measures along two axes: responsible party (data owner /\n",
      "Page: 13\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: third-party) and type of measure (qualitative / quantitative).\n",
      "Page: 13\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: assesses and highlights metadata completeness across a\n",
      "Page: 13\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: number of categories and against a common framework.\n",
      "Page: 13\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Figure 7. Prototype sketch of Content\n",
      "Page: 14\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: certifications from HDX, Data Org\n",
      "Page: 14\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: / Owner and Third-Party expert\n",
      "Page: 14\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: (pass / fail) or quantitative (e.g. a score).\n",
      "Page: 14\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: V. RECOMMENDATIONS & DESIGNS\n",
      "Page: 15\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Recommendations\n",
      "Page: 15\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Additional notes on our recommendations:\n",
      "Page: 16\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Designs\n",
      "Page: 16\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Figure 8. Phase 1 content in Quality Measures Pane on HDX site.\n",
      "Page: 16\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: VI. ROADMAP & IMPLEMENTATION\n",
      "Page: 19\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Phase 1\n",
      "Page: 19\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Approach\n",
      "Page: 19\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Use | Trust & Safety | Content Quality | Technical Specs\n",
      "Page: 19\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Technical Considerations\n",
      "Page: 19\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Quality\tSection Measure\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: HDX\tProcess/source Response\tParameters\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Use\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Intended Use\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: NEW: Dataset Upload - Intended Use Field\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Open Text\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Restrictions\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Dataset Upload - Caveats\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Open Text\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Trust & Safety\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: PII\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: HDX QA\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Yes, No\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: SDC Check\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: HDX QA\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Yes, No\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Passed HDX QA\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: HDX QA\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Yes, No\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Content Quality\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Update Frequency & Last Updated date*\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Dataset Upload - Expected Frequency Update, Upload timestamp\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Frequency - Multiple choice (Every day, every week, every two weeks, etc.)\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Last uploaded- Date-time\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Collection Method\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Dataset Upload - Methodology\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Multiple Choice (Census, Sample Survey, Direct Observational Data, Registry, Other)\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Level of Analysis\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: HDX QA\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Multiple Choice (national or sub-national)\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Quality Certifications\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Review by HDX Data Team\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Technical Specs\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: P-Code\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Dataset Upload - Automatically reviewed\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: HXL\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Dataset Upload - Automatically reviewed\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Valid URLs\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: HDX QA\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Yes, No\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: API Used\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: NEW: Dataset Upload - Automatically reviewed\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Yes, No\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Format\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Dataset Upload - Resource Upload\n",
      "Page: 20\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Further recommendations\n",
      "Page: 21\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Phase 2\n",
      "Page: 21\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Approach\n",
      "Page: 21\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Technical Considerations\n",
      "Page: 21\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Phase 3\n",
      "Page: 21\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Approach\n",
      "Page: 21\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Rationale\n",
      "Page: 21\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: VII. ADDITIONAL CONSIDERATIONS\n",
      "Page: 23\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Inclusion of quality measures in future technical projects\n",
      "Page: 23\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Trusted Org & Third Party Certification program definition\n",
      "Page: 23\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Compare feature dependencies\n",
      "Page: 23\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Resource identification\n",
      "Page: 24\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: VIII. CONCLUSION\n",
      "Page: 25\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: IX. APPENDIX\n",
      "Page: 26\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Aid Memoir for a COR/AOR (March 2012)\n",
      "Page: 26\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Methods in the Humanitarian Sector (April 2020) - https://www.hum-dseg.org/dseg-ethical-\n",
      "Page: 26\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: framework\n",
      "Page: 26\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Action. Second Edition (2020) - https://missingpersons.icrc.org/library/handbook-data-\n",
      "Page: 26\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: protection-humanitarian-action-second-edition\n",
      "Page: 26\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Agency (September 2015) - https://unstats.un.org/unsd/unsystem/Documents-Sept2015/\n",
      "Page: 26\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: GSQAF-GenericData-Sept2015.pdf\n",
      "Page: 26\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Figure 8. Phase 1 content in Quality Measures Pane on HDX site.\n",
      "Page: 27\n",
      "Filename: F-62.pdf\n",
      "---\n",
      "Title: Figure 9. HDX Search view with Quality Measure counts.\n",
      "Page: 28\n",
      "Filename: F-62.pdf\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# CORRECT way to use Titles\n",
    "for title in titles:\n",
    "    print(f\"Title: {title.text}\")\n",
    "    print(f\"Page: {title.metadata.page_number}\")\n",
    "    print(f\"Filename: {title.metadata.filename}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46cca008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Created 129 title-based chunks for RAG\n"
     ]
    }
   ],
   "source": [
    "# Group content by titles (perfect for RAG)\n",
    "chunks = []\n",
    "\n",
    "for i, title in enumerate(titles):\n",
    "    chunk = {\n",
    "        \"title\": title.text,\n",
    "        \"content\": title.text,  # Start with title\n",
    "        \"page\": title.metadata.page_number,\n",
    "        \"source\": title.metadata.filename,\n",
    "        \"type\": \"section\"\n",
    "    }\n",
    "    chunks.append(chunk)\n",
    "\n",
    "print(f\"---> Created {len(chunks)} title-based chunks for RAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da99c4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title           | Page 1 | QUALITY MEASURES FOR HUMANITARIAN DATA...\n",
      "Title           | Page 1 | SPRINT REPORT...\n",
      "Title           | Page 1 | APRIL 2023...\n",
      "Title           | Page 2 | QUALITY MEASURES FOR HUMANITARIAN DATA...\n",
      "Title           | Page 2 | SPRINT REPORT...\n",
      "Title           | Page 2 | APRIL 2023...\n",
      "Title           | Page 3 | MEET THE TEAM...\n",
      "Title           | Page 3 | Lead Kasia Chmielinski...\n",
      "Title           | Page 3 | Technology Matt Taylor...\n",
      "Title           | Page 3 | Research Sarah Newman...\n",
      "Title           | Page 3 | Design Jessica Yurkofsky...\n",
      "Title           | Page 3 | Design Chelsea Qiu...\n",
      "Title           | Page 3 | i...\n",
      "Title           | Page 4 | I. BACKGROUND 1...\n",
      "Title           | Page 4 | II. CHALLENGES 2...\n",
      "Title           | Page 4 | III. KEY FINDINGS 4...\n",
      "Title           | Page 4 | IV. APPROACH & DIRECTIONS 6...\n",
      "Title           | Page 4 | V. RECOMMENDATIONS & DESIGNS 11...\n",
      "Title           | Page 4 | VI. ROADMAP & IMPLEMENTATION 15...\n",
      "Title           | Page 4 | VII. ADDITIONAL CONSIDERATIONS 19...\n",
      "Title           | Page 4 | VIII. CONCLUSION 21...\n",
      "Title           | Page 4 | IX. APPENDIX 22...\n",
      "Title           | Page 4 | ii...\n",
      "Title           | Page 5 | I. BACKGROUND...\n",
      "Title           | Page 5 | Goals...\n",
      "NarrativeText   | Page 5 | The purpose of this Data Labeling project was for select members of the Data Nut...\n",
      "ListItem        | Page 5 | User and Platform Research. We conducted user research with the Centre team (and...\n",
      "ListItem        | Page 5 | Quality Measurement Prototype. Building on user research and an assessment of th...\n",
      "ListItem        | Page 5 | Preliminary thoughts on Scalability. Through research and prototyping, we began ...\n",
      "Title           | Page 5 | Philosophy...\n",
      "NarrativeText   | Page 5 | The Data Nutrition Project is a non-profit initiative that formed in 2018 to dev...\n",
      "UncategorizedText | Page 5 | 1...\n",
      "Title           | Page 6 | II. CHALLENGES...\n",
      "NarrativeText   | Page 6 | There are many challenges that can be impediments to dataset quality. This is ce...\n",
      "NarrativeText   | Page 6 | Challenge 1 - Identifying scoring methods that are succinct while not overly sim...\n",
      "NarrativeText   | Page 6 | Scores are meant to provide information quickly and ease comparison, while invit...\n",
      "NarrativeText   | Page 6 | Challenge 2 - Balancing scalable (quantitative) & comprehensive (qualitative) me...\n",
      "NarrativeText   | Page 6 | Qualitative information helps mitigate some of the concerns above, as it is ofte...\n",
      "NarrativeText   | Page 6 | Challenge 3 - Communicating quality to motivate rather than disincentivize...\n",
      "NarrativeText   | Page 6 | Our hope is that quality measures will, in the short term, facilitate better dat...\n",
      "UncategorizedText | Page 6 | 2...\n",
      "NarrativeText   | Page 7 | it possibly could have been given a particular set of circumstances. It is imp...\n",
      "NarrativeText   | Page 7 | Challenge 4 - Building a quality framework that balances flexibility with consis...\n",
      "NarrativeText   | Page 7 | As the humanitarian sector changes over time with respect to crises and data nee...\n",
      "NarrativeText   | Page 7 | Challenge 5 - Determining responsibilities within the data pipeline...\n",
      "NarrativeText   | Page 7 | HDX is committed to hosting good quality data, and requires QA and other data on...\n",
      "UncategorizedText | Page 7 | 3...\n",
      "Title           | Page 8 | III. KEY FINDINGS...\n",
      "NarrativeText   | Page 8 | The five-week sprint gave rise to a number of key findings, which informed our f...\n",
      "NarrativeText   | Page 8 | Finding 1 - HDX is best positioned to define rather than assess quality...\n",
      "NarrativeText   | Page 8 | Due to the range of dataset types on HDX, limitations of domain knowledge, and r...\n",
      "ListItem        | Page 8 | 1) Define the framework for quality of datasets on HDX (meaning define what is...\n",
      "ListItem        | Page 8 | 2) Facilitate the gathering of this information from data organizations;...\n",
      "ListItem        | Page 8 | 3) Provide a display of this information to data users on HDX, designed in align...\n",
      "NarrativeText   | Page 8 | Finding 2 - There is an opportunity to leverage existing quality measures...\n",
      "NarrativeText   | Page 8 | Data quality assessment is already conducted on HDX, albeit at different times a...\n",
      "NarrativeText   | Page 8 | Finding 3 - Domain experts and third-party validators can provide complementary ...\n",
      "NarrativeText   | Page 8 | Due to the variety of data types and domains on HDX, data content quality assess...\n",
      "UncategorizedText | Page 8 | 4...\n",
      "NarrativeText   | Page 9 | owners and third-party assessors who will be the ones to contribute much of this...\n",
      "NarrativeText   | Page 9 | Finding 4 - Automation of QA and assessment tasks can enable scale...\n",
      "NarrativeText   | Page 9 | While there is some initial groundwork required to prepare for automating certai...\n",
      "NarrativeText   | Page 9 | Finding 5 - Primary use case is data selection, which can ultimately be supporte...\n",
      "NarrativeText   | Page 9 | Through our conversations and interviews, we learned that the primary reason for...\n",
      "UncategorizedText | Page 9 | 5...\n",
      "Title           | Page 10 | IV. APPROACH & DIRECTIONS...\n",
      "NarrativeText   | Page 10 | We explored quality measures on the HDX platform through a tailored 5-week disco...\n",
      "Title           | Page 10 | Research...\n",
      "NarrativeText   | Page 10 | Our team spent the first two weeks researching background materials and intervie...\n",
      "NarrativeText   | Page 10 | In parallel, we conducted interviews with stakeholders that represented key poin...\n",
      "NarrativeText   | Page 10 | Figure 1. Matrix aligning data...\n",
      "Title           | Page 10 | quality principles across several...\n",
      "Title           | Page 10 | organizations, with HDX in blue....\n",
      "NarrativeText   | Page 10 | Full size matrix included in...\n",
      "Title           | Page 10 | appendix....\n",
      "UncategorizedText | Page 10 | 6...\n",
      "Title           | Page 11 | Prototype directions...\n",
      "NarrativeText   | Page 11 | Based on the research and interviews conducted in the first two weeks of our spr...\n",
      "ListItem        | Page 11 | 1.\t Comparability:\tfeatures\tto\tsupport\tdataset\tselection...\n",
      "NarrativeText   | Page 11 | Throughout the interviews, we heard that a primary use case for data quality ass...\n",
      "Title           | Page 11 | Figure 2. Prototype...\n",
      "Title           | Page 11 | sketches of features to...\n",
      "Title           | Page 11 | support the comparing and...\n",
      "Title           | Page 11 | contrasting of metadata on...\n",
      "Title           | Page 11 | similar datasets....\n",
      "ListItem        | Page 11 | 2.\t Credibility:\tleveraging\ttrust\tin\torganizations...\n",
      "NarrativeText   | Page 11 | From the earliest conversations, data organizations and the Centre teams stresse...\n",
      "UncategorizedText | Page 11 | 7...\n",
      "NarrativeText   | Page 12 | Figure 3. Aligning the data pipeline to quality principles and responsible parti...\n",
      "UncategorizedText | Page 12 | relationship between the data organization and HDX for the assessment and commun...\n",
      "Title           | Page 12 | quality....\n",
      "NarrativeText   | Page 12 | Our second prototype aimed to leverage trust in organizations based on their dat...\n",
      "Title           | Page 12 | Figure 4. Prototype sketches of a dataset with a...\n",
      "Title           | Page 12 | level 3 trust organization indicator as a proxy...\n",
      "Title           | Page 12 | for the data quality principle of credibility....\n",
      "UncategorizedText | Page 12 | 8...\n",
      "ListItem        | Page 13 | 3.\t Completeness,\ttimeliness:\tassessing\tmetadata\tcompleteness...\n",
      "NarrativeText   | Page 13 | The last two prototype directions are related to fitness for purpose - assessing...\n",
      "NarrativeText   | Page 13 | Building off this analysis, our third prototype direction falls within the third...\n",
      "NarrativeText   | Page 13 | Figure 5 (left). Quadrant analysis of fitness for purpose...\n",
      "Title           | Page 13 | measures along two axes: responsible party (data owner /...\n",
      "Title           | Page 13 | third-party) and type of measure (qualitative / quantitative)....\n",
      "NarrativeText   | Page 13 | Figure 6 (right). Prototype for a quality label that...\n",
      "Title           | Page 13 | assesses and highlights metadata completeness across a...\n",
      "Title           | Page 13 | number of categories and against a common framework....\n",
      "UncategorizedText | Page 13 | 9...\n",
      "ListItem        | Page 14 | 4.\t Relevance,\taccuracy:\tassessing\tfitness\tfor\tpurpose...\n",
      "NarrativeText   | Page 14 | The final prototype approach, assessing fitness for purpose in alignment with da...\n",
      "NarrativeText   | Page 14 | Our suggestion for this approach is thus to acknowledge the dependency between H...\n",
      "Title           | Page 14 | Figure 7. Prototype sketch of Content...\n",
      "NarrativeText   | Page 14 | Quality Measures that include quality...\n",
      "Title           | Page 14 | certifications from HDX, Data Org...\n",
      "Title           | Page 14 | / Owner and Third-Party expert...\n",
      "NarrativeText   | Page 14 | organizations. These could be binary...\n",
      "Title           | Page 14 | (pass / fail) or quantitative (e.g. a score)....\n",
      "UncategorizedText | Page 14 | 10...\n",
      "Title           | Page 15 | V. RECOMMENDATIONS & DESIGNS...\n",
      "Title           | Page 15 | Recommendations...\n",
      "NarrativeText   | Page 15 | From our four prototype directions outlined above, and integrating feedback from...\n",
      "NarrativeText   | Page 15 | We also share recommendations for how to approach the continuation of these expl...\n",
      "NarrativeText   | Page 15 | Phase 1 - Fully scoped, ready to implement...\n",
      "NarrativeText   | Page 15 | Aggregate and make easily accessible the content that HDX already collects with ...\n",
      "NarrativeText   | Page 15 | Phase 2 - High-level spec, requires additional research and design...\n",
      "NarrativeText   | Page 15 | Create an organization review and vetting process that allows for trusted orgs t...\n",
      "NarrativeText   | Page 15 | Phase 3 - High-level spec, requires additional research & design...\n",
      "NarrativeText   | Page 15 | Collect additional quality measures through third-party organization QA processe...\n",
      "UncategorizedText | Page 15 | 11...\n",
      "Title           | Page 16 | Additional notes on our recommendations:...\n",
      "ListItem        | Page 16 | Our approach involved prototyping on real datasets. This proved to be an essenti...\n",
      "ListItem        | Page 16 | Based on our research and interviews, completeness, accuracy, and relevance were...\n",
      "ListItem        | Page 16 | Based on the needs of HDX users and the circumstances  20K+ disparate datasets,...\n",
      "Title           | Page 16 | Designs...\n",
      "NarrativeText   | Page 16 | DNP created three Phase 1 designs (a template + two dataset-specific versions), ...\n",
      "Title           | Page 16 | Figure 8. Phase 1 content in Quality Measures Pane on HDX site....\n",
      "UncategorizedText | Page 16 | 12...\n",
      "NarrativeText   | Page 17 | Figure 9. HDX search view with Quality Measure counts....\n",
      "UncategorizedText | Page 17 | Figure 10. Views of Quality Measures Panes (Phase 1) for two example datasets....\n",
      "UncategorizedText | Page 17 | 13...\n",
      "Header          | Page 18 | Quality Measures for Humanitarian Data...\n",
      "NarrativeText   | Page 18 | Figure 11. Similar Datasets comparison sketch, to be refined in Phase 3....\n",
      "UncategorizedText | Page 18 | 14...\n",
      "Title           | Page 19 | VI. ROADMAP & IMPLEMENTATION...\n",
      "Title           | Page 19 | Phase 1...\n",
      "Title           | Page 19 | Approach...\n",
      "NarrativeText   | Page 19 | We recommend creating a new Quality Measures pane (alongside the Data & Resource...\n",
      "Title           | Page 19 | Use | Trust & Safety | Content Quality | Technical Specs...\n",
      "NarrativeText   | Page 19 | The technical needs for this should be minimal, and implementation process could...\n",
      "Title           | Page 19 | Technical Considerations...\n",
      "NarrativeText   | Page 19 | Phase 1 involves no database changes, and minimal back-end implementation. It wi...\n",
      "ListItem        | Page 19 | Database/DevOps. The data needed for the Phase 1 measures view exists within HDX...\n",
      "ListItem        | Page 19 | Back-end. Implementation would be focused on making sure all of the necessary qu...\n",
      "ListItem        | Page 19 | Front-end. Front-end work would be the most significant portion of this phase. I...\n",
      "ListItem        | Page 19 | Feedback. It will be important to have a clearly defined list of stakeholders fr...\n",
      "NarrativeText   | Page 20 | Phase 1 is intentionally a consolidation and surfacing and organizing what is a...\n",
      "Title           | Page 20 | Quality\tSection Measure...\n",
      "Title           | Page 20 | HDX\tProcess/source Response\tParameters...\n",
      "Title           | Page 20 | Use...\n",
      "Title           | Page 20 | Intended Use...\n",
      "Title           | Page 20 | NEW: Dataset Upload - Intended Use Field...\n",
      "Title           | Page 20 | Open Text...\n",
      "Title           | Page 20 | Restrictions...\n",
      "Title           | Page 20 | Dataset Upload - Caveats...\n",
      "Title           | Page 20 | Open Text...\n",
      "Title           | Page 20 | Trust & Safety...\n",
      "Title           | Page 20 | PII...\n",
      "Title           | Page 20 | HDX QA...\n",
      "Title           | Page 20 | Yes, No...\n",
      "Title           | Page 20 | SDC Check...\n",
      "Title           | Page 20 | HDX QA...\n",
      "Title           | Page 20 | Yes, No...\n",
      "Title           | Page 20 | Passed HDX QA...\n",
      "Title           | Page 20 | HDX QA...\n",
      "Title           | Page 20 | Yes, No...\n",
      "Title           | Page 20 | Content Quality...\n",
      "Title           | Page 20 | Update Frequency & Last Updated date*...\n",
      "ListItem        | Page 20 | When these two pieces of information conflict, it should be noted as conflicting...\n",
      "Title           | Page 20 | Dataset Upload - Expected Frequency Update, Upload timestamp...\n",
      "Title           | Page 20 | Frequency - Multiple choice (Every day, every week, every two weeks, etc.)...\n",
      "Title           | Page 20 | Last uploaded- Date-time...\n",
      "Title           | Page 20 | Collection Method...\n",
      "Title           | Page 20 | Dataset Upload - Methodology...\n",
      "Title           | Page 20 | Multiple Choice (Census, Sample Survey, Direct Observational Data, Registry, Oth...\n",
      "Title           | Page 20 | Level of Analysis...\n",
      "Title           | Page 20 | HDX QA...\n",
      "Title           | Page 20 | Multiple Choice (national or sub-national)...\n",
      "NarrativeText   | Page 20 | Badge (i.e. it is present if the review has been done, absent if not)....\n",
      "Title           | Page 20 | Quality Certifications...\n",
      "Title           | Page 20 | Review by HDX Data Team...\n",
      "NarrativeText   | Page 20 | Possible badges include: Datagrid Dataset (NEW, would have to be imported throug...\n",
      "Title           | Page 20 | Technical Specs...\n",
      "Title           | Page 20 | P-Code...\n",
      "Title           | Page 20 | Dataset Upload - Automatically reviewed...\n",
      "NarrativeText   | Page 20 | Badge (i.e. it is present if P-codes are used, absent if not)....\n",
      "Title           | Page 20 | HXL...\n",
      "Title           | Page 20 | Dataset Upload - Automatically reviewed...\n",
      "NarrativeText   | Page 20 | Badge (i.e. it is present if HXL is used, absent if not)....\n",
      "Title           | Page 20 | Valid URLs...\n",
      "Title           | Page 20 | HDX QA...\n",
      "Title           | Page 20 | Yes, No...\n",
      "Title           | Page 20 | API Used...\n",
      "Title           | Page 20 | NEW: Dataset Upload - Automatically reviewed...\n",
      "Title           | Page 20 | Yes, No...\n",
      "Title           | Page 20 | Format...\n",
      "Title           | Page 20 | Dataset Upload - Resource Upload...\n",
      "NarrativeText   | Page 20 | Select All that Apply (.csv, .kxl, .xlsx, etc. [Centre to generate comprehensive...\n",
      "NarrativeText   | Page 20 | Figure 12. Phase 1 Quality Measures table including source of information and re...\n",
      "UncategorizedText | Page 20 | 16...\n",
      "Title           | Page 21 | Further recommendations...\n",
      "Title           | Page 21 | Phase 2...\n",
      "NarrativeText   | Page 21 | Phases 2 and 3 research and designs could be explored in future engagements....\n",
      "Title           | Page 21 | Approach...\n",
      "NarrativeText   | Page 21 | Phase 2 has three specific foci: 1) determining measures for and assessing organ...\n",
      "Title           | Page 21 | Technical Considerations...\n",
      "NarrativeText   | Page 21 | For each of the three components of Phase 2, technical considerations would vary...\n",
      "Title           | Page 21 | Phase 3...\n",
      "Title           | Page 21 | Approach...\n",
      "NarrativeText   | Page 21 | Following on the recommendations from Phases 1 & 2, Phase 3 would enable a more ...\n",
      "NarrativeText   | Page 21 | With more comprehensive quality measures, HDX will have the information availabl...\n",
      "Title           | Page 21 | Rationale...\n",
      "NarrativeText   | Page 21 | In our research on Common Operational Datasets (CODs) and GIS road-mapping datas...\n",
      "UncategorizedText | Page 21 | 17...\n",
      "NarrativeText   | Page 22 | tend to have a standardized structure that most dataset creators use. Consequent...\n",
      "NarrativeText   | Page 22 | And, while the measures in Phase 1 are a helpful starting point to assess qualit...\n",
      "UncategorizedText | Page 22 | 18...\n",
      "Title           | Page 23 | VII. ADDITIONAL CONSIDERATIONS...\n",
      "NarrativeText   | Page 23 | Impact on existing data processes and systems...\n",
      "NarrativeText   | Page 23 | Currently, data organizations upload their datasets to HDX either in bulk (using...\n",
      "Title           | Page 23 | Inclusion of quality measures in future technical projects...\n",
      "NarrativeText   | Page 23 | Over the course of our engagement with the Centre, we learned that there are sev...\n",
      "Title           | Page 23 | Trusted Org & Third Party Certification program definition...\n",
      "NarrativeText   | Page 23 | As outlined above, for Phase 2 would entail research for two initiatives that le...\n",
      "Title           | Page 23 | Compare feature dependencies...\n",
      "NarrativeText   | Page 23 | Phase 3 considerations include the addition of domain-specific metadata, third-p...\n",
      "UncategorizedText | Page 23 | 19...\n",
      "NarrativeText   | Page 24 | on HDX. Multiple conversations with the Centre and its users highlighted the cri...\n",
      "Title           | Page 24 | Resource identification...\n",
      "NarrativeText   | Page 24 | Each of the recommendations made in this report will require resources from the ...\n",
      "UncategorizedText | Page 24 | 20...\n",
      "Title           | Page 25 | VIII. CONCLUSION...\n",
      "NarrativeText   | Page 25 | This report outlines the findings from a five-week research and design sprint, u...\n",
      "NarrativeText   | Page 25 | In summary, HDX already attends to dataset quality. We found that a lot could be...\n",
      "NarrativeText   | Page 25 | Many fields that involve data-driven decision making are only now starting to as...\n",
      "UncategorizedText | Page 25 | 21...\n",
      "Title           | Page 26 | IX. APPENDIX...\n",
      "NarrativeText   | Page 26 | Figure 1. Matrix aligning data quality principles across several organizations, ...\n",
      "NarrativeText   | Page 26 | Documents cited:...\n",
      "NarrativeText   | Page 26 | a. USAID, Democratic Republic of Congo, How to conduct a data quality assessmen...\n",
      "Title           | Page 26 | Aid Memoir for a COR/AOR (March 2012)...\n",
      "NarrativeText   | Page 26 | b. Frontier Technologies Hub, releasing the power of digital data for developme...\n",
      "NarrativeText   | Page 26 | opportunities (June 2019)...\n",
      "UncategorizedText | Page 26 | c. Data Science & Ethics Group, A Framework for the Ethical Use of Advanced Dat...\n",
      "Title           | Page 26 | Methods in the Humanitarian Sector (April 2020) - https://www.hum-dseg.org/dseg...\n",
      "Title           | Page 26 | framework...\n",
      "UncategorizedText | Page 26 | d. International Committee of the Red Cross, Handbook on Data Protection in Hum...\n",
      "Title           | Page 26 | Action. Second Edition (2020) - https://missingpersons.icrc.org/library/handboo...\n",
      "Title           | Page 26 | protection-humanitarian-action-second-edition...\n",
      "UncategorizedText | Page 26 | e. The United Nations Statistics Division, Generic Data Quality Assurance Frame...\n",
      "Title           | Page 26 | Agency (September 2015) - https://unstats.un.org/unsd/unsystem/Documents-Sept20...\n",
      "Title           | Page 26 | GSQAF-GenericData-Sept2015.pdf...\n",
      "UncategorizedText | Page 26 | 22...\n",
      "Header          | Page 27 | Quality Measures for Humanitarian Data...\n",
      "Title           | Page 27 | Figure 8. Phase 1 content in Quality Measures Pane on HDX site....\n",
      "UncategorizedText | Page 27 | 23...\n",
      "Header          | Page 28 | Quality Measures for Humanitarian Data...\n",
      "Title           | Page 28 | Figure 9. HDX Search view with Quality Measure counts....\n",
      "UncategorizedText | Page 28 | 24...\n",
      "Header          | Page 29 | Quality Measures for Humanitarian Data...\n",
      "Footer          | Page 29 | Figure 10a. Views of Quality Measures Panes (Phase 1) for two example datasets -...\n",
      "UncategorizedText | Page 29 | 25...\n",
      "Header          | Page 30 | Quality Measures for Humanitarian Data...\n",
      "Footer          | Page 30 | Figure 10b. Views of Quality Measures Panes (Phase 1) for two example datasets -...\n",
      "UncategorizedText | Page 30 | 26...\n",
      "Header          | Page 31 | Quality Measures for Humanitarian Data...\n",
      "NarrativeText   | Page 31 | Figure 11. Similar Datasets comparison sketch, to be refined in Phase 3....\n",
      "UncategorizedText | Page 31 | 27...\n",
      "Footer          | Page 32 |  2023 Data Nutrition Project...\n"
     ]
    }
   ],
   "source": [
    "# Better approach - ALL elements for hybrid retrieval\n",
    "for el in pdf_elements:\n",
    "    print(f\"{el.category:15} | Page {el.metadata.page_number} | {el.text[:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7c02d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> 276 chunks ready for BM25 + Semantic indexing\n"
     ]
    }
   ],
   "source": [
    "# Create proper chunks with metadata\n",
    "chunks = []\n",
    "\n",
    "for el in pdf_elements:\n",
    "    chunk = {\n",
    "        \"content\": el.text,\n",
    "        \"category\": el.category,  # Title, Table, Text, etc.\n",
    "        \"page\": el.metadata.page_number,\n",
    "        \"source\": el.metadata.filename,\n",
    "        \"is_table\": el.category == \"Table\",\n",
    "        \"table_html\": el.metadata.text_as_html if el.category == \"Table\" else None\n",
    "    }\n",
    "    chunks.append(chunk)\n",
    "\n",
    "print(f\"---> {len(chunks)} chunks ready for BM25 + Semantic indexing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c1f3dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the element with text \"References\" and category \"Title\"\n",
    "title = [\n",
    "    el for el in pdf_elements\n",
    "    if el.category == \"Title\"\n",
    "][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca2736dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Title',\n",
       " 'element_id': 'c61a9b38a9d6298964b86638210a4622',\n",
       " 'text': 'QUALITY MEASURES FOR HUMANITARIAN DATA',\n",
       " 'metadata': {'coordinates': {'points': ((83.5767, 330.3082),\n",
       "    (83.5767, 396.9582),\n",
       "    (537.5593000000001, 396.9582),\n",
       "    (537.5593000000001, 330.3082)),\n",
       "   'system': 'PixelSpace',\n",
       "   'layout_width': 612.0,\n",
       "   'layout_height': 792.0},\n",
       "  'file_directory': '../data/pdf',\n",
       "  'filename': 'F-62.pdf',\n",
       "  'last_modified': '2026-01-19T15:23:02',\n",
       "  'page_number': 1,\n",
       "  'languages': ['eng'],\n",
       "  'filetype': 'application/pdf'}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae47abe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c61a9b38a9d6298964b86638210a4622'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5576ee67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Title', 'element_id': 'c61a9b38a9d6298964b86638210a4622', 'text': 'QUALITY MEASURES FOR HUMANITARIAN DATA', 'metadata': {'coordinates': {'points': ((83.5767, 330.3082), (83.5767, 396.9582), (537.5593000000001, 396.9582), (537.5593000000001, 330.3082)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 1, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '7da0b5e778fd30f37d7ec6ba7a536453', 'text': 'SPRINT REPORT', 'metadata': {'coordinates': {'points': ((244.796, 421.828), (244.796, 434.178), (367.1871, 434.178), (367.1871, 421.828)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 1, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '88b950c120c046782bcec6b7cf7854cf', 'text': 'APRIL 2023', 'metadata': {'coordinates': {'points': ((265.0125, 441.928), (265.0125, 454.278), (346.9749, 454.278), (346.9749, 441.928)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 1, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '4f984e949288e28b7c851f7ce99e460b', 'text': 'QUALITY MEASURES FOR HUMANITARIAN DATA', 'metadata': {'coordinates': {'points': ((83.5767, 330.3082), (83.5767, 396.9582), (537.5593000000001, 396.9582), (537.5593000000001, 330.3082)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 2, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '7b8e52b236df84a1e9c334cb417a042d', 'text': 'SPRINT REPORT', 'metadata': {'coordinates': {'points': ((244.796, 421.828), (244.796, 434.178), (367.1871, 434.178), (367.1871, 421.828)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 2, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '91c8ba69d3a52c2d0da72a0875997e2a', 'text': 'APRIL 2023', 'metadata': {'coordinates': {'points': ((265.0125, 441.928), (265.0125, 454.278), (346.9749, 454.278), (346.9749, 441.928)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 2, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': 'f058a90af41c7fcf2c05c8cb5ef91e1d', 'text': 'MEET THE TEAM', 'metadata': {'coordinates': {'points': ((248.0876, 215.74159999999995), (248.0876, 229.04160000000002), (363.92359999999996, 229.04160000000002), (363.92359999999996, 215.74159999999995)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 3, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': 'd2ea66c0d5cc2454c3837b43c38459ce', 'text': 'Lead Kasia Chmielinski', 'metadata': {'coordinates': {'points': ((120.5334, 360.5788), (120.5334, 382.0788), (196.4124, 382.0788), (196.4124, 360.5788)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 3, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '835cd7c73eb433cad34f930698ae2f22', 'text': 'Technology Matt Taylor', 'metadata': {'coordinates': {'points': ((282.1331, 360.5788), (282.1331, 382.0788), (332.3431, 382.0788), (332.3431, 360.5788)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 3, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '5db5773d1659beccdfa597cb619c1d6f', 'text': 'Research Sarah Newman', 'metadata': {'coordinates': {'points': ((422.7203, 360.5788), (422.7203, 382.0788), (489.2803, 382.0788), (489.2803, 360.5788)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 3, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '1c245ae9c9918e781ff48354b18ef5b4', 'text': 'Design Jessica Yurkofsky', 'metadata': {'coordinates': {'points': ((189.1259, 521.8177000000001), (189.1259, 543.3177000000001), (262.8739, 543.3177000000001), (262.8739, 521.8177000000001)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 3, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '474ac5413ef4f25d082dfb5e3f6f06ab', 'text': 'Design Chelsea Qiu', 'metadata': {'coordinates': {'points': ((359.7805, 522.9449), (359.7805, 544.4449), (412.2195, 544.4449), (412.2195, 522.9449)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 3, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '11f472f70ab4913b947be45627600c7f', 'text': 'i', 'metadata': {'coordinates': {'points': ((590.7384, 722.8499), (590.7384, 732.8499), (592.8484, 732.8499), (592.8484, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 3, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': 'a724d352b0f657661407a6c00b1886fc', 'text': 'I. BACKGROUND 1', 'metadata': {'coordinates': {'points': ((255.364, 97.4991), (255.364, 139.90250000000003), (356.65399999999994, 139.90250000000003), (356.65399999999994, 97.4991)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 4, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '16ea1a53dc128e36d23e3099a3d897f6', 'text': 'II. CHALLENGES 2', 'metadata': {'coordinates': {'points': ((259.2229, 167.69909999999993), (259.2229, 210.10249999999996), (352.78489999999994, 210.10249999999996), (352.78489999999994, 167.69909999999993)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 4, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': 'bb5a060dca147116e9187527a929d211', 'text': 'III. KEY FINDINGS 4', 'metadata': {'coordinates': {'points': ((253.9425, 237.89909999999998), (253.9425, 280.3025), (358.0395, 280.3025), (358.0395, 237.89909999999998)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 4, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '17377f0f04d99a844eb54958f5dc356d', 'text': 'IV. APPROACH & DIRECTIONS 6', 'metadata': {'coordinates': {'points': ((213.4031, 308.0991), (213.4031, 350.5025), (398.6090999999999, 350.5025), (398.6090999999999, 308.0991)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 4, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '0a7fec2c60bce0e2cada937f3e79533c', 'text': 'V. RECOMMENDATIONS & DESIGNS 11', 'metadata': {'coordinates': {'points': ((189.6864, 378.29909999999995), (189.6864, 420.7025), (422.3313999999998, 420.7025), (422.3313999999998, 378.29909999999995)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 4, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '4f7c7d847a63d05bdcfcbbb55c903279', 'text': 'VI. ROADMAP & IMPLEMENTATION 15', 'metadata': {'coordinates': {'points': ((194.6389, 448.4991), (194.6389, 490.90250000000003), (417.3928999999999, 490.90250000000003), (417.3928999999999, 448.4991)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 4, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '3a5d4ca624931611433ecd6fedbfedde', 'text': 'VII. ADDITIONAL CONSIDERATIONS 19', 'metadata': {'coordinates': {'points': ((195.3944, 518.6991), (195.3944, 561.1025), (416.6573999999998, 561.1025), (416.6573999999998, 518.6991)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 4, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '1c3a706021918fc81dafb25403c90321', 'text': 'VIII. CONCLUSION 21', 'metadata': {'coordinates': {'points': ((258.5837, 588.8991), (258.5837, 631.3025), (353.4267, 631.3025), (353.4267, 588.8991)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 4, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '2036afe26a05a4aa4eed29555bf3c908', 'text': 'IX. APPENDIX 22', 'metadata': {'coordinates': {'points': ((270.2388, 659.0989999999999), (270.2388, 701.5024), (341.7648, 701.5024), (341.7648, 659.0989999999999)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 4, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': 'f9d75b1f7fb54a11415c88c03a04d364', 'text': 'ii', 'metadata': {'coordinates': {'points': ((589.6584, 722.8499), (589.6584, 732.8499), (593.9284, 732.8499), (593.9284, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 4, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': 'f0095ef689288d3320fcb10fb6788b84', 'text': 'I. BACKGROUND', 'metadata': {'coordinates': {'points': ((255.364, 76.38159999999993), (255.364, 108.1816), (360.59779999999995, 108.1816), (360.59779999999995, 76.38159999999993)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 5, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '56cdae409ada7bb3dafd2ae35998ce9c', 'text': 'Goals', 'metadata': {'coordinates': {'points': ((72.0, 132.85180000000003), (72.0, 144.2518), (105.24000000000001, 144.2518), (105.24000000000001, 132.85180000000003)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 5, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'NarrativeText', 'element_id': '628814a1c903b945f3243d6220bcc77e', 'text': 'The purpose of this Data Labeling project was for select members of the Data Nutrition Project team to research and prototype possible quality measures for humanitarian datasets that are hosted on the HDX platform, which is owned and managed by the UN Centre for Humanitarian Data. The scope included:', 'metadata': {'coordinates': {'points': ((72.0, 156.45190000000002), (72.0, 211.65179999999998), (539.0135999999998, 211.65179999999998), (539.0135999999998, 156.45190000000002)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 5, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '56cdae409ada7bb3dafd2ae35998ce9c'}}\n",
      "{'type': 'ListItem', 'element_id': 'd0d1d80628ffffbc5e38062c05e8107e', 'text': 'User and Platform Research. We conducted user research with the Centre team (and additional stakeholders suggested by the Centre) to learn about 1) Different conceptions of data quality in the humanitarian sector; 2) How users find and select data on HDX, including priority of criteria; 3) The current DPT / HDX team QA workflow with regards to assessing data quality.', 'metadata': {'coordinates': {'points': ((99.0, 219.35180000000003), (99.0, 289.15180000000004), (534.3804000000001, 289.15180000000004), (534.3804000000001, 219.35180000000003)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 5, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '56cdae409ada7bb3dafd2ae35998ce9c'}}\n",
      "{'type': 'ListItem', 'element_id': '906df042640af3c78a10d0b88bbb33be', 'text': 'Quality Measurement Prototype. Building on user research and an assessment of the state of the data and the needs in play, and using two preselected datasets as examples, we prototyped a quality measures label for HDX. The prototyping involved varying degrees of fidelity and was shaped by feedback from the Centre team.', 'metadata': {'coordinates': {'points': ((99.0, 296.85179999999997), (99.0, 366.65180000000004), (531.2711999999999, 366.65180000000004), (531.2711999999999, 296.85179999999997)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 5, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '56cdae409ada7bb3dafd2ae35998ce9c'}}\n",
      "{'type': 'ListItem', 'element_id': '8b6fed9456e9cdccc47bc3d0e2ab5416', 'text': 'Preliminary thoughts on Scalability. Through research and prototyping, we began to explore how this effort could scale, including paths toward automatability. Our findings are discussed in this report.', 'metadata': {'coordinates': {'points': ((99.0, 374.35179999999997), (99.0, 414.9518), (516.6302999999999, 414.9518), (516.6302999999999, 374.35179999999997)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 5, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '56cdae409ada7bb3dafd2ae35998ce9c'}}\n",
      "{'type': 'Title', 'element_id': 'f6adb43ed16a91054277bedd1ff0a297', 'text': 'Philosophy', 'metadata': {'coordinates': {'points': ((72.0, 440.6518), (72.0, 452.0518), (130.212, 452.0518), (130.212, 440.6518)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 5, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'a451f736770b47232e55c7283499ae6e', 'text': 'The Data Nutrition Project is a non-profit initiative that formed in 2018 to develop tools and practices to improve transparency into datasets. Our team is interdisciplinary, and we leverage insights from a variety of fields, including product development, data science, ethics, engineering, design, and education. Our approach with our Nutrition Labels for Datasets is threefold: 1) We encourage the creation, documentation, and publishing of higher quality data; 2) We enable transparency into datasets through our legible, extensible, interactive framework; and 3) Our Labels provide education about what kinds of information a user should ascertain before using a dataset. We bring this approach into our work with clients, where we prioritize user-centered design, realistic goals, and practitioner-focused outcomes, informed by our experience working in data transparency initiatives and with the real tradeoffs and tensions faced by data practitioners. In seeking to do work that is both applied and realizable, we aim to provide not only a long-term vision but also a roadmap with recommendations for future iterations of a project.', 'metadata': {'coordinates': {'points': ((72.0, 464.2518), (72.0, 665.4518), (541.7123999999999, 665.4518), (541.7123999999999, 464.2518)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 5, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'f6adb43ed16a91054277bedd1ff0a297'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '1a4265fef724ac253795fc72b25f4bcb', 'text': '1', 'metadata': {'coordinates': {'points': ((590.3384, 722.8499), (590.3384, 732.8499), (593.4984, 732.8499), (593.4984, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 5, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'f6adb43ed16a91054277bedd1ff0a297'}}\n",
      "{'type': 'Title', 'element_id': '4f3dbe9c080caaa9cfd2480b71d5bbcb', 'text': 'II. CHALLENGES', 'metadata': {'coordinates': {'points': ((259.2229, 58.38170000000002), (259.2229, 90.18170000000009), (356.73009999999994, 90.18170000000009), (356.73009999999994, 58.38170000000002)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 6, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'f2787ea76e5884fd8009fbf5ef3aad78', 'text': 'There are many challenges that can be impediments to dataset quality. This is certainly the case in the humanitarian sector, where crises unfold quickly and data capture will almost always be imperfect, often as a consequence of the need for rapid collection. Furthermore, on a more philosophical level, the assigning of rankings, scores, or grades to a dataset will always be tricky business, for the legitimacy of the scoring standards themselves can undermine the effort for scoring in the first place. We believe it is useful to explicitly enumerate these challenges before we describe our recommendations. The latter were formed in light of the former, which will be familiar to the HDX team and to others who have worked on dataset metrics, measures, and assessments.', 'metadata': {'coordinates': {'points': ((72.0, 101.3519), (72.0, 229.55200000000002), (537.4631999999999, 229.55200000000002), (537.4631999999999, 101.3519)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 6, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '4f3dbe9c080caaa9cfd2480b71d5bbcb'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'e6354cbfcb88686310b96edc3f4a2750', 'text': 'Challenge 1 - Identifying scoring methods that are succinct while not overly simplistic', 'metadata': {'coordinates': {'points': ((72.0, 255.25200000000007), (72.0, 266.65200000000004), (522.1512, 266.65200000000004), (522.1512, 255.25200000000007)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 6, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '4f3dbe9c080caaa9cfd2480b71d5bbcb'}}\n",
      "{'type': 'NarrativeText', 'element_id': '33398552639f1d933b1ba8f216f0f459', 'text': 'Scores are meant to provide information quickly and ease comparison, while inviting further exploration. They can, however, risk being reductive or overly simplistic. This is particularly difficult when comparing datasets whose provenances are entirely different. A score that is too simplistic will not only be useless but may also seem arbitrary. A single score to compare across inconsistent data types or domains may risk both. Depending on the scoring framework, there is the additional challenge of validating accuracy: what is the rubric by which this score was determined? How is accuracy of evaluation defined and ensured?', 'metadata': {'coordinates': {'points': ((72.0, 278.852), (72.0, 392.4519), (537.9083999999998, 392.4519), (537.9083999999998, 278.852)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 6, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '4f3dbe9c080caaa9cfd2480b71d5bbcb'}}\n",
      "{'type': 'NarrativeText', 'element_id': '0c36acc89c739e907e13157b857aec6d', 'text': 'Challenge 2 - Balancing scalable (quantitative) & comprehensive (qualitative) measures', 'metadata': {'coordinates': {'points': ((72.0, 418.152), (72.0, 429.552), (531.6336, 429.552), (531.6336, 418.152)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 6, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '4f3dbe9c080caaa9cfd2480b71d5bbcb'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'ed484029b165b61ca38ca846dc1708dd', 'text': 'Qualitative information helps mitigate some of the concerns above, as it is often more context-aware than quantitative statistics alone. However, qualitative information (such as detailed provenance information) is also resource-intensive to collect, often is domain-specific, and is sometimes impossible to obtain, such as when provenance is simply unknown. Conversely, quantitative measures can be easier to automate and thus easier to scale, but they can miss nuance or context that is essential to understanding the particulars of a dataset. The tension here is between usefulness and scalability; in our experience, this is the most common challenge in dataset transparency efforts.', 'metadata': {'coordinates': {'points': ((72.0, 441.752), (72.0, 555.352), (539.1311999999998, 555.352), (539.1311999999998, 441.752)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 6, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '4f3dbe9c080caaa9cfd2480b71d5bbcb'}}\n",
      "{'type': 'NarrativeText', 'element_id': '7735defe41f3807e00f729ff8032b192', 'text': 'Challenge 3 - Communicating quality to motivate rather than disincentivize', 'metadata': {'coordinates': {'points': ((72.0, 581.0519), (72.0, 592.4519), (467.8271999999997, 592.4519), (467.8271999999997, 581.0519)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 6, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '4f3dbe9c080caaa9cfd2480b71d5bbcb'}}\n",
      "{'type': 'NarrativeText', 'element_id': '30e70aef01c99d1bdeba456a44f873eb', 'text': 'Our hope is that quality measures will, in the short term, facilitate better data use choices, and in the long term motivate the creation and publishing of better quality data by changing user expectations and data collection habits. However, depending on how measures are disclosed and how scores are determined, they could discourage full transparency when sharing data in cases where increased transparency might negatively affect a score. The challenge here is to motivate better quality data without penalizing or disincentivizing current dataset owners from sharing data or disclosing shortcomings. For example, over the course of our research, a data organization voiced concern that their data was being marked incomplete even though it was as good as', 'metadata': {'coordinates': {'points': ((72.0, 604.652), (72.0, 732.852), (536.3591999999999, 732.852), (536.3591999999999, 604.652)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 6, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '4f3dbe9c080caaa9cfd2480b71d5bbcb'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '8272f65ae564038a766d59701ca35136', 'text': '2', 'metadata': {'coordinates': {'points': ((589.4884, 722.8499), (589.4884, 732.8499), (594.3484, 732.8499), (594.3484, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 6, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '4f3dbe9c080caaa9cfd2480b71d5bbcb'}}\n",
      "{'type': 'NarrativeText', 'element_id': '15f00a8b2254ba0e7506e60adb13952e', 'text': 'it possibly could have been given a particular set of circumstances. It is important to note that in some scenarios certain information cannot be ascertained and this should not reflect negatively on the quality of the dataset.', 'metadata': {'coordinates': {'points': ((72.0, 54.406600000000026), (72.0, 95.00660000000005), (531.4055999999997, 95.00660000000005), (531.4055999999997, 54.406600000000026)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 7, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '4f3dbe9c080caaa9cfd2480b71d5bbcb'}}\n",
      "{'type': 'NarrativeText', 'element_id': '0a47667dc66fba4ddf429544503aa593', 'text': 'Challenge 4 - Building a quality framework that balances flexibility with consistency', 'metadata': {'coordinates': {'points': ((72.0, 120.7066000000001), (72.0, 132.10660000000007), (513.2603999999998, 132.10660000000007), (513.2603999999998, 120.7066000000001)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 7, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '4f3dbe9c080caaa9cfd2480b71d5bbcb'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'd79d88f51e9d7d0e09195e5ca05fee4e', 'text': 'As the humanitarian sector changes over time with respect to crises and data needs, any discrete quality metrics will also likely change. For these reasons, whatever is built will need to be adaptable. However, consistency is also important, so that datasets from different time periods can be compared, and so that dataset owners and site visitors can develop familiarity and comfort with the site. For example, when and how do existing datasets get re-evaluated under updated scoring rubrics? What is the right approach to keeping information up to date (timely and punctual) that will be both robust and scalable across thousands of datasets? When or how will that score be altered or downgraded as time goes on?', 'metadata': {'coordinates': {'points': ((72.0, 144.3066), (72.0, 272.50660000000005), (542.5895999999998, 272.50660000000005), (542.5895999999998, 144.3066)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 7, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '4f3dbe9c080caaa9cfd2480b71d5bbcb'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'f1354ede5ca13da0deb5c771ea1638c9', 'text': 'Challenge 5 - Determining responsibilities within the data pipeline', 'metadata': {'coordinates': {'points': ((72.0, 298.2066), (72.0, 309.6066), (421.7495999999997, 309.6066), (421.7495999999997, 298.2066)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 7, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '4f3dbe9c080caaa9cfd2480b71d5bbcb'}}\n",
      "{'type': 'NarrativeText', 'element_id': '90c0d6f13d0a283ae86a23c13037ec75', 'text': 'HDX is committed to hosting good quality data, and requires QA and other data onboarding processes. However, HDX, like all organizations in the humanitarian sector, has limited resources, with respect to time and personnel for validating datasets. Furthermore, even if there were no resource constraints, there are always knowledge gaps between on-the-ground domain expertise and data experts looking at raw or processed data. This challenge is shared among all data validation efforts, and it might be even more drastic in the domain of humanitarian data, where data collection methods require agility, and thus context-awareness and domain knowledge is essential for accurately interpreting or validating the data. However, HDX is extremely well- positioned to build a process, and for that process to incorporate shared responsibility for data-validation, as we discuss below.', 'metadata': {'coordinates': {'points': ((72.0, 321.8066), (72.0, 479.20660000000004), (542.0363999999998, 479.20660000000004), (542.0363999999998, 321.8066)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 7, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '4f3dbe9c080caaa9cfd2480b71d5bbcb'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'c3b597bc3a8c5f3cbcb7296c1b06d527', 'text': '3', 'metadata': {'coordinates': {'points': ((589.4384, 722.8499), (589.4384, 732.8499), (594.3984, 732.8499), (594.3984, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 7, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '4f3dbe9c080caaa9cfd2480b71d5bbcb'}}\n",
      "{'type': 'Title', 'element_id': '9ff8ce2d84c7567ad00dd8641f82e578', 'text': 'III. KEY FINDINGS', 'metadata': {'coordinates': {'points': ((256.0582, 58.381599999999935), (256.0582, 90.1816), (355.9342, 90.1816), (355.9342, 58.381599999999935)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 8, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'NarrativeText', 'element_id': '7bb33759421ab3b3bdf40fb9d919902e', 'text': 'The five-week sprint gave rise to a number of key findings, which informed our final designs and recommendations.', 'metadata': {'coordinates': {'points': ((72.0, 101.35180000000003), (72.0, 127.3519), (515.2295999999998, 127.3519), (515.2295999999998, 101.35180000000003)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 8, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '9ff8ce2d84c7567ad00dd8641f82e578'}}\n",
      "{'type': 'NarrativeText', 'element_id': '9f93a7a8731924825031fddc8ca9189d', 'text': 'Finding 1 - HDX is best positioned to define rather than assess quality', 'metadata': {'coordinates': {'points': ((123.5674, 154.93360000000007), (123.5674, 166.33360000000005), (494.5053999999999, 166.33360000000005), (494.5053999999999, 154.93360000000007)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 8, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '9ff8ce2d84c7567ad00dd8641f82e578'}}\n",
      "{'type': 'NarrativeText', 'element_id': '54c2ee62fa024eee4c37ec4162cfc77b', 'text': 'Due to the range of dataset types on HDX, limitations of domain knowledge, and resource constraints, HDX is not well positioned to conduct quality assessments for all datasets on its platform, and instead, HDX should focus that attention to data types or categories that have been defined as critical, such as the Data Grids. HDX is best positioned to', 'metadata': {'coordinates': {'points': ((90.0, 178.5336000000001), (90.0, 248.33360000000005), (519.4511999999997, 248.33360000000005), (519.4511999999997, 178.5336000000001)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 8, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '9ff8ce2d84c7567ad00dd8641f82e578'}}\n",
      "{'type': 'ListItem', 'element_id': '41c892e64efd06d595842a2500c34f7e', 'text': '1) Define the framework for quality of datasets on HDX (meaning define what is getting collected and assessed);', 'metadata': {'coordinates': {'points': ((112.5, 260.5336000000001), (112.5, 286.53360000000004), (500.1936, 286.53360000000004), (500.1936, 260.5336000000001)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 8, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '9ff8ce2d84c7567ad00dd8641f82e578'}}\n",
      "{'type': 'ListItem', 'element_id': '1e1619630a3b6df040c98da8bd85829f', 'text': '2) Facilitate the gathering of this information from data organizations;', 'metadata': {'coordinates': {'points': ((112.5, 298.73359999999997), (112.5, 310.1336), (480.54839999999984, 310.1336), (480.54839999999984, 298.73359999999997)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 8, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '9ff8ce2d84c7567ad00dd8641f82e578'}}\n",
      "{'type': 'ListItem', 'element_id': '0e21710a20a4e0e98b4747eb48c166a5', 'text': '3) Provide a display of this information to data users on HDX, designed in alignment with user needs.', 'metadata': {'coordinates': {'points': ((112.5, 322.3336), (112.5, 348.3336), (490.53360000000015, 348.3336), (490.53360000000015, 322.3336)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 8, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '9ff8ce2d84c7567ad00dd8641f82e578'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'c84213f2707159c963c8cdad7a7e0419', 'text': 'Finding 2 - There is an opportunity to leverage existing quality measures', 'metadata': {'coordinates': {'points': ((116.3975, 397.6336), (116.3975, 409.03360000000004), (498.64309999999983, 409.03360000000004), (498.64309999999983, 397.6336)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 8, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '9ff8ce2d84c7567ad00dd8641f82e578'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'cc4f92b839b04d95620afc6c0af57033', 'text': 'Data quality assessment is already conducted on HDX, albeit at different times and displayed or communicated in disparate regions of the site. This provides an opportunity, as a first step, to aggregate, prioritize, and organize information that has already been gathered. Further ambitions to collect and validate data that is not currently collected should come only after the current effort to bring transparency and legibility to the valuable information that HDX already collects. It is our belief that a phased approach, starting with the information already collected, and expanding out from there to leverage the credibility of data organizations, will be most suitable to HDXs current infrastructure.', 'metadata': {'coordinates': {'points': ((90.0, 421.23359999999997), (90.0, 549.4336), (517.5443999999997, 549.4336), (517.5443999999997, 421.23359999999997)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 8, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '9ff8ce2d84c7567ad00dd8641f82e578'}}\n",
      "{'type': 'NarrativeText', 'element_id': '80d61c0a4a8aaf754635b02024c2cc2d', 'text': 'Finding 3 - Domain experts and third-party validators can provide complementary value', 'metadata': {'coordinates': {'points': ((133.713, 598.7336), (133.713, 624.7336), (481.3278000000001, 624.7336), (481.3278000000001, 598.7336)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 8, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '9ff8ce2d84c7567ad00dd8641f82e578'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'dc745d004a5a7a5ec80d7043e5b9e8c2', 'text': 'Due to the variety of data types and domains on HDX, data content quality assessment is likely to require verticalization (e.g. different approaches for GIS data, CODs, etc). Considering the ranges of domain expertise required, and the limited bandwidth on the Centre team, our recommendation, as stated in Finding 1, is that the Centre define the parameters of quality through a set of extended metadata that is to be displayed HDX, and then work with data', 'metadata': {'coordinates': {'points': ((90.0, 636.9336000000001), (90.0, 721.3336), (505.2671999999999, 721.3336), (505.2671999999999, 636.9336000000001)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 8, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '9ff8ce2d84c7567ad00dd8641f82e578'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '4b2fc45583800df1d2f02c095e87f2dd', 'text': '4', 'metadata': {'coordinates': {'points': ((589.3984, 722.8499), (589.3984, 732.8499), (594.4384, 732.8499), (594.4384, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 8, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '9ff8ce2d84c7567ad00dd8641f82e578'}}\n",
      "{'type': 'NarrativeText', 'element_id': '5bf6c6ae71f1d172dbfa6613e0481807', 'text': 'owners and third-party assessors who will be the ones to contribute much of this extended metadata. This would follow HDXs work to aggregate the information already collected, and determine the best design approach for communicating this information to users. Many data organizations have quality frameworks or assessments for their own data, and these could be indicated on HDX to communicate things like known issues and certain strengths of a dataset within its domain. Working in collaboration with these organizations can lend institutional validation to these quality frameworks  which, either independently or alongside additional support, could motivate third parties to work with HDX  and would provide domain expertise to HDX and its users. Using these external third-party-determined metrics also encourages other organizations to consider adapting their use frameworks to include quality, which can drive cultural change around responsible data usage.', 'metadata': {'coordinates': {'points': ((90.0, 65.2066000000001), (90.0, 251.8066), (522.4163999999998, 251.8066), (522.4163999999998, 65.2066000000001)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 9, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '9ff8ce2d84c7567ad00dd8641f82e578'}}\n",
      "{'type': 'NarrativeText', 'element_id': '9d256abe5eff73bea8c361ecb2d67cdf', 'text': 'Finding 4 - Automation of QA and assessment tasks can enable scale', 'metadata': {'coordinates': {'points': ((124.0408, 301.1065), (124.0408, 312.5065), (490.99839999999995, 312.5065), (490.99839999999995, 301.1065)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 9, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '9ff8ce2d84c7567ad00dd8641f82e578'}}\n",
      "{'type': 'NarrativeText', 'element_id': '0bfe887e552f967c84cd59952cf4c6e1', 'text': 'While there is some initial groundwork required to prepare for automating certain QA tasks, we believe that HDX investing the time to move in this direction will, in the long run, enable quality measures to be assessed and applied at scale. For example, automating the collection of certain metadata (such as restrictions around API use, required metadata through API collection, or requiring the use of HXL) can make it easier to enforce and collect technical quality information about datasets. We know that HDX has done a lot of work toward formatting datasets into HXL and advocating for others to do the same. We understand that this is no small feat, but if HXL can be more widely adopted, this would enable greater interoperability, comparability, and analysis.', 'metadata': {'coordinates': {'points': ((90.0, 324.7066), (90.0, 467.5065), (525.3023999999998, 467.5065), (525.3023999999998, 324.7066)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 9, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '9ff8ce2d84c7567ad00dd8641f82e578'}}\n",
      "{'type': 'NarrativeText', 'element_id': '9a882a5bdf0571def7fe460596edb2dd', 'text': 'Finding 5 - Primary use case is data selection, which can ultimately be supported through metrics comparison', 'metadata': {'coordinates': {'points': ((122.0186, 516.8066), (122.0186, 542.8066), (493.0189999999998, 542.8066), (493.0189999999998, 516.8066)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 9, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '9ff8ce2d84c7567ad00dd8641f82e578'}}\n",
      "{'type': 'NarrativeText', 'element_id': '6d0dad7508b6507c327c38edc8ce55da', 'text': 'Through our conversations and interviews, we learned that the primary reason for having quality measures included on the platform is to improve dataset selection, with additional use cases including dataset comparison (choosing among several on HDX, wanting to quickly ascertain which is better for a certain need) or dataset combination (merging several to cover a bigger geographic region or to otherwise extend a particular dataset). The availability of legible, digestible measures, such as format, update frequency, and uses and restrictions, permits users to quickly scan for their particular needs. We recommend prioritizing information that is already available, and in later phases collecting (and collaborating with others to collect) additional information that can bring even more value to dataset users.', 'metadata': {'coordinates': {'points': ((90.0, 555.0065), (90.0, 712.4065), (525.2868000000001, 712.4065), (525.2868000000001, 555.0065)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 9, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '9ff8ce2d84c7567ad00dd8641f82e578'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'd21545d3c64833dd0313ec8c606d1bbc', 'text': '5', 'metadata': {'coordinates': {'points': ((589.4183, 722.8499), (589.4183, 732.8499), (594.4183, 732.8499), (594.4183, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 9, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '9ff8ce2d84c7567ad00dd8641f82e578'}}\n",
      "{'type': 'Title', 'element_id': 'f5aa4911585dde9b46a8b68148c3a500', 'text': 'IV. APPROACH & DIRECTIONS', 'metadata': {'coordinates': {'points': ((213.4031, 58.381599999999935), (213.4031, 90.1816), (398.6090999999999, 90.1816), (398.6090999999999, 58.381599999999935)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 10, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'NarrativeText', 'element_id': '84c30aa1ef3f74e26c379308d5ed54a0', 'text': 'We explored quality measures on the HDX platform through a tailored 5-week discovery sprint in a three-part inquiry: 1) Researching data quality principles in the context of humanitarian data and the existing platform; 2) Developing several prototype directions building on this principles-based foundation drawing on our expertise in data quality labels; 3) Refining our direction and recommended implementation strategy based on feedback from the Centre.', 'metadata': {'coordinates': {'points': ((72.0, 101.35180000000003), (72.0, 185.7518), (541.8936000000001, 185.7518), (541.8936000000001, 101.35180000000003)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 10, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'f5aa4911585dde9b46a8b68148c3a500'}}\n",
      "{'type': 'Title', 'element_id': 'c5385af7b906d0fd19d7f05c829cc212', 'text': 'Research', 'metadata': {'coordinates': {'points': ((72.0, 211.45190000000002), (72.0, 222.8519), (124.42800000000001, 222.8519), (124.42800000000001, 211.45190000000002)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 10, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'NarrativeText', 'element_id': '1b1185e0e1c3339730709cec08c79b69', 'text': 'Our team spent the first two weeks researching background materials and interviewing diverse stakeholders. We read and analyzed approximately a dozen reports about data quality principles in the humanitarian sector (published by HDX, UNICEF, UK AID, IOM, OCHA, ICRC, GAHI, DSEG, GSQAF, including others) in order to build an understanding of quality measures on the HDX platform. We sketched a matrix aligning and comparing principles across several major organizations (compared primarily to GDQAF principles, which were most commonly cited as baseline) in order to better understand these concepts in the context of HDX (fig. 1). Notably, we saw a gap in the literature published by HDX around credibility, so we sketched this into the matrix (in light blue).', 'metadata': {'coordinates': {'points': ((72.0, 235.05180000000007), (72.0, 363.2518), (543.3023999999998, 363.2518), (543.3023999999998, 235.05180000000007)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 10, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'c5385af7b906d0fd19d7f05c829cc212'}}\n",
      "{'type': 'NarrativeText', 'element_id': '9213c20e9e4a07f0e0234d5708e7b4a2', 'text': 'In parallel, we conducted interviews with stakeholders that represented key points along the data collection, processing, hosting, and use timeline, including data partners (IOM, Humanitarian OpenStreetMap Team) and several within the Centre (Data Partnerships, Data Responsibility, organization onboarding, product development, quality assessment process, and others), in order to understand how the Centre thinks about quality, to learn about existing mechanisms for identifying and surfacing quality issues, and to explore future scenarios for expanding or adjusting quality assessment practices.', 'metadata': {'coordinates': {'points': ((72.0, 375.45189999999997), (72.0, 474.4518), (542.5524, 474.4518), (542.5524, 375.45189999999997)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 10, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'c5385af7b906d0fd19d7f05c829cc212'}}\n",
      "{'type': 'NarrativeText', 'element_id': '9406d1b9d597e90ef22aab34e2716a43', 'text': 'Figure 1. Matrix aligning data', 'metadata': {'coordinates': {'points': ((396.6143, 653.254), (396.6143, 662.754), (526.3613, 662.754), (526.3613, 653.254)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 10, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'c5385af7b906d0fd19d7f05c829cc212'}}\n",
      "{'type': 'Title', 'element_id': 'f71f522ace698a5ffba60f9f4e196830', 'text': 'quality principles across several', 'metadata': {'coordinates': {'points': ((396.6143, 667.8541), (396.6143, 677.3541), (542.7403000000002, 677.3541), (542.7403000000002, 667.8541)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 10, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '522131c921ac9bd4dd004cc36fe96f9a', 'text': 'organizations, with HDX in blue.', 'metadata': {'coordinates': {'points': ((396.6143, 682.454), (396.6143, 691.954), (541.4223000000001, 691.954), (541.4223000000001, 682.454)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 10, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'NarrativeText', 'element_id': '7184ac0c3a8e32be07b3032b0990fc38', 'text': 'Full size matrix included in', 'metadata': {'coordinates': {'points': ((396.6143, 697.0541000000001), (396.6143, 706.5541000000001), (517.8513, 706.5541000000001), (517.8513, 697.0541000000001)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 10, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '522131c921ac9bd4dd004cc36fe96f9a'}}\n",
      "{'type': 'Title', 'element_id': '2323610f4922a7ea8a07958c8d3aa59c', 'text': 'appendix.', 'metadata': {'coordinates': {'points': ((396.6143, 711.654), (396.6143, 721.154), (440.78330000000005, 721.154), (440.78330000000005, 711.654)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 10, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'fb3eb0ff9368ce1eb70b94cdc092eccd', 'text': '6', 'metadata': {'coordinates': {'points': ((589.3584, 722.8499), (589.3584, 732.8499), (594.4784, 732.8499), (594.4784, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 10, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '2323610f4922a7ea8a07958c8d3aa59c'}}\n",
      "{'type': 'Title', 'element_id': '052638895e5fe606d204615662b4dc10', 'text': 'Prototype directions', 'metadata': {'coordinates': {'points': ((72.0, 54.406600000000026), (72.0, 65.8066), (181.55880000000002, 65.8066), (181.55880000000002, 54.406600000000026)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 11, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'febc542c0ea9994b740bd86d02852f0b', 'text': 'Based on the research and interviews conducted in the first two weeks of our sprint, the DNP team developed four potential paths forward to highlight specific data quality principles. These were:', 'metadata': {'coordinates': {'points': ((72.0, 78.00660000000005), (72.0, 118.60660000000007), (531.7139999999997, 118.60660000000007), (531.7139999999997, 78.00660000000005)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 11, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '052638895e5fe606d204615662b4dc10'}}\n",
      "{'type': 'ListItem', 'element_id': 'b3e3b6d3c58a1fda83d9895e0a15a0df', 'text': '1.\\t Comparability:\\tfeatures\\tto\\tsupport\\tdataset\\tselection', 'metadata': {'coordinates': {'points': ((85.5, 139.8066), (85.5, 151.20659999999998), (412.19640000000004, 151.20659999999998), (412.19640000000004, 139.8066)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 11, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '052638895e5fe606d204615662b4dc10'}}\n",
      "{'type': 'NarrativeText', 'element_id': '77829acf3e10ff3da010641f1ad7a4ae', 'text': 'Throughout the interviews, we heard that a primary use case for data quality assessment on HDX (and more broadly in the sector) was the enabling of dataset selection, either for a particular need at hand, to join with other external or proprietary data (e.g. Combine several datasets about a particular geography), or to compare against similar datasets to assess which is best aligned for a particular use (e.g. Identifying which administrative boundary dataset is appropriate if there are several to choose from). To support this particular use case of dataset selection, which we felt was best aligned to the data principle of comparability, we proposed features that support the direct comparing and contrasting of datasets based on metadata comparison (fig. 2)', 'metadata': {'coordinates': {'points': ((72.0, 163.40660000000003), (72.0, 291.6066), (539.2307999999998, 291.6066), (539.2307999999998, 163.40660000000003)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 11, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '052638895e5fe606d204615662b4dc10'}}\n",
      "{'type': 'Title', 'element_id': '74d8486f67953c98e4ea958445df8961', 'text': 'Figure 2. Prototype', 'metadata': {'coordinates': {'points': ((416.88, 494.00879999999995), (416.88, 503.50879999999995), (507.55800000000005, 503.50879999999995), (507.55800000000005, 494.00879999999995)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 11, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': 'f381fb1c64391db3ec570c29d8a489f0', 'text': 'sketches of features to', 'metadata': {'coordinates': {'points': ((416.88, 508.6088), (416.88, 518.1088), (520.378, 518.1088), (520.378, 508.6088)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 11, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': 'eac9690998f91e1f7ef6a5f3e20a245f', 'text': 'support the comparing and', 'metadata': {'coordinates': {'points': ((416.88, 523.2088), (416.88, 532.7088), (542.6980000000001, 532.7088), (542.6980000000001, 523.2088)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 11, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '73db64457ad8c76e20a2b0a0aaced063', 'text': 'contrasting of metadata on', 'metadata': {'coordinates': {'points': ((416.88, 537.8088), (416.88, 547.3088), (539.928, 547.3088), (539.928, 537.8088)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 11, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '107ed0ef34a791ea428789b964fc88b1', 'text': 'similar datasets.', 'metadata': {'coordinates': {'points': ((416.88, 552.4088), (416.88, 561.9088), (490.719, 561.9088), (490.719, 552.4088)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 11, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'ListItem', 'element_id': '50fad5b45c9599ed1e2a45f731f513b1', 'text': '2.\\t Credibility:\\tleveraging\\ttrust\\tin\\torganizations', 'metadata': {'coordinates': {'points': ((85.5, 592.6066000000001), (85.5, 604.0065999999999), (362.9628, 604.0065999999999), (362.9628, 592.6066000000001)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 11, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '107ed0ef34a791ea428789b964fc88b1'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'b2acb6b2935dfd6263b0c84bee259937', 'text': 'From the earliest conversations, data organizations and the Centre teams stressed the critical dependency between data quality and data collection and processing practices. In fact, although there were several measures and principles of data quality that came after the processing of the data  such as freshness, accessibility, and interpretability  some of the most salient measures could only be assessed by those most familiar with the origin of the data itself (fig. 3). This highlighted not only the importance of but also the reliance upon data organizations to help surface data quality on HDX.', 'metadata': {'coordinates': {'points': ((72.0, 616.2066), (72.0, 715.2066), (542.3087999999999, 715.2066), (542.3087999999999, 616.2066)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 11, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '107ed0ef34a791ea428789b964fc88b1'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '9c6da5955548948a6135ca35f97ef3e2', 'text': '7', 'metadata': {'coordinates': {'points': ((589.6384, 722.8499), (589.6384, 732.8499), (594.1984, 732.8499), (594.1984, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 11, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '107ed0ef34a791ea428789b964fc88b1'}}\n",
      "{'type': 'NarrativeText', 'element_id': '67515a9042dd9c96c6ce3afc3527026a', 'text': 'Figure 3. Aligning the data pipeline to quality principles and responsible parties highlights the critical', 'metadata': {'coordinates': {'points': ((72.0, 318.5788), (72.0, 328.0788), (524.0889999999999, 328.0788), (524.0889999999999, 318.5788)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 12, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '107ed0ef34a791ea428789b964fc88b1'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '9f6e5d4853d5019cb2ada7fc90b5d104', 'text': 'relationship between the data organization and HDX for the assessment and communication of data', 'metadata': {'coordinates': {'points': ((72.0, 333.17879999999997), (72.0, 342.67879999999997), (523.5699999999998, 342.67879999999997), (523.5699999999998, 333.17879999999997)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 12, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '107ed0ef34a791ea428789b964fc88b1'}}\n",
      "{'type': 'Title', 'element_id': 'd8578d1b3aa70d4c1b08031c0d332863', 'text': 'quality.', 'metadata': {'coordinates': {'points': ((72.0, 347.77889999999996), (72.0, 357.27889999999996), (103.149, 357.27889999999996), (103.149, 347.77889999999996)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 12, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'NarrativeText', 'element_id': '5886e44ba4660dc4710c957eed3cf0d9', 'text': 'Our second prototype aimed to leverage trust in organizations based on their data practices and commitment to data quality as a proxy for the data quality principle of credibility. For this approach, our recommendation (which follows the initial work performed by DNP team member and 2021 Strategic Communications Data Fellow Kasia Chmielinski), HDX would build a framework for organization trust levels that signal an active, relational approach towards quality: one that depends on the organization that produces or publishes the dataset. Datasets would then qualitatively inherit the credibility from the organization that produced them, with the organization serving as a proxy for responsible data collection and processing practices (fig. 4).', 'metadata': {'coordinates': {'points': ((72.0, 378.9767), (72.0, 507.1766), (529.3259999999998, 507.1766), (529.3259999999998, 378.9767)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 12, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'd8578d1b3aa70d4c1b08031c0d332863'}}\n",
      "{'type': 'Title', 'element_id': 'eda57cdf527e4a29fae33f67d883d191', 'text': 'Figure 4. Prototype sketches of a dataset with a', 'metadata': {'coordinates': {'points': ((322.218, 683.7789), (322.218, 693.2789), (537.1840000000001, 693.2789), (537.1840000000001, 683.7789)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 12, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': 'abadfaea909d2dcc31c5988c0beded57', 'text': 'level 3 trust organization indicator as a proxy', 'metadata': {'coordinates': {'points': ((322.218, 698.3788), (322.218, 707.8788), (531.264, 707.8788), (531.264, 698.3788)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 12, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': 'cfb3c39b2c1f439a67fc2248ba86905e', 'text': 'for the data quality principle of credibility.', 'metadata': {'coordinates': {'points': ((322.218, 712.9789000000001), (322.218, 722.4789000000001), (506.2160000000001, 722.4789000000001), (506.2160000000001, 712.9789000000001)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 12, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'f89730b89a8962b96dfc26b657979e2d', 'text': '8', 'metadata': {'coordinates': {'points': ((589.4183, 722.8499), (589.4183, 732.8499), (594.4183, 732.8499), (594.4183, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 12, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'cfb3c39b2c1f439a67fc2248ba86905e'}}\n",
      "{'type': 'ListItem', 'element_id': '0ecccd1eab1872c422c6f877df9e7793', 'text': '3.\\t Completeness,\\ttimeliness:\\tassessing\\tmetadata\\tcompleteness', 'metadata': {'coordinates': {'points': ((85.5, 54.406600000000026), (85.5, 65.8066), (467.02440000000007, 65.8066), (467.02440000000007, 54.406600000000026)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 13, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'cfb3c39b2c1f439a67fc2248ba86905e'}}\n",
      "{'type': 'NarrativeText', 'element_id': '85bb93b9c78e5476098d4bd14d2c2384', 'text': 'The last two prototype directions are related to fitness for purpose - assessing whether what is represented in the dataset is appropriate for use (complete, timely, relevant, accurate). We found fitness for purpose metrics to be the most challenging due to the distribution of responsibility in dataset management, and the realities of data collection in humanitarian situations. Stated simply, it is very hard to assess quality without an ideal ground truth dataset against which to compare, or without access to information about the collection and processing practices of the data owner. To facilitate our analysis, we approached these measures along two axes: the assessor (data owner vs. third party), and the type of assessment (qualitative vs. quantitative) (fig. 5). The resulting matrix helps clarify four directions: qualitative (not easily scorable) assessment at two levels of granularity, where the data owner can be much more detailed than a third party, and two quantitative (more easily scored or ranked) approaches, one domain- specific (e.g. GIS data quality, ranked by the data owner) and the other focused on adherence to a metadata or technical standard (e.g. metadata completeness, in this case conducted by HDX).', 'metadata': {'coordinates': {'points': ((72.0, 78.00660000000005), (72.0, 293.8066), (542.0682999999999, 293.8066), (542.0682999999999, 78.00660000000005)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 13, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'cfb3c39b2c1f439a67fc2248ba86905e'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'e552ba5b90a439df109699f7c29ac5fc', 'text': 'Building off this analysis, our third prototype direction falls within the third-party quantitative assessment for completeness and timeliness: measuring and reporting adherence to standards of metadata completeness. This version, along with the former (Credibility of Trusted Orgs) and the one that follows, combine for our recommendation to the Centre team. In this version, HDX builds a framework of expectations of metadata standards and provides a score or indicator on whether a dataset meets that standard. For example, HDX could incentivize higher data quality through a measurement that assigns a higher score (or ranking) for the use of automatic data submission, the use of standard data elements (such as P-codes or HXL), or attestation of a third party review. For simplicity of communication, these metadata could be categorized into sections (such as Trust, Content Quality, Uses, etc.) (fig. 6).', 'metadata': {'coordinates': {'points': ((72.0, 306.0066), (72.0, 463.4066), (539.0375999999999, 463.4066), (539.0375999999999, 306.0066)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 13, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'cfb3c39b2c1f439a67fc2248ba86905e'}}\n",
      "{'type': 'NarrativeText', 'element_id': '48f30aaf955fc85cad260061ca325dbe', 'text': 'Figure 5 (left). Quadrant analysis of fitness for purpose', 'metadata': {'coordinates': {'points': ((72.0, 637.6088), (72.0, 647.1088), (308.8451999999999, 647.1088), (308.8451999999999, 637.6088)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 13, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'cfb3c39b2c1f439a67fc2248ba86905e'}}\n",
      "{'type': 'Title', 'element_id': '30fbd332caab4660ef6dccc6575805d9', 'text': 'measures along two axes: responsible party (data owner /', 'metadata': {'coordinates': {'points': ((72.0, 652.2088), (72.0, 661.7088), (324.565, 661.7088), (324.565, 652.2088)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 13, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '9127647a348881ca96051f8b9596eb16', 'text': 'third-party) and type of measure (qualitative / quantitative).', 'metadata': {'coordinates': {'points': ((72.0, 666.8088), (72.0, 676.3088), (327.306, 676.3088), (327.306, 666.8088)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 13, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'adc8526306a31cba70067c1040fab758', 'text': 'Figure 6 (right). Prototype for a quality label that', 'metadata': {'coordinates': {'points': ((72.0, 690.4088), (72.0, 699.9088), (294.915, 699.9088), (294.915, 690.4088)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 13, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '9127647a348881ca96051f8b9596eb16'}}\n",
      "{'type': 'Title', 'element_id': '0424791a6d8d4c5288b7ca3cccc126cc', 'text': 'assesses and highlights metadata completeness across a', 'metadata': {'coordinates': {'points': ((72.0, 705.0088000000001), (72.0, 714.5088000000001), (333.12400000000014, 714.5088000000001), (333.12400000000014, 705.0088000000001)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 13, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': 'c9f0316ea3501dc5e0744ffa17116f56', 'text': 'number of categories and against a common framework.', 'metadata': {'coordinates': {'points': ((72.0, 719.6088), (72.0, 729.1088), (328.99399999999997, 729.1088), (328.99399999999997, 719.6088)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 13, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '4233cc3b3dcb79daf51f6349c99dfcbd', 'text': '9', 'metadata': {'coordinates': {'points': ((589.3234, 722.8499), (589.3234, 732.8499), (594.5134, 732.8499), (594.5134, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 13, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'c9f0316ea3501dc5e0744ffa17116f56'}}\n",
      "{'type': 'ListItem', 'element_id': 'd011cd0b00f82862e0354376ae5fb986', 'text': '4.\\t Relevance,\\taccuracy:\\tassessing\\tfitness\\tfor\\tpurpose', 'metadata': {'coordinates': {'points': ((85.5, 54.406600000000026), (85.5, 65.8066), (410.35200000000003, 65.8066), (410.35200000000003, 54.406600000000026)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 14, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'c9f0316ea3501dc5e0744ffa17116f56'}}\n",
      "{'type': 'NarrativeText', 'element_id': '7943a6f5466a275abe551075c1dff7bc', 'text': 'The final prototype approach, assessing fitness for purpose in alignment with data principles relevance and accuracy, most likely requires direct input from the data owner or a party that is familiar with the entire lifecycle of data collection and processing (see the left hand side of the quadrant matrix fig. 5). This is because it is extremely difficult, if not impossible, to understand the quality of content contained within a dataset without understanding the context in which it was gathered, processed, and how it will be used. This requires both knowledge of the data collection process as well as significant domain expertise.', 'metadata': {'coordinates': {'points': ((72.0, 78.00660000000005), (72.0, 191.60660000000007), (541.6656000000002, 191.60660000000007), (541.6656000000002, 78.00660000000005)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 14, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'c9f0316ea3501dc5e0744ffa17116f56'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'fdc0849441597627c827ed87347c7de5', 'text': 'Our suggestion for this approach is thus to acknowledge the dependency between HDX and the data owner (organization) and leverage structured frameworks for the communication of dataset quality information. For example, HDX could partner with third party organizations that certify certain data quality domains (e.g. GIS data, CODs, boundary data, education or health data) and when datasets achieve that certification, HDX could communicate that information on the platform. In some instances, HDX may also be a certifier  the Data Grids are a good example of this  but for the sake of scaling, expanding to third party certifications will be less resource-intensive and more applicable to the breadth of datasets within the HDX platform. An additional option might be for HDX to work with particular data organizations to surface their internal quality measures through standardized metadata fields that, while not consistent with respect to content across data organizations, would be a consistent field that appears on all datasets regardless of organization or domain (e.g. a domain-specific quality measure field that could be defined differently across organizations and domains). For example, in the figure below (fig. 7), HDX has defined a portion of the metadata structure to include both a self-reported QA adherence from the Data Organization as well as a domain-specific metric built by a third party.', 'metadata': {'coordinates': {'points': ((72.0, 203.8066), (72.0, 448.8066), (540.5817000000002, 448.8066), (540.5817000000002, 203.8066)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 14, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'c9f0316ea3501dc5e0744ffa17116f56'}}\n",
      "{'type': 'Title', 'element_id': 'f6ab66c4f92a68b7657436308da7d06d', 'text': 'Figure 7. Prototype sketch of Content', 'metadata': {'coordinates': {'points': ((351.3701, 589.4088), (351.3701, 598.9088), (519.5291, 598.9088), (519.5291, 589.4088)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 14, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'NarrativeText', 'element_id': '9a31814b7f5ef2ffc1f66e6c0840d6bf', 'text': 'Quality Measures that include quality', 'metadata': {'coordinates': {'points': ((351.3701, 604.0088000000001), (351.3701, 613.5088000000001), (521.3361, 613.5088000000001), (521.3361, 604.0088000000001)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 14, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'f6ab66c4f92a68b7657436308da7d06d'}}\n",
      "{'type': 'Title', 'element_id': 'fa41e4a0fc66fd6679f3756772452e06', 'text': 'certifications from HDX, Data Org', 'metadata': {'coordinates': {'points': ((351.3701, 618.6088), (351.3701, 628.1088), (504.35710000000006, 628.1088), (504.35710000000006, 618.6088)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 14, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '419019622a0b0eb37e8aa0044417dacd', 'text': '/ Owner and Third-Party expert', 'metadata': {'coordinates': {'points': ((351.3701, 633.2088), (351.3701, 642.7088), (496.8361, 642.7088), (496.8361, 633.2088)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 14, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'NarrativeText', 'element_id': '6ff055984d425ccafe194ec3693228d8', 'text': 'organizations. These could be binary', 'metadata': {'coordinates': {'points': ((351.3701, 647.8088), (351.3701, 657.3088), (519.6061, 657.3088), (519.6061, 647.8088)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 14, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '419019622a0b0eb37e8aa0044417dacd'}}\n",
      "{'type': 'Title', 'element_id': '0348da611d546bddb12ed5a695efd799', 'text': '(pass / fail) or quantitative (e.g. a score).', 'metadata': {'coordinates': {'points': ((351.3701, 662.4087999999999), (351.3701, 671.9088), (531.7371, 671.9088), (531.7371, 662.4087999999999)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 14, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '9bf0bfd5131a7c81d1d5c5a41f3d9ad0', 'text': '10', 'metadata': {'coordinates': {'points': ((587.6735, 722.8499), (587.6735, 732.8499), (596.1635, 732.8499), (596.1635, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 14, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '0348da611d546bddb12ed5a695efd799'}}\n",
      "{'type': 'Title', 'element_id': 'f4c31c4d6841b5695b6deb30eb355196', 'text': 'V. RECOMMENDATIONS & DESIGNS', 'metadata': {'coordinates': {'points': ((189.6864, 58.381599999999935), (189.6864, 90.1816), (422.3313999999998, 90.1816), (422.3313999999998, 58.381599999999935)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 15, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': '05c6b74e951c6c9ad8e2e3cec897dc6b', 'text': 'Recommendations', 'metadata': {'coordinates': {'points': ((72.0, 114.85180000000003), (72.0, 126.2518), (170.868, 126.2518), (170.868, 114.85180000000003)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 15, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'bd8438b6c04574d0df38f9ec935232a8', 'text': 'From our four prototype directions outlined above, and integrating feedback from the Centre team, we recommend a combination of prototype directions 2, 3, and 4, organized into three phases of work. Detailed work plans and sketches for Phase 1 are included in this report.', 'metadata': {'coordinates': {'points': ((72.0, 138.45190000000002), (72.0, 193.65179999999998), (531.1992000000001, 193.65179999999998), (531.1992000000001, 138.45190000000002)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 15, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '05c6b74e951c6c9ad8e2e3cec897dc6b'}}\n",
      "{'type': 'NarrativeText', 'element_id': '1d032244fb3f2ff0e7008b3624d7c223', 'text': 'We also share recommendations for how to approach the continuation of these explorations in Phases 2 and 3, and include a preview (low fidelity sketch) of how extended information that might be included in Phase 3 could appear on HDX. The phased approach enables HDX to prioritize the information that is already available, while beginning to build an on-ramp for further work that will require additional resources and infrastructure. A summary of the phases is included below, and discussed in more detail in Section VI.', 'metadata': {'coordinates': {'points': ((72.0, 205.85180000000003), (72.0, 304.8519), (542.4815999999998, 304.8519), (542.4815999999998, 205.85180000000003)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 15, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '05c6b74e951c6c9ad8e2e3cec897dc6b'}}\n",
      "{'type': 'NarrativeText', 'element_id': '39e9c98c11920d6081a15cf01b271980', 'text': 'Phase 1 - Fully scoped, ready to implement', 'metadata': {'coordinates': {'points': ((193.9937, 328.72659999999996), (193.9937, 340.1266), (418.0085, 340.1266), (418.0085, 328.72659999999996)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 15, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '05c6b74e951c6c9ad8e2e3cec897dc6b'}}\n",
      "{'type': 'NarrativeText', 'element_id': '1ccde74f4a2f53e7d469c852de3d13e4', 'text': 'Aggregate and make easily accessible the content that HDX already collects with a specialized Quality Measures pane on the HDX site. This Quality Measures pane is divided into four parts: Use, Trust & Safety, Content Quality, and Technical Specs. The measures in each section are summed, not as a score, but as an indicator for comparability, and an indication of the value of transparency into dataset information. These sums are visible in the search view on HDX as at- a-glance indicators about dataset quality measures.', 'metadata': {'coordinates': {'points': ((90.0, 352.3266), (90.0, 451.32660000000004), (524.4191999999998, 451.32660000000004), (524.4191999999998, 352.3266)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 15, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '05c6b74e951c6c9ad8e2e3cec897dc6b'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'd6c6a15f2e506dfaf8a523f7548b8e13', 'text': 'Phase 2 - High-level spec, requires additional research and design', 'metadata': {'coordinates': {'points': ((131.9485, 500.6266), (131.9485, 512.0266), (480.05649999999986, 512.0266), (480.05649999999986, 500.6266)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 15, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '05c6b74e951c6c9ad8e2e3cec897dc6b'}}\n",
      "{'type': 'NarrativeText', 'element_id': '61439d6bfebf08ca4992cfd54ef6984c', 'text': 'Create an organization review and vetting process that allows for trusted orgs to serve as a proxy  or at least an additional indicator  for dataset credibility, and introduce org badges into the Quality Measures pane; automate QA processes where possible; begin research into domain-specific quality measures.', 'metadata': {'coordinates': {'points': ((90.0, 524.2266), (90.0, 579.4266), (516.8205, 579.4266), (516.8205, 524.2266)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 15, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '05c6b74e951c6c9ad8e2e3cec897dc6b'}}\n",
      "{'type': 'NarrativeText', 'element_id': '184804f897e4bbedbc60c846ceef5efe', 'text': 'Phase 3 - High-level spec, requires additional research & design', 'metadata': {'coordinates': {'points': ((137.3305, 628.7266), (137.3305, 640.1266), (474.67209999999994, 640.1266), (474.67209999999994, 628.7266)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 15, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '05c6b74e951c6c9ad8e2e3cec897dc6b'}}\n",
      "{'type': 'NarrativeText', 'element_id': '32bb1fb32b7291ebc92a1fdda03ccd8f', 'text': 'Collect additional quality measures through third-party organization QA processes; introduce self-reporting assessment for domain-specific quality measures; implement dataset comparison suggestions of similar datasets, and consider adding further measures pending user feedback from Phases 1 and 2.', 'metadata': {'coordinates': {'points': ((90.0, 652.3266), (90.0, 707.5266), (512.4685999999999, 707.5266), (512.4685999999999, 652.3266)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 15, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '05c6b74e951c6c9ad8e2e3cec897dc6b'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '70d6870b87058591b128834e933fa8e1', 'text': '11', 'metadata': {'coordinates': {'points': ((588.7884, 722.8499), (588.7884, 732.8499), (595.0484, 732.8499), (595.0484, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 15, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '05c6b74e951c6c9ad8e2e3cec897dc6b'}}\n",
      "{'type': 'Title', 'element_id': 'e6ba4016a8371c31809458665e882476', 'text': 'Additional notes on our recommendations:', 'metadata': {'coordinates': {'points': ((72.0, 54.406600000000026), (72.0, 65.8066), (301.22159999999997, 65.8066), (301.22159999999997, 54.406600000000026)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 16, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'ListItem', 'element_id': 'a14278c0854903194974f03e99d2b5e7', 'text': 'Our approach involved prototyping on real datasets. This proved to be an essential part of our process; it enabled our work to be grounded in the particulars of the HDX context. We will follow this model for any future work with HDX.', 'metadata': {'coordinates': {'points': ((99.0, 73.50660000000005), (99.0, 128.70659999999998), (520.4843999999999, 128.70659999999998), (520.4843999999999, 73.50660000000005)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 16, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'e6ba4016a8371c31809458665e882476'}}\n",
      "{'type': 'ListItem', 'element_id': '60625f5b2493eaba48cffb096283f4c2', 'text': 'Based on our research and interviews, completeness, accuracy, and relevance were the quality measures that were most useful, and HDX already collects certain information that has indicators for these areas. The work in Phase 1 involves organizing this information into a legible knowledge structure, and designing it in a visible and easily accessible way. The chart in Section VI below (fig. 12) Indicates where and when this information is collected, and possible answers for each field.', 'metadata': {'coordinates': {'points': ((99.0, 136.40660000000003), (99.0, 235.40660000000003), (541.5417, 235.40660000000003), (541.5417, 136.40660000000003)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 16, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'e6ba4016a8371c31809458665e882476'}}\n",
      "{'type': 'ListItem', 'element_id': '0069d46f0409612c7c9f04d1604d54c8', 'text': 'Based on the needs of HDX users and the circumstances  20K+ disparate datasets, limited resources for additional dataset security  we determined that HDX ought to build frameworks for measuring metadata completeness and, additionally, seek out quality certifications (likely conducted by third parties, but could also be conducted internally by HDX).', 'metadata': {'coordinates': {'points': ((99.0, 243.10660000000007), (99.0, 312.9066), (540.8507999999999, 312.9066), (540.8507999999999, 243.10660000000007)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 16, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'e6ba4016a8371c31809458665e882476'}}\n",
      "{'type': 'Title', 'element_id': 'ab29961b9bd72a2a451d44afa80bb0c9', 'text': 'Designs', 'metadata': {'coordinates': {'points': ((72.0, 338.60659999999996), (72.0, 350.0066), (114.732, 350.0066), (114.732, 338.60659999999996)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 16, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'NarrativeText', 'element_id': '4b516fd57a851762cbd98cff5ac350c4', 'text': 'DNP created three Phase 1 designs (a template + two dataset-specific versions), a search view, and a Phase 3 preview of the dataset comparison section. Full resolution designs are included in the Appendix.', 'metadata': {'coordinates': {'points': ((72.0, 362.2066), (72.0, 402.8066), (535.0739999999998, 402.8066), (535.0739999999998, 362.2066)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 16, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'ab29961b9bd72a2a451d44afa80bb0c9'}}\n",
      "{'type': 'Title', 'element_id': '6e3d9a555596b1605f6fd9db8e745716', 'text': 'Figure 8. Phase 1 content in Quality Measures Pane on HDX site.', 'metadata': {'coordinates': {'points': ((161.8533, 723.0088), (161.8533, 732.5088), (452.89230000000003, 732.5088), (452.89230000000003, 723.0088)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 16, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '51707ffc72809579f4c2c827f1c40be6', 'text': '12', 'metadata': {'coordinates': {'points': ((587.8585, 722.8499), (587.8585, 732.8499), (595.9785, 732.8499), (595.9785, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 16, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '6e3d9a555596b1605f6fd9db8e745716'}}\n",
      "{'type': 'NarrativeText', 'element_id': '9381dce8103c6b22815512498eae250b', 'text': 'Figure 9. HDX search view with Quality Measure counts.', 'metadata': {'coordinates': {'points': ((179.783, 273.7096), (179.783, 283.20959999999997), (432.41, 283.20959999999997), (432.41, 273.7096)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 17, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '6e3d9a555596b1605f6fd9db8e745716'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '273fd9cae5af49b0df4b39719ba2c6ed', 'text': 'Figure 10. Views of Quality Measures Panes (Phase 1) for two example datasets.', 'metadata': {'coordinates': {'points': ((118.7548, 729.7096), (118.7548, 739.2096), (493.2488, 739.2096), (493.2488, 729.7096)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 17, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '6e3d9a555596b1605f6fd9db8e745716'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'ef0f92286f2ec5314e6a83a8d4517395', 'text': '13', 'metadata': {'coordinates': {'points': ((587.8585, 722.8499), (587.8585, 732.8499), (595.9785, 732.8499), (595.9785, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 17, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '6e3d9a555596b1605f6fd9db8e745716'}}\n",
      "{'type': 'Header', 'element_id': '5656bffc8386005b5d85c21afe83a967', 'text': 'Quality Measures for Humanitarian Data', 'metadata': {'coordinates': {'points': ((0.0, 0.0), (0.0, 0.0), (612.0, 0.0), (612.0, 0.0)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 18, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'NarrativeText', 'element_id': '0d035724a15c9a575cb924cdba24a8b0', 'text': 'Figure 11. Similar Datasets comparison sketch, to be refined in Phase 3.', 'metadata': {'coordinates': {'points': ((150.2488, 283.4675), (150.2488, 292.9675), (461.9257999999998, 292.9675), (461.9257999999998, 283.4675)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 18, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '00a7d0efd09cb583e39d5b142d8465c9', 'text': '14', 'metadata': {'coordinates': {'points': ((587.8484, 722.8499), (587.8484, 732.8499), (595.9884, 732.8499), (595.9884, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 18, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': 'bf93f3f286292f4693b63350313d0d84', 'text': 'VI. ROADMAP & IMPLEMENTATION', 'metadata': {'coordinates': {'points': ((194.6389, 58.381599999999935), (194.6389, 90.1816), (417.3928999999999, 90.1816), (417.3928999999999, 58.381599999999935)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 19, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': 'fc7f5c1faaed9643a9d7e62a9d757d4d', 'text': 'Phase 1', 'metadata': {'coordinates': {'points': ((72.0, 114.85180000000003), (72.0, 126.2518), (111.70679999999999, 126.2518), (111.70679999999999, 114.85180000000003)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 19, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '245a84774b5238f7dc5c32fbaf2522f5', 'text': 'Approach', 'metadata': {'coordinates': {'points': ((72.0, 138.2518), (72.0, 149.65179999999998), (123.51600000000002, 149.65179999999998), (123.51600000000002, 138.2518)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 19, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'NarrativeText', 'element_id': '693d6272b0195e386cd33066c42d84a5', 'text': 'We recommend creating a new Quality Measures pane (alongside the Data & Resources and Metadata panes) for the HDX dataset landing page. This view will consolidate existing measures from across HDX into one view that gives users a quick overview of dataset information and proxies for quality, organized into four sections:', 'metadata': {'coordinates': {'points': ((72.0, 161.85180000000003), (72.0, 217.05190000000005), (530.6951999999999, 217.05190000000005), (530.6951999999999, 161.85180000000003)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 19, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '245a84774b5238f7dc5c32fbaf2522f5'}}\n",
      "{'type': 'Title', 'element_id': 'f18982999a644a1e90a1d9079385da33', 'text': 'Use | Trust & Safety | Content Quality | Technical Specs', 'metadata': {'coordinates': {'points': ((142.676, 229.2518), (142.676, 240.65179999999998), (469.32559999999995, 240.65179999999998), (469.32559999999995, 229.2518)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 19, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'NarrativeText', 'element_id': '047e11aa3033b5c7009544dac097bd89', 'text': 'The technical needs for this should be minimal, and implementation process could include: 1) Implementing the prototype on HDXs staging server; 2) Soliciting feedback on the prototype from key stakeholders, integrating feedback where possible; and 3) Rolling out the measures design to HDX. Because all of the information present in the Phase 1 prototype is already collected, it would be a matter of consolidating information rather than creating new information or processes. Below (fig. 12)is a chart of the information contained in the Phase 1 designs, and where that information comes from in the HDX workflow.', 'metadata': {'coordinates': {'points': ((72.0, 252.85180000000003), (72.0, 366.4518), (539.9999999999999, 366.4518), (539.9999999999999, 252.85180000000003)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 19, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'f18982999a644a1e90a1d9079385da33'}}\n",
      "{'type': 'Title', 'element_id': '5da812bef9c430d3db85c59937835c2b', 'text': 'Technical Considerations', 'metadata': {'coordinates': {'points': ((72.0, 378.45189999999997), (72.0, 389.8519), (203.83080000000004, 389.8519), (203.83080000000004, 378.45189999999997)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 19, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'NarrativeText', 'element_id': '0482bb814104e92c2ef3be2f65508e37', 'text': 'Phase 1 involves no database changes, and minimal back-end implementation. It will focus primarily on front-end implementation for HDX, and soliciting feedback from stakeholders.', 'metadata': {'coordinates': {'points': ((72.0, 402.05179999999996), (72.0, 442.65180000000004), (521.5907999999997, 442.65180000000004), (521.5907999999997, 402.05179999999996)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 19, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5da812bef9c430d3db85c59937835c2b'}}\n",
      "{'type': 'ListItem', 'element_id': '7bdb22c477d0a0cd7927cfd665725f9f', 'text': 'Database/DevOps. The data needed for the Phase 1 measures view exists within HDX already, meaning there should be no database migration/change considerations.', 'metadata': {'coordinates': {'points': ((99.0, 450.35179999999997), (99.0, 490.9518), (527.1216, 490.9518), (527.1216, 450.35179999999997)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 19, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5da812bef9c430d3db85c59937835c2b'}}\n",
      "{'type': 'ListItem', 'element_id': '2d6338b0c4b9bc2c09deb4c5c0399441', 'text': 'Back-end. Implementation would be focused on making sure all of the necessary quality measures are available to the front-end website. While many of these are already available to the front-end, such as last-updated date and caveats, some things may not be readily available, such as whether a QA check has been conducted. This would involve an audit of existing data access endpoints, with the potential need to implement a few new back-end endpoints for existing information. It may also require reformatting some of the back-end endpoints to ensure the information needed by the front-end is in the right format.', 'metadata': {'coordinates': {'points': ((99.0, 498.6518), (99.0, 612.2518), (537.8592, 612.2518), (537.8592, 498.6518)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 19, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5da812bef9c430d3db85c59937835c2b'}}\n",
      "{'type': 'ListItem', 'element_id': '1450e656ee29a64f1f43032c57908f78', 'text': 'Front-end. Front-end work would be the most significant portion of this phase. It would include implementing back-end requests and an accessible, localizable UX.', 'metadata': {'coordinates': {'points': ((99.0, 619.9519), (99.0, 645.9518), (542.2259999999999, 645.9518), (542.2259999999999, 619.9519)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 19, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5da812bef9c430d3db85c59937835c2b'}}\n",
      "{'type': 'ListItem', 'element_id': '0992c7866325243b66984ab52383bf20', 'text': 'Feedback. It will be important to have a clearly defined list of stakeholders from whom to get feedback on Phase 1 designs, and clear reasons for why they are being chosen, and the kind of feedback sought. It will be important to set limitations for the scope of their feedback, so that they understand what is possible in Phase 1. 15', 'metadata': {'coordinates': {'points': ((99.0, 653.6519000000001), (99.0, 732.8499), (596.0184, 732.8499), (596.0184, 653.6519000000001)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 19, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5da812bef9c430d3db85c59937835c2b'}}\n",
      "{'type': 'NarrativeText', 'element_id': '8e637459e2b4afb8d61865b0deaf081b', 'text': 'Phase 1 is intentionally a consolidation and surfacing and organizing what is already there phase and thus should not require substantial technical work.', 'metadata': {'coordinates': {'points': ((72.0, 54.406600000000026), (72.0, 80.40660000000003), (522.7176, 80.40660000000003), (522.7176, 54.406600000000026)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5da812bef9c430d3db85c59937835c2b'}}\n",
      "{'type': 'Title', 'element_id': '9e737f4d21db1544073fbf0709581dd6', 'text': 'Quality\\tSection Measure', 'metadata': {'coordinates': {'points': ((76.5, 118.8587), (76.5, 128.3587), (209.68, 128.3587), (209.68, 118.8587)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': 'd8434c5333f7f8b062f0f1954a486149', 'text': 'HDX\\tProcess/source Response\\tParameters', 'metadata': {'coordinates': {'points': ((275.44, 118.8587), (275.44, 128.3587), (499.44899999999996, 128.3587), (499.44899999999996, 118.8587)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '8ceffa3c5bb86fefb65683f1c7aa4de3', 'text': 'Use', 'metadata': {'coordinates': {'points': ((76.5, 134.20850000000007), (76.5, 143.70850000000007), (93.83, 143.70850000000007), (93.83, 134.20850000000007)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': 'f395da915e80b94024ba6d1a413b5d74', 'text': 'Intended Use', 'metadata': {'coordinates': {'points': ((167.44, 141.64870000000008), (167.44, 151.14870000000008), (226.61, 151.14870000000008), (226.61, 141.64870000000008)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '485b6ef1fca2ab5488b4416b103c2451', 'text': 'NEW: Dataset Upload - Intended Use Field', 'metadata': {'coordinates': {'points': ((275.44, 135.64870000000008), (275.44, 157.14870000000008), (381.8496, 157.14870000000008), (381.8496, 135.64870000000008)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '56ee37ef61eed90f8ce520db8fc78685', 'text': 'Open Text', 'metadata': {'coordinates': {'points': ((392.08, 141.64870000000008), (392.08, 151.14870000000008), (437.49999999999994, 151.14870000000008), (437.49999999999994, 141.64870000000008)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '0891f720e7ae023f0268de4f554e4ae9', 'text': 'Restrictions', 'metadata': {'coordinates': {'points': ((167.44, 170.43870000000004), (167.44, 179.93870000000004), (219.379, 179.93870000000004), (219.379, 170.43870000000004)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '7d47d41649e12d7de06b71eeabcfb8e1', 'text': 'Dataset Upload - Caveats', 'metadata': {'coordinates': {'points': ((275.44, 164.43870000000004), (275.44, 185.93870000000004), (353.77, 185.93870000000004), (353.77, 164.43870000000004)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': 'ef48e7409267efeb09a4f4937e40cdd6', 'text': 'Open Text', 'metadata': {'coordinates': {'points': ((392.08, 170.43870000000004), (392.08, 179.93870000000004), (437.49999999999994, 179.93870000000004), (437.49999999999994, 170.43870000000004)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '0bb94f7a50b771e782a4e669612a68ff', 'text': 'Trust & Safety', 'metadata': {'coordinates': {'points': ((76.5, 191.7886000000001), (76.5, 201.2886000000001), (138.97899999999998, 201.2886000000001), (138.97899999999998, 191.7886000000001)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '667a59d5ce95df9599f6fb8c4bd0f6f0', 'text': 'PII', 'metadata': {'coordinates': {'points': ((167.44, 194.19370000000004), (167.44, 203.69370000000004), (179.17000000000002, 203.69370000000004), (179.17000000000002, 194.19370000000004)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '7229f03ea2a9ff44f24d2bde77a99f2f', 'text': 'HDX QA', 'metadata': {'coordinates': {'points': ((275.44, 194.19370000000004), (275.44, 203.69370000000004), (313.72, 203.69370000000004), (313.72, 194.19370000000004)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '29c7d0e01eb1d910aae473d1a4ff4657', 'text': 'Yes, No', 'metadata': {'coordinates': {'points': ((392.08, 194.19370000000004), (392.08, 203.69370000000004), (425.26, 203.69370000000004), (425.26, 194.19370000000004)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '7140abc710c8bc910de24596018b4bfb', 'text': 'SDC Check', 'metadata': {'coordinates': {'points': ((167.44, 213.6336), (167.44, 223.1336), (219.529, 223.1336), (219.529, 213.6336)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': 'a8fd49e4704d4a6aac4fd62f8390519b', 'text': 'HDX QA', 'metadata': {'coordinates': {'points': ((275.44, 213.6336), (275.44, 223.1336), (313.72, 223.1336), (313.72, 213.6336)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '316ad06153011332e696578007e452a8', 'text': 'Yes, No', 'metadata': {'coordinates': {'points': ((392.08, 213.6336), (392.08, 223.1336), (425.26, 223.1336), (425.26, 213.6336)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': 'ff7e2c0448a7c6d36346323da60d965b', 'text': 'Passed HDX QA', 'metadata': {'coordinates': {'points': ((167.44, 232.35360000000003), (167.44, 241.85360000000003), (240.79999999999998, 241.85360000000003), (240.79999999999998, 232.35360000000003)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '7cbaf25e0fb69c233cab57e20fb8eca6', 'text': 'HDX QA', 'metadata': {'coordinates': {'points': ((275.44, 232.35360000000003), (275.44, 241.85360000000003), (313.72, 241.85360000000003), (313.72, 232.35360000000003)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': 'da11421505734b0e65c91a619a0ff1dc', 'text': 'Yes, No', 'metadata': {'coordinates': {'points': ((392.08, 232.35360000000003), (392.08, 241.85360000000003), (425.26, 241.85360000000003), (425.26, 232.35360000000003)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '782078a2ca2708df7a87914e90c561d5', 'text': 'Content Quality', 'metadata': {'coordinates': {'points': ((76.5, 249.38850000000002), (76.5, 258.8885), (146.27, 258.8885), (146.27, 249.38850000000002)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': 'e3a48b49fdd9779a608047adb23393cc', 'text': 'Update Frequency & Last Updated date*', 'metadata': {'coordinates': {'points': ((167.44, 249.38850000000002), (167.44, 270.8885), (262.68899999999996, 270.8885), (262.68899999999996, 249.38850000000002)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'ListItem', 'element_id': 'e4f378b1fa4bc79b8d0879d70fb6ba0a', 'text': 'When these two pieces of information conflict, it should be noted as conflicting information, and the more recent one gets prioritized.', 'metadata': {'coordinates': {'points': ((167.44, 285.89070000000004), (167.44, 331.8907), (269.3488, 331.8907), (269.3488, 285.89070000000004)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'e3a48b49fdd9779a608047adb23393cc'}}\n",
      "{'type': 'Title', 'element_id': 'e1c355fa6f83a358eb2ef7eb31d68183', 'text': 'Dataset Upload - Expected Frequency Update, Upload timestamp', 'metadata': {'coordinates': {'points': ((275.44, 268.1385), (275.44, 313.63849999999996), (369.819, 313.63849999999996), (369.819, 268.1385)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '833c77cd349272b1b69354878787de4b', 'text': 'Frequency - Multiple choice (Every day, every week, every two weeks, etc.)', 'metadata': {'coordinates': {'points': ((392.08, 261.3885), (392.08, 294.88849999999996), (525.519, 294.88849999999996), (525.519, 261.3885)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '22d3339d6d7b8a46e71224e5155efcb8', 'text': 'Last uploaded- Date-time', 'metadata': {'coordinates': {'points': ((392.08, 310.88849999999996), (392.08, 320.38849999999996), (506.039, 320.38849999999996), (506.039, 310.88849999999996)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': 'e56536aab15d1807587e328ec6f39b75', 'text': 'Collection Method', 'metadata': {'coordinates': {'points': ((167.44, 356.23839999999996), (167.44, 365.73839999999996), (248.919, 365.73839999999996), (248.919, 356.23839999999996)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': 'e15e7595d7e1682d64fa2710ac5ad66a', 'text': 'Dataset Upload - Methodology', 'metadata': {'coordinates': {'points': ((275.44, 350.23839999999996), (275.44, 371.73839999999996), (353.77, 371.73839999999996), (353.77, 350.23839999999996)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '7b6302d08d57f3e12040e3e381c3ba44', 'text': 'Multiple Choice (Census, Sample Survey, Direct Observational Data, Registry, Other)', 'metadata': {'coordinates': {'points': ((392.08, 338.23839999999996), (392.08, 383.73839999999996), (522.659, 383.73839999999996), (522.659, 338.23839999999996)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '227c0c8f5a7845903819afef4e57e22f', 'text': 'Level of Analysis', 'metadata': {'coordinates': {'points': ((167.44, 395.5882), (167.44, 405.0882), (241.719, 405.0882), (241.719, 395.5882)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '69faebde4ac85c419c41c2cbff93145e', 'text': 'HDX QA', 'metadata': {'coordinates': {'points': ((275.44, 395.5882), (275.44, 405.0882), (313.72, 405.0882), (313.72, 395.5882)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '4832d75defd243359c409c82bc7d3b77', 'text': 'Multiple Choice (national or sub-national)', 'metadata': {'coordinates': {'points': ((392.08, 389.5882), (392.08, 411.0882), (516.81, 411.0882), (516.81, 389.5882)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'ce36a1eed1c32b0b5000f7bb12345a48', 'text': 'Badge (i.e. it is present if the review has been done, absent if not).', 'metadata': {'coordinates': {'points': ((392.08, 416.93809999999996), (392.08, 450.43809999999996), (527.0509999999999, 450.43809999999996), (527.0509999999999, 416.93809999999996)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '4832d75defd243359c409c82bc7d3b77'}}\n",
      "{'type': 'Title', 'element_id': '8e4592349191c9f7644330a7e81b8f48', 'text': 'Quality Certifications', 'metadata': {'coordinates': {'points': ((167.44, 459.68809999999996), (167.44, 469.18809999999996), (260.19899999999996, 469.18809999999996), (260.19899999999996, 459.68809999999996)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '087a33bb0e2ee388247e479104d886a6', 'text': 'Review by HDX Data Team', 'metadata': {'coordinates': {'points': ((275.44, 453.68809999999996), (275.44, 475.18809999999996), (371.519, 475.18809999999996), (371.519, 453.68809999999996)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'NarrativeText', 'element_id': '0597aabff6dd2f6292005026c5020736', 'text': 'Possible badges include: Datagrid Dataset (NEW, would have to be imported through a script), COD', 'metadata': {'coordinates': {'points': ((392.08, 466.43809999999996), (392.08, 511.93809999999996), (530.4386, 511.93809999999996), (530.4386, 466.43809999999996)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '087a33bb0e2ee388247e479104d886a6'}}\n",
      "{'type': 'Title', 'element_id': '5f1f1550ce047f1db1dbf3d7f3f4c191', 'text': 'Technical Specs', 'metadata': {'coordinates': {'points': ((76.5, 517.788), (76.5, 527.288), (148.26899999999998, 527.288), (148.26899999999998, 517.788)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': 'b50b2d11b602bb04477f897cdb25bbbb', 'text': 'P-Code', 'metadata': {'coordinates': {'points': ((167.44, 523.788), (167.44, 533.288), (201.41000000000003, 533.288), (201.41000000000003, 523.788)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': 'f5e79b59491efc237a4dd8ab5c746e65', 'text': 'Dataset Upload - Automatically reviewed', 'metadata': {'coordinates': {'points': ((275.44, 517.788), (275.44, 539.288), (378.258, 539.288), (378.258, 517.788)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'c87a5f1314cdc156fa850deacad44d9e', 'text': 'Badge (i.e. it is present if P-codes are used, absent if not).', 'metadata': {'coordinates': {'points': ((392.08, 517.788), (392.08, 539.288), (534.508, 539.288), (534.508, 517.788)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'f5e79b59491efc237a4dd8ab5c746e65'}}\n",
      "{'type': 'Title', 'element_id': '13acdec90545a8524e86b0c24b1e690a', 'text': 'HXL', 'metadata': {'coordinates': {'points': ((167.44, 551.1378), (167.44, 560.6378), (186.94, 560.6378), (186.94, 551.1378)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '816f34afa1392ad2dc34d51c3d79f3be', 'text': 'Dataset Upload - Automatically reviewed', 'metadata': {'coordinates': {'points': ((275.44, 545.1378), (275.44, 566.6378), (378.258, 566.6378), (378.258, 545.1378)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'NarrativeText', 'element_id': '74c2556168a41158d22ba6988ecae06c', 'text': 'Badge (i.e. it is present if HXL is used, absent if not).', 'metadata': {'coordinates': {'points': ((392.08, 545.1378), (392.08, 566.6378), (534.379, 566.6378), (534.379, 545.1378)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '816f34afa1392ad2dc34d51c3d79f3be'}}\n",
      "{'type': 'Title', 'element_id': '0d4857402ca55ec1edb4eed7b3668746', 'text': 'Valid URLs', 'metadata': {'coordinates': {'points': ((167.44, 572.4877), (167.44, 581.9877), (216.609, 581.9877), (216.609, 572.4877)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '90c9d43d4d397138eb96d376b0498393', 'text': 'HDX QA', 'metadata': {'coordinates': {'points': ((275.44, 572.4877), (275.44, 581.9877), (313.72, 581.9877), (313.72, 572.4877)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': 'e05b391d18a177debc7185db62e52c04', 'text': 'Yes, No', 'metadata': {'coordinates': {'points': ((392.08, 572.4877), (392.08, 581.9877), (425.26, 581.9877), (425.26, 572.4877)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '86261d4518dfb8e10b8d7591c0c2ab56', 'text': 'API Used', 'metadata': {'coordinates': {'points': ((167.44, 593.8375), (167.44, 603.3375), (209.22000000000003, 603.3375), (209.22000000000003, 593.8375)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': 'ef8efada65a2e094439d93a2c6bd9a1e', 'text': 'NEW: Dataset Upload - Automatically reviewed', 'metadata': {'coordinates': {'points': ((275.44, 587.8375), (275.44, 609.3375), (381.8496, 609.3375), (381.8496, 587.8375)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '02c3c8d8be291121617d6475f514e279', 'text': 'Yes, No', 'metadata': {'coordinates': {'points': ((392.08, 593.8375), (392.08, 603.3375), (425.26, 603.3375), (425.26, 593.8375)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '3682f0016e35ad6bc106212a4166aece', 'text': 'Format', 'metadata': {'coordinates': {'points': ((167.44, 627.1874), (167.44, 636.6874), (199.0, 636.6874), (199.0, 627.1874)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': 'b9c44cb5aa5b5a4c1f418da748caa47e', 'text': 'Dataset Upload - Resource Upload', 'metadata': {'coordinates': {'points': ((275.44, 621.1874), (275.44, 642.6874), (353.77, 642.6874), (353.77, 621.1874)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'NarrativeText', 'element_id': '7ecee24f1256c2c1d17341d0c5d5f82c', 'text': 'Select All that Apply (.csv, .kxl, .xlsx, etc. [Centre to generate comprehensive list])', 'metadata': {'coordinates': {'points': ((392.08, 615.1874), (392.08, 648.6874), (527.077, 648.6874), (527.077, 615.1874)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'b9c44cb5aa5b5a4c1f418da748caa47e'}}\n",
      "{'type': 'NarrativeText', 'element_id': '094ac69070961e3dd9fa8c02d404fcc7', 'text': 'Figure 12. Phase 1 Quality Measures table including source of information and response parameters.', 'metadata': {'coordinates': {'points': ((72.0, 672.2873), (72.0, 681.7873), (517.9529999999999, 681.7873), (517.9529999999999, 672.2873)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'b9c44cb5aa5b5a4c1f418da748caa47e'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'a545412ad436b817470e217f6132ab5f', 'text': '16', 'metadata': {'coordinates': {'points': ((587.7285, 722.8499), (587.7285, 732.8499), (596.1085, 732.8499), (596.1085, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 20, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'b9c44cb5aa5b5a4c1f418da748caa47e'}}\n",
      "{'type': 'Title', 'element_id': '2aae09542e93746282b76b2fb59fc293', 'text': 'Further recommendations', 'metadata': {'coordinates': {'points': ((72.0, 54.406600000000026), (72.0, 65.8066), (209.19600000000003, 65.8066), (209.19600000000003, 54.406600000000026)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 21, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '23b635638f621c53aa10838ff3352f09', 'text': 'Phase 2', 'metadata': {'coordinates': {'points': ((72.0, 91.50660000000005), (72.0, 102.90660000000003), (113.63879999999999, 102.90660000000003), (113.63879999999999, 91.50660000000005)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 21, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'NarrativeText', 'element_id': '3c027d88bbf6909eeb5bda7143cf976a', 'text': 'Phases 2 and 3 research and designs could be explored in future engagements.', 'metadata': {'coordinates': {'points': ((72.0, 115.10660000000007), (72.0, 126.50660000000005), (490.66439999999994, 126.50660000000005), (490.66439999999994, 115.10660000000007)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 21, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '23b635638f621c53aa10838ff3352f09'}}\n",
      "{'type': 'Title', 'element_id': '62fd480572b9e391d460758982ad317b', 'text': 'Approach', 'metadata': {'coordinates': {'points': ((72.0, 138.50660000000005), (72.0, 149.90660000000003), (123.51600000000002, 149.90660000000003), (123.51600000000002, 138.50660000000005)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 21, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'be1dfdc0b45f6ab726ea3e3da1861bf4', 'text': 'Phase 2 has three specific foci: 1) determining measures for and assessing organizational trust, 2) creating capacity for longer-term quality measures development, and 3) research on domain-specific measures. For organizational trust, the goal would be to come up with an architecture for measuring an organizations data processes, which would be used as a proxy for the credibility of the organizations datasets. This would then be easily viewable as a quality indicator. The element of creating capacity for QA automation would include identifying the components of the QA process that are automatable, and implementing changes in technical workflows to create this automation. The third component of this phase involves researching domain-specific quality measures. For example, how is quality evaluated for GIS infrastructure datasets, or food security datasets? Domain-specific quality measures will add value to dataset review and may reveal potential avenues for automated assessment.', 'metadata': {'coordinates': {'points': ((72.0, 162.10660000000007), (72.0, 334.1066), (538.3859999999999, 334.1066), (538.3859999999999, 162.10660000000007)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 21, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '62fd480572b9e391d460758982ad317b'}}\n",
      "{'type': 'Title', 'element_id': '1dad7c8981c911aeac32759c666552e3', 'text': 'Technical Considerations', 'metadata': {'coordinates': {'points': ((72.0, 346.10659999999996), (72.0, 357.5066), (203.83080000000004, 357.5066), (203.83080000000004, 346.10659999999996)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 21, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'NarrativeText', 'element_id': '7777b4cc23332bd25d367f1e441a0f6d', 'text': 'For each of the three components of Phase 2, technical considerations would vary based on the capacity of HDX. A narrative exploring the range of technical considerations (from limited capacity to high capacity) would be included after conducting further research.', 'metadata': {'coordinates': {'points': ((72.0, 369.7066), (72.0, 424.9066), (494.3975999999999, 424.9066), (494.3975999999999, 369.7066)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 21, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '1dad7c8981c911aeac32759c666552e3'}}\n",
      "{'type': 'Title', 'element_id': '1a6777d6ae90a2685dd7119cf3124e23', 'text': 'Phase 3', 'metadata': {'coordinates': {'points': ((72.0, 450.60659999999996), (72.0, 462.0066), (116.976, 462.0066), (116.976, 450.60659999999996)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 21, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '94d335901719ab1fadd239d3b49e28e3', 'text': 'Approach', 'metadata': {'coordinates': {'points': ((72.0, 474.0066), (72.0, 485.4066), (123.51600000000002, 485.4066), (123.51600000000002, 474.0066)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 21, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'NarrativeText', 'element_id': '92762a999c9e3fb4cdfc244e9ec4931e', 'text': 'Following on the recommendations from Phases 1 & 2, Phase 3 would enable a more comprehensive quality metrics interface. This would include implementing the research from Phase 2 on domain-specific quality measures and either 1) soliciting third party organizations to build certification processes for these metrics, or 2) proposing a self- assessment for agreed-upon domain-specific measures.', 'metadata': {'coordinates': {'points': ((72.0, 497.60659999999996), (72.0, 567.4066), (536.9027999999998, 567.4066), (536.9027999999998, 497.60659999999996)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 21, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '94d335901719ab1fadd239d3b49e28e3'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'fe99a9237ff8ce525183b2a52fbf1a50', 'text': 'With more comprehensive quality measures, HDX will have the information available for meaningful dataset comparison. This comparison could be displayed in a section called Similar Datasets, enabling users to quickly compare across HDX datasets along the metrics that are most important for them, and thus choose the best data for their use cases.', 'metadata': {'coordinates': {'points': ((72.0, 579.6066000000001), (72.0, 649.4066), (538.3895999999997, 649.4066), (538.3895999999997, 579.6066000000001)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 21, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '94d335901719ab1fadd239d3b49e28e3'}}\n",
      "{'type': 'Title', 'element_id': '0ec382e89bf9646ff1028ee7435a020d', 'text': 'Rationale', 'metadata': {'coordinates': {'points': ((72.0, 661.4066), (72.0, 672.8066), (121.38, 672.8066), (121.38, 661.4066)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 21, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'NarrativeText', 'element_id': '491a150bc44a158ca0433a2cf484286f', 'text': 'In our research on Common Operational Datasets (CODs) and GIS road-mapping datasets, we discovered that there were some specific methods for quality analysis that applied to all datasets in a given domain, but not beyond that domain. CODs have their own quality metrics framework and third party certification; GIS road-mapping datasets', 'metadata': {'coordinates': {'points': ((72.0, 685.0065999999999), (72.0, 740.2066), (538.7591999999997, 740.2066), (538.7591999999997, 685.0065999999999)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 21, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '0ec382e89bf9646ff1028ee7435a020d'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '8e3d74d5817b2b2961728ab973b11f5b', 'text': '17', 'metadata': {'coordinates': {'points': ((588.0584, 722.8499), (588.0584, 732.8499), (595.7783999999999, 732.8499), (595.7783999999999, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 21, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '0ec382e89bf9646ff1028ee7435a020d'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'a958c2009911f2516f12b9abd0bcf6dd', 'text': 'tend to have a standardized structure that most dataset creators use. Consequently, it seems feasible that the findings from Phase 2 on domain-specific datasets could be rolled into third party certification in some cases, or automated analysis in others (where data is already informally standardized).', 'metadata': {'coordinates': {'points': ((72.0, 54.406600000000026), (72.0, 109.60660000000007), (542.4084, 109.60660000000007), (542.4084, 54.406600000000026)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 22, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '0ec382e89bf9646ff1028ee7435a020d'}}\n",
      "{'type': 'NarrativeText', 'element_id': '8b3f01c2d07a50639f31275880d9f8d3', 'text': 'And, while the measures in Phase 1 are a helpful starting point to assess quality, more analysis is needed for robust dataset comparison. The addition of third party certifications and automated analyses by domain will provide the content for such comparison. Technical considerations for Phase 3 would be enumerated after the research, development, and design for Phases 2 and 3.', 'metadata': {'coordinates': {'points': ((72.0, 121.8066), (72.0, 191.60660000000007), (508.90679999999963, 191.60660000000007), (508.90679999999963, 121.8066)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 22, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '0ec382e89bf9646ff1028ee7435a020d'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'ace997634a440d841f7e27b7cd5341ec', 'text': '18', 'metadata': {'coordinates': {'points': ((587.8384, 722.8499), (587.8384, 732.8499), (595.9984, 732.8499), (595.9984, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 22, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '0ec382e89bf9646ff1028ee7435a020d'}}\n",
      "{'type': 'Title', 'element_id': '0e811fc7b38d0f32e56df3e4039134d4', 'text': 'VII. ADDITIONAL CONSIDERATIONS', 'metadata': {'coordinates': {'points': ((195.3944, 58.381599999999935), (195.3944, 90.1816), (416.6573999999998, 90.1816), (416.6573999999998, 58.381599999999935)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 23, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'e6190e6f21146361b58eba217018c1b6', 'text': 'Impact on existing data processes and systems', 'metadata': {'coordinates': {'points': ((72.0, 114.85180000000003), (72.0, 126.2518), (320.472, 126.2518), (320.472, 114.85180000000003)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 23, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '0e811fc7b38d0f32e56df3e4039134d4'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'd21973239cc7c81348ac3d196139b462', 'text': 'Currently, data organizations upload their datasets to HDX either in bulk (using the HDX / CKAN APIs) or manually (using the upload form process). Many dataset quality measures are already collected during these processes, and we recommend that additional information could be gathered through updating the API and the form. Critically, our Phase 1 recommendation does not require this additional infrastructure, and instead utilizes only information that HDX already collects. In Phase 2 and beyond, there are additional automated and manual processes in which more metadata is gathered, some of which could be leveraged as quality measures. The particulars of this information - what is gathered and when, and what opportunities there are to collect more data automatically or otherwise  require further exploration.', 'metadata': {'coordinates': {'points': ((72.0, 138.45190000000002), (72.0, 281.2518), (539.2055999999997, 281.2518), (539.2055999999997, 138.45190000000002)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 23, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '0e811fc7b38d0f32e56df3e4039134d4'}}\n",
      "{'type': 'Title', 'element_id': '62abe5e251db61f49a9f949883868402', 'text': 'Inclusion of quality measures in future technical projects', 'metadata': {'coordinates': {'points': ((72.0, 306.95189999999997), (72.0, 318.3519), (371.27639999999997, 318.3519), (371.27639999999997, 306.95189999999997)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 23, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'NarrativeText', 'element_id': '754bb939bdee26b94d3cef0c4f55b5ff', 'text': 'Over the course of our engagement with the Centre, we learned that there are several additional projects in flight that could overlap with the further collection and surfacing of quality metrics on HDX. These projects include the Data-as-a-Service work (ArgoDesign) and shifts towards workflow management of the QA process. It is an open question as to how and whether these projects could address the quality measurements initiative. As these projects get scoped further, we recommend surfacing any possible overlaps early and identifying what, if anything, can be added to more quickly enable the collection and surfacing of quality measures on HDX.', 'metadata': {'coordinates': {'points': ((72.0, 330.55179999999996), (72.0, 444.15180000000004), (540.3408, 444.15180000000004), (540.3408, 330.55179999999996)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 23, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '62abe5e251db61f49a9f949883868402'}}\n",
      "{'type': 'Title', 'element_id': 'dd694a942882e43dba3e8da773f110f6', 'text': 'Trusted Org & Third Party Certification program definition', 'metadata': {'coordinates': {'points': ((72.0, 469.85179999999997), (72.0, 481.2518), (375.1908, 481.2518), (375.1908, 469.85179999999997)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 23, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'NarrativeText', 'element_id': '4fd5275b2e95edafb6817015868c0922', 'text': 'As outlined above, for Phase 2 would entail research for two initiatives that leverage external organizations as proxies for credibility: 1) A trusted organization program, which results in a trust score or level that is inherited by all datasets from that organization; and 2) Beginning research on a third party certification program, to be implemented in Phase 3, that enables third party validators of content quality (most likely domain expertise) to report whether a dataset meets assessment criteria. Although we have drafted some potential metadata options, including a trust level or score for organizations and an area in the UI to hold certifications (which could sit within the quality measurements pane described in Phase 1), further research is required to define the set of metadata and the processes of collecting that information; this would include stakeholder interviews with current contributing orgs, some of the (informally) trusted orgs, and additional third party organizations.', 'metadata': {'coordinates': {'points': ((72.0, 493.45189999999997), (72.0, 665.4518), (540.6539999999999, 665.4518), (540.6539999999999, 493.45189999999997)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 23, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'dd694a942882e43dba3e8da773f110f6'}}\n",
      "{'type': 'Title', 'element_id': '771aa18efac3a2f8e1d4ec790a55293f', 'text': 'Compare feature dependencies', 'metadata': {'coordinates': {'points': ((72.0, 691.1519), (72.0, 702.5519), (249.4896, 702.5519), (249.4896, 691.1519)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 23, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'NarrativeText', 'element_id': '05d48ff531b9961d421de17d5d559eab', 'text': 'Phase 3 considerations include the addition of domain-specific metadata, third-party certification metrics, and the ability to compare and see additional, related datasets', 'metadata': {'coordinates': {'points': ((72.0, 714.7518), (72.0, 740.7518), (523.2923999999998, 740.7518), (523.2923999999998, 714.7518)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 23, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '771aa18efac3a2f8e1d4ec790a55293f'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'f53ec79e1ec457173e5f6eed8ee30960', 'text': '19', 'metadata': {'coordinates': {'points': ((587.7184, 722.8499), (587.7184, 732.8499), (596.1184000000001, 732.8499), (596.1184000000001, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 23, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '771aa18efac3a2f8e1d4ec790a55293f'}}\n",
      "{'type': 'NarrativeText', 'element_id': '95b580a91c5c30152f459769528bfcd8', 'text': 'on HDX. Multiple conversations with the Centre and its users highlighted the critical importance of data selection. However, the notion of comparing and contrasting datasets requires standardized metadata, some of which is already collected, but much of which is not programmatically accessible. In particular, the usefulness of the compare feature, which requires additional research but could appear, for example, within the Quality Measures tab on the dataset page or the search results returned after submitting a query  increases significantly with the inclusion of technical information about the dataset that would be made available through the HXL-ation process. This is no doubt a challenge, considering that the majority of datasets are not yet HXLated. There is an open question about how much metadata must be available on HDX datasets for the compare feature to be useful.', 'metadata': {'coordinates': {'points': ((72.0, 54.406600000000026), (72.0, 211.8066), (531.2280000000001, 211.8066), (531.2280000000001, 54.406600000000026)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 24, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '771aa18efac3a2f8e1d4ec790a55293f'}}\n",
      "{'type': 'Title', 'element_id': '4f35bc173a9cf756aad81f29fcd052b9', 'text': 'Resource identification', 'metadata': {'coordinates': {'points': ((72.0, 237.50660000000005), (72.0, 248.90660000000003), (192.75360000000003, 248.90660000000003), (192.75360000000003, 237.50660000000005)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 24, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'NarrativeText', 'element_id': '0367944a0b9803f48fd4206c453c7084', 'text': 'Each of the recommendations made in this report will require resources from the Centre and, in some cases, beyond the Centre. This echoes a common refrain in technology processes and projects about resource management, and thus requires consideration within the context of roadmap prioritization across the larger team. Phase 1 will require design and technical resources for implementation, though we have tried to scope this phase to be relatively small with respect to back-end changes. Phases 2 and 3 will require additional resources, especially for the trusted org and third party validation programs and UX / Product Management / Development resources for the compare datasets feature set. Additionally, any work with third parties requires not only building but also maintaining relationships over time.', 'metadata': {'coordinates': {'points': ((72.0, 261.10660000000007), (72.0, 403.9066), (541.4939999999998, 403.9066), (541.4939999999998, 261.10660000000007)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 24, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '4f35bc173a9cf756aad81f29fcd052b9'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'f33f9884082b71ac2f4ce1c3f08ebd7f', 'text': '20', 'metadata': {'coordinates': {'points': ((586.7935, 722.8499), (586.7935, 732.8499), (597.0435, 732.8499), (597.0435, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 24, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '4f35bc173a9cf756aad81f29fcd052b9'}}\n",
      "{'type': 'Title', 'element_id': 'd8abc739835a0285e7c977ed44d10ead', 'text': 'VIII. CONCLUSION', 'metadata': {'coordinates': {'points': ((258.5837, 58.381599999999935), (258.5837, 90.1816), (357.3691, 90.1816), (357.3691, 58.381599999999935)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 25, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'NarrativeText', 'element_id': '0098319cfafcfdc96ea69ba2c0ae91f3', 'text': 'This report outlines the findings from a five-week research and design sprint, undertaken between February into early March 2023, by the DNP team, to deliver a set of implementable prototypes for quality metrics indicators on the HDX site (Phase 1). While the process included contending with some known  and some new  challenges, we are pleased to share that this sprint has concluded in a number of valuable findings, a concrete set of designs based on content that is already available on or collected by HDX, a determination of the path forward of a summation score that indicates whether the information is available, rather than an normative grade on the information itself, and prospects for future work (Phases 2 and 3). We are also delivering complete prototypes of two distinct datasets as an illustration of the information that can be conveyed in the Phase 1 quality measures pane of the HDX site.', 'metadata': {'coordinates': {'points': ((72.0, 101.35180000000003), (72.0, 258.7518), (535.3991999999998, 258.7518), (535.3991999999998, 101.35180000000003)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 25, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'd8abc739835a0285e7c977ed44d10ead'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'e879dbe5fa8209b78a388e559ff37af2', 'text': 'In summary, HDX already attends to dataset quality. We found that a lot could be gained simply by consolidating disparate elements from the HDX upload and review process, and making this information readily available to dataset users. We also found that summing the information that is provided within four discrete sections (with a numerator but no denominator) enables for a gentle indicator of quantity of information without penalizing others for not having that information.', 'metadata': {'coordinates': {'points': ((72.0, 270.9519), (72.0, 355.3519), (542.2523999999999, 355.3519), (542.2523999999999, 270.9519)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 25, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'd8abc739835a0285e7c977ed44d10ead'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'd928f5ff4d3911c4b71ea90d5e00e290', 'text': 'Many fields that involve data-driven decision making are only now starting to ask questions about dataset quality  questions that HDX has already answered and started to build into its systems. With a concrete, phased approach, HDX can implement quality measures for data in a way that meets its users needs and sets an example for many other fields. DNP looks forward to continued collaboration in this process.', 'metadata': {'coordinates': {'points': ((72.0, 367.55179999999996), (72.0, 437.3519), (542.2655999999998, 437.3519), (542.2655999999998, 367.55179999999996)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 25, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'd8abc739835a0285e7c977ed44d10ead'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '0b0fcd4f68709962f1c7b9a6dd2b9311', 'text': '21', 'metadata': {'coordinates': {'points': ((587.8884, 722.8499), (587.8884, 732.8499), (595.9484, 732.8499), (595.9484, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 25, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'd8abc739835a0285e7c977ed44d10ead'}}\n",
      "{'type': 'Title', 'element_id': '26578dee61e4a0737a4cd1c0b212a945', 'text': 'IX. APPENDIX', 'metadata': {'coordinates': {'points': ((270.2388, 58.381599999999935), (270.2388, 90.1816), (341.7648, 90.1816), (341.7648, 58.381599999999935)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 26, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'f96532d85e2d7931ebf0c715091aea28', 'text': 'Figure 1. Matrix aligning data quality principles across several organizations, with HDX in blue.', 'metadata': {'coordinates': {'points': ((72.0, 470.589), (72.0, 480.089), (492.832, 480.089), (492.832, 470.589)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 26, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '26578dee61e4a0737a4cd1c0b212a945'}}\n",
      "{'type': 'NarrativeText', 'element_id': 'c3c54f07c97b17187d71813f9f90799b', 'text': 'Documents cited:', 'metadata': {'coordinates': {'points': ((72.0, 485.18899999999996), (72.0, 494.68899999999996), (154.338, 494.68899999999996), (154.338, 485.18899999999996)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 26, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '26578dee61e4a0737a4cd1c0b212a945'}}\n",
      "{'type': 'NarrativeText', 'element_id': '3e5ca67c5592fc035abd274d6e7f96d4', 'text': 'a. USAID, Democratic Republic of Congo, How to conduct a data quality assessment (DQA): An', 'metadata': {'coordinates': {'points': ((99.0, 508.789), (99.0, 518.289), (533.584, 518.289), (533.584, 508.789)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 26, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '26578dee61e4a0737a4cd1c0b212a945'}}\n",
      "{'type': 'Title', 'element_id': '2c96201f88b0ebc3eae623d76dd2c7bf', 'text': 'Aid Memoir for a COR/AOR (March 2012)', 'metadata': {'coordinates': {'points': ((108.0, 523.3889999999999), (108.0, 532.8889999999999), (299.02599999999995, 532.8889999999999), (299.02599999999995, 523.3889999999999)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 26, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'NarrativeText', 'element_id': '4724ae9f8e5073051a9af289b6444fb0', 'text': 'b. Frontier Technologies Hub, releasing the power of digital data for development: a guide to new', 'metadata': {'coordinates': {'points': ((99.0, 546.989), (99.0, 556.489), (537.3119999999999, 556.489), (537.3119999999999, 546.989)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 26, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '2c96201f88b0ebc3eae623d76dd2c7bf'}}\n",
      "{'type': 'NarrativeText', 'element_id': '4b25b99fd627b057f571542c03c03074', 'text': 'opportunities (June 2019)', 'metadata': {'coordinates': {'points': ((108.0, 561.5889999999999), (108.0, 571.0889999999999), (225.08799999999997, 571.0889999999999), (225.08799999999997, 561.5889999999999)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 26, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '2c96201f88b0ebc3eae623d76dd2c7bf'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'c25ee93e49df985b60423250c6e6778b', 'text': 'c. Data Science & Ethics Group, A Framework for the Ethical Use of Advanced Data Science', 'metadata': {'coordinates': {'points': ((99.0, 585.189), (99.0, 594.689), (516.6349999999999, 594.689), (516.6349999999999, 585.189)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 26, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '2c96201f88b0ebc3eae623d76dd2c7bf'}}\n",
      "{'type': 'Title', 'element_id': '5c764666a414ad9b4f79b604e045cfbe', 'text': 'Methods in the Humanitarian Sector (April 2020) - https://www.hum-dseg.org/dseg-ethical-', 'metadata': {'coordinates': {'points': ((108.0, 599.789), (108.0, 609.289), (523.0619999999999, 609.289), (523.0619999999999, 599.789)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 26, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': '0133d18fa7e4e243bb53d19885bd8614', 'text': 'framework', 'metadata': {'coordinates': {'points': ((108.0, 614.389), (108.0, 623.889), (155.529, 623.889), (155.529, 614.389)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 26, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'bd2c74bdd6aad300990dbd987d7cacf2', 'text': 'd. International Committee of the Red Cross, Handbook on Data Protection in Humanitarian', 'metadata': {'coordinates': {'points': ((99.0, 637.989), (99.0, 647.489), (512.0019999999998, 647.489), (512.0019999999998, 637.989)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 26, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '0133d18fa7e4e243bb53d19885bd8614'}}\n",
      "{'type': 'Title', 'element_id': 'e1bbf2e11bff3394a86a450e9ea0fd36', 'text': 'Action. Second Edition (2020) - https://missingpersons.icrc.org/library/handbook-data-', 'metadata': {'coordinates': {'points': ((108.0, 652.5889999999999), (108.0, 662.0889999999999), (501.85399999999976, 662.0889999999999), (501.85399999999976, 652.5889999999999)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 26, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': 'db269e0eca326bf7fd66bd0d363920a5', 'text': 'protection-humanitarian-action-second-edition', 'metadata': {'coordinates': {'points': ((108.0, 667.189), (108.0, 676.689), (318.6959999999999, 676.689), (318.6959999999999, 667.189)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 26, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '72481ab8956b614bd8e30d2554a77d8f', 'text': 'e. The United Nations Statistics Division, Generic Data Quality Assurance Framework for a UN', 'metadata': {'coordinates': {'points': ((99.0, 690.789), (99.0, 700.289), (524.7010000000001, 700.289), (524.7010000000001, 690.789)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 26, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'db269e0eca326bf7fd66bd0d363920a5'}}\n",
      "{'type': 'Title', 'element_id': 'd756797a1968fe7a6daf9a8ceaf5cbb0', 'text': 'Agency (September 2015) - https://unstats.un.org/unsd/unsystem/Documents-Sept2015/', 'metadata': {'coordinates': {'points': ((108.0, 705.389), (108.0, 714.889), (511.8819999999997, 714.889), (511.8819999999997, 705.389)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 26, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'Title', 'element_id': 'ac8438aa0a6fb3b95144916b3afa2ee7', 'text': 'GSQAF-GenericData-Sept2015.pdf', 'metadata': {'coordinates': {'points': ((108.0, 719.989), (108.0, 729.489), (267.477, 729.489), (267.477, 719.989)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 26, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '5656bffc8386005b5d85c21afe83a967'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'b3e6f737dfaffaca6c36d0eb40a8d3b4', 'text': '22', 'metadata': {'coordinates': {'points': ((586.8884, 722.8499), (586.8884, 732.8499), (596.9484000000001, 732.8499), (596.9484000000001, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 26, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'ac8438aa0a6fb3b95144916b3afa2ee7'}}\n",
      "{'type': 'Header', 'element_id': '685f5cc45612c20bfadad93ae9b55945', 'text': 'Quality Measures for Humanitarian Data', 'metadata': {'coordinates': {'points': ((0.0, 0.0), (0.0, 0.0), (612.0, 0.0), (612.0, 0.0)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 27, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': 'e9deb6d63d2f94938605d8e9d821b0d2', 'text': 'Figure 8. Phase 1 content in Quality Measures Pane on HDX site.', 'metadata': {'coordinates': {'points': ((161.8533, 637.1875), (161.8533, 646.6875), (450.34130000000005, 646.6875), (450.34130000000005, 637.1875)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 27, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': '685f5cc45612c20bfadad93ae9b55945'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '75873ce6a3514a5bbb90b9d3735e5df8', 'text': '23', 'metadata': {'coordinates': {'points': ((586.9385, 722.8499), (586.9385, 732.8499), (596.8985, 732.8499), (596.8985, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 27, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'e9deb6d63d2f94938605d8e9d821b0d2'}}\n",
      "{'type': 'Header', 'element_id': 'f49e0f84a5b182cbd8116a05dfbad062', 'text': 'Quality Measures for Humanitarian Data', 'metadata': {'coordinates': {'points': ((0.0, 0.0), (0.0, 0.0), (612.0, 0.0), (612.0, 0.0)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 28, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Title', 'element_id': 'e557731cd93c6b567b82fd7a877e0edb', 'text': 'Figure 9. HDX Search view with Quality Measure counts.', 'metadata': {'coordinates': {'points': ((178.983, 396.33889999999997), (178.983, 405.83889999999997), (433.21000000000004, 405.83889999999997), (433.21000000000004, 396.33889999999997)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 28, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'f49e0f84a5b182cbd8116a05dfbad062'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '43234d9ed69d6a65b4ad3fc1da92d15f', 'text': '24', 'metadata': {'coordinates': {'points': ((586.9984, 722.8499), (586.9984, 732.8499), (596.8383999999999, 732.8499), (596.8383999999999, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 28, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'e557731cd93c6b567b82fd7a877e0edb'}}\n",
      "{'type': 'Header', 'element_id': '733977fb3a05ca7735ca0d3bfc03e957', 'text': 'Quality Measures for Humanitarian Data', 'metadata': {'coordinates': {'points': ((0.0, 0.0), (0.0, 0.0), (612.0, 0.0), (612.0, 0.0)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 29, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Footer', 'element_id': 'cdf32b09567280de281450e17f0ffd3d', 'text': 'Figure 10a. Views of Quality Measures Panes (Phase 1) for two example datasets - dataset 1 of 2.', 'metadata': {'coordinates': {'points': ((92.1999, 744.3389), (92.1999, 753.8389), (519.9958999999998, 753.8389), (519.9958999999998, 744.3389)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 29, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'UncategorizedText', 'element_id': '02d167a6d503bfd0472889895a39253f', 'text': '25', 'metadata': {'coordinates': {'points': ((586.9534, 722.8499), (586.9534, 732.8499), (596.8833999999999, 732.8499), (596.8833999999999, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 29, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Header', 'element_id': '17a85389825a60a7ad93225f69db5ce8', 'text': 'Quality Measures for Humanitarian Data', 'metadata': {'coordinates': {'points': ((0.0, 0.0), (0.0, 0.0), (612.0, 0.0), (612.0, 0.0)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 30, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Footer', 'element_id': '5399589269ae0c2af2e2b28a45b61ffd', 'text': 'Figure 10b. Views of Quality Measures Panes (Phase 1) for two example datasets - dataset 2 of 2.', 'metadata': {'coordinates': {'points': ((89.3101, 744.3389), (89.3101, 753.8389), (522.8850999999999, 753.8389), (522.8850999999999, 744.3389)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 30, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'bfbcb2ecba2dd31a4bcde81e0160a6de', 'text': '26', 'metadata': {'coordinates': {'points': ((586.8685, 722.8499), (586.8685, 732.8499), (596.9685000000001, 732.8499), (596.9685000000001, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 30, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'Header', 'element_id': 'd522437d770e627f3bb14d1a2c45ca02', 'text': 'Quality Measures for Humanitarian Data', 'metadata': {'coordinates': {'points': ((0.0, 0.0), (0.0, 0.0), (612.0, 0.0), (612.0, 0.0)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 31, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n",
      "{'type': 'NarrativeText', 'element_id': '3168567934936d5e7e9bd7b3383824f9', 'text': 'Figure 11. Similar Datasets comparison sketch, to be refined in Phase 3.', 'metadata': {'coordinates': {'points': ((145.6388, 303.18609999999995), (145.6388, 312.68609999999995), (466.5528000000001, 312.68609999999995), (466.5528000000001, 303.18609999999995)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 31, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'd522437d770e627f3bb14d1a2c45ca02'}}\n",
      "{'type': 'UncategorizedText', 'element_id': 'e1a2c4886d6301a6ecee0dd37b3bcaa4', 'text': '27', 'metadata': {'coordinates': {'points': ((587.2084, 722.8499), (587.2084, 732.8499), (596.6283999999999, 732.8499), (596.6283999999999, 722.8499)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 31, 'languages': ['eng'], 'filetype': 'application/pdf', 'parent_id': 'd522437d770e627f3bb14d1a2c45ca02'}}\n",
      "{'type': 'Footer', 'element_id': '1fc7e620ebeb2cdb637c66747183cd70', 'text': ' 2023 Data Nutrition Project', 'metadata': {'coordinates': {'points': ((258.2339, 748.9465), (258.2339, 755.9465), (353.7559, 755.9465), (353.7559, 748.9465)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': '../data/pdf', 'filename': 'F-62.pdf', 'last_modified': '2026-01-19T15:23:02', 'page_number': 32, 'languages': ['eng'], 'filetype': 'application/pdf'}}\n"
     ]
    }
   ],
   "source": [
    "for el in pdf_elements:\n",
    "    print(el.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c207dfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Title',\n",
       " 'element_id': 'c61a9b38a9d6298964b86638210a4622',\n",
       " 'text': 'QUALITY MEASURES FOR HUMANITARIAN DATA',\n",
       " 'metadata': {'coordinates': {'points': ((83.5767, 330.3082),\n",
       "    (83.5767, 396.9582),\n",
       "    (537.5593000000001, 396.9582),\n",
       "    (537.5593000000001, 330.3082)),\n",
       "   'system': 'PixelSpace',\n",
       "   'layout_width': 612.0,\n",
       "   'layout_height': 792.0},\n",
       "  'file_directory': '../data/pdf',\n",
       "  'filename': 'F-62.pdf',\n",
       "  'last_modified': '2026-01-19T15:23:02',\n",
       "  'page_number': 1,\n",
       "  'languages': ['eng'],\n",
       "  'filetype': 'application/pdf'}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [ele.to_dict() for ele in pdf_elements]\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7197ef6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "chunk_by_title(\n",
      "    elements: \u001b[33m'Iterable[Element]'\u001b[39m,\n",
      "    *,\n",
      "    combine_text_under_n_chars: \u001b[33m'Optional[int]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    include_orig_elements: \u001b[33m'Optional[bool]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    max_characters: \u001b[33m'Optional[int]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    multipage_sections: \u001b[33m'Optional[bool]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    new_after_n_chars: \u001b[33m'Optional[int]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    overlap: \u001b[33m'Optional[int]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    overlap_all: \u001b[33m'Optional[bool]'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      ") -> \u001b[33m'list[Element]'\u001b[39m\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "\u001b[38;5;28;01mdef\u001b[39;00m chunk_by_title(\n",
      "    elements: Iterable[Element],\n",
      "    *,\n",
      "    combine_text_under_n_chars: Optional[int] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    include_orig_elements: Optional[bool] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    max_characters: Optional[int] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    multipage_sections: Optional[bool] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    new_after_n_chars: Optional[int] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    overlap: Optional[int] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    overlap_all: Optional[bool] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      ") -> list[Element]:\n",
      "    \u001b[33m\"\"\"Uses title elements to identify sections within the document for chunking.\u001b[39m\n",
      "\n",
      "\u001b[33m    Splits off into a new CompositeElement when a title is detected or if metadata changes, which\u001b[39m\n",
      "\u001b[33m    happens when page numbers or sections change. Cuts off sections once they have exceeded a\u001b[39m\n",
      "\u001b[33m    character length of max_characters.\u001b[39m\n",
      "\n",
      "\u001b[33m    Parameters\u001b[39m\n",
      "\u001b[33m    ----------\u001b[39m\n",
      "\u001b[33m    elements\u001b[39m\n",
      "\u001b[33m        A list of unstructured elements. Usually the output of a partition function.\u001b[39m\n",
      "\u001b[33m    combine_text_under_n_chars\u001b[39m\n",
      "\u001b[33m        Combines elements (for example a series of titles) until a section reaches a length of\u001b[39m\n",
      "\u001b[33m        n characters. Defaults to `max_characters` which combines chunks whenever space allows.\u001b[39m\n",
      "\u001b[33m        Specifying 0 for this argument suppresses combining of small chunks. Note this value is\u001b[39m\n",
      "\u001b[33m        \"capped\" at the `new_after_n_chars` value since a value higher than that would not change\u001b[39m\n",
      "\u001b[33m        this parameter's effect.\u001b[39m\n",
      "\u001b[33m    include_orig_elements\u001b[39m\n",
      "\u001b[33m        When `True` (default), add elements from pre-chunk to the `.metadata.orig_elements` field\u001b[39m\n",
      "\u001b[33m        of the chunk(s) formed from that pre-chunk. Among other things, this allows access to\u001b[39m\n",
      "\u001b[33m        original-element metadata that cannot be consolidated and is dropped in the course of\u001b[39m\n",
      "\u001b[33m        chunking.\u001b[39m\n",
      "\u001b[33m    max_characters\u001b[39m\n",
      "\u001b[33m        Chunks elements text and text_as_html (if present) into chunks of length\u001b[39m\n",
      "\u001b[33m        n characters (hard max)\u001b[39m\n",
      "\u001b[33m    multipage_sections\u001b[39m\n",
      "\u001b[33m        If True, sections can span multiple pages. Defaults to True.\u001b[39m\n",
      "\u001b[33m    new_after_n_chars\u001b[39m\n",
      "\u001b[33m        Cuts off new sections once they reach a length of n characters (soft max). Defaults to\u001b[39m\n",
      "\u001b[33m        `max_characters` when not specified, which effectively disables any soft window.\u001b[39m\n",
      "\u001b[33m        Specifying 0 for this argument causes each element to appear in a chunk by itself (although\u001b[39m\n",
      "\u001b[33m        an element with text longer than `max_characters` will be still be split into two or more\u001b[39m\n",
      "\u001b[33m        chunks).\u001b[39m\n",
      "\u001b[33m    overlap\u001b[39m\n",
      "\u001b[33m        Specifies the length of a string (\"tail\") to be drawn from each chunk and prefixed to the\u001b[39m\n",
      "\u001b[33m        next chunk as a context-preserving mechanism. By default, this only applies to split-chunks\u001b[39m\n",
      "\u001b[33m        where an oversized element is divided into multiple chunks by text-splitting.\u001b[39m\n",
      "\u001b[33m    overlap_all\u001b[39m\n",
      "\u001b[33m        Default: `False`. When `True`, apply overlap between \"normal\" chunks formed from whole\u001b[39m\n",
      "\u001b[33m        elements and not subject to text-splitting. Use this with caution as it entails a certain\u001b[39m\n",
      "\u001b[33m        level of \"pollution\" of otherwise clean semantic chunk boundaries.\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "    opts = _ByTitleChunkingOptions.new(\n",
      "        combine_text_under_n_chars=combine_text_under_n_chars,\n",
      "        include_orig_elements=include_orig_elements,\n",
      "        max_characters=max_characters,\n",
      "        multipage_sections=multipage_sections,\n",
      "        new_after_n_chars=new_after_n_chars,\n",
      "        overlap=overlap,\n",
      "        overlap_all=overlap_all,\n",
      "    )\n",
      "    \u001b[38;5;28;01mreturn\u001b[39;00m _chunk_by_title(elements, opts)\n",
      "\u001b[31mFile:\u001b[39m      e:\\the leo programmer\\internships\\nrsc\\assignments\\testing-models-huge-dataset\\.venv\\lib\\site-packages\\unstructured\\chunking\\title.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "chunk_by_title??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a4948d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE = {\"Header\", \"Footer\", \"UncategorizedText\"}\n",
    "\n",
    "elements = [\n",
    "    el for el in pdf_elements\n",
    "    if el.category not in IGNORE and el.text.strip()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e484ea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group elements by section title\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "sections = []\n",
    "current_section = {\n",
    "    \"title\": None,\n",
    "    \"elements\": [],\n",
    "    \"page_start\": None\n",
    "}\n",
    "\n",
    "for el in elements:\n",
    "    if el.category == \"Title\":\n",
    "        if current_section[\"elements\"]:\n",
    "            sections.append(current_section)\n",
    "\n",
    "        current_section = {\n",
    "            \"title\": el.text,\n",
    "            \"elements\": [],\n",
    "            \"page_start\": el.metadata.page_number\n",
    "        }\n",
    "    else:\n",
    "        current_section[\"elements\"].append(el)\n",
    "\n",
    "# flush\n",
    "if current_section[\"elements\"]:\n",
    "    sections.append(current_section)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888ed9cc",
   "metadata": {},
   "source": [
    "##  Input: simplified `elements` list (in order)\n",
    "\n",
    "Assume this is what `elements` looks like:\n",
    "\n",
    "```text\n",
    "1. Title           | \"I. BACKGROUND\"          | page 5\n",
    "2. NarrativeText   | \"The purpose of this...\" | page 5\n",
    "3. ListItem        | \"User research...\"       | page 5\n",
    "4. NarrativeText   | \"We conducted...\"        | page 5\n",
    "5. Title           | \"II. CHALLENGES\"          | page 6\n",
    "6. NarrativeText   | \"There are many...\"      | page 6\n",
    "7. NarrativeText   | \"Challenge 1 - ...\"      | page 6\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  Initial state (before loop starts)\n",
    "\n",
    "```python\n",
    "sections = []\n",
    "\n",
    "current_section = {\n",
    "    \"title\": None,\n",
    "    \"elements\": [],\n",
    "    \"page_start\": None\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  Loop iteration-by-iteration\n",
    "\n",
    "---\n",
    "\n",
    "###  Iteration 1\n",
    "\n",
    "**Element:** `Title | \"I. BACKGROUND\"`\n",
    "\n",
    "```python\n",
    "if el.category == \"Title\":  # TRUE\n",
    "```\n",
    "\n",
    "Check:\n",
    "\n",
    "```python\n",
    "if current_section[\"elements\"]:  # []\n",
    "```\n",
    "\n",
    " FALSE (empty)\n",
    "\n",
    "So nothing is appended yet.\n",
    "\n",
    "Now start new section:\n",
    "\n",
    "```python\n",
    "current_section = {\n",
    "    \"title\": \"I. BACKGROUND\",\n",
    "    \"elements\": [],\n",
    "    \"page_start\": 5\n",
    "}\n",
    "```\n",
    "\n",
    " **State now:**\n",
    "\n",
    "```\n",
    "current_section = BACKGROUND (empty)\n",
    "sections = []\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Iteration 2\n",
    "\n",
    "**Element:** `NarrativeText | \"The purpose of this...\"`\n",
    "\n",
    "```python\n",
    "if el.category == \"Title\":  # FALSE\n",
    "```\n",
    "\n",
    "So:\n",
    "\n",
    "```python\n",
    "current_section[\"elements\"].append(el)\n",
    "```\n",
    "\n",
    " **State now:**\n",
    "\n",
    "```\n",
    "current_section:\n",
    "  title = \"I. BACKGROUND\"\n",
    "  elements = [\"The purpose of this...\"]\n",
    "sections = []\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Iteration 3\n",
    "\n",
    "**Element:** `ListItem | \"User research...\"`\n",
    "\n",
    "Same path:\n",
    "\n",
    "```python\n",
    "current_section[\"elements\"].append(el)\n",
    "```\n",
    "\n",
    " **State now:**\n",
    "\n",
    "```\n",
    "current_section:\n",
    "  title = \"I. BACKGROUND\"\n",
    "  elements = [\n",
    "    \"The purpose of this...\",\n",
    "    \"User research...\"\n",
    "  ]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Iteration 4\n",
    "\n",
    "**Element:** `NarrativeText | \"We conducted...\"`\n",
    "\n",
    "Append again.\n",
    "\n",
    " **State now:**\n",
    "\n",
    "```\n",
    "current_section:\n",
    "  title = \"I. BACKGROUND\"\n",
    "  elements = [\n",
    "    \"The purpose of this...\",\n",
    "    \"User research...\",\n",
    "    \"We conducted...\"\n",
    "  ]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Iteration 5\n",
    "\n",
    "**Element:** `Title | \"II. CHALLENGES\"`\n",
    "\n",
    "```python\n",
    "if el.category == \"Title\":  # TRUE\n",
    "```\n",
    "\n",
    "Now check:\n",
    "\n",
    "```python\n",
    "if current_section[\"elements\"]:  # NOT empty\n",
    "```\n",
    "\n",
    "So we **save the previous section**:\n",
    "\n",
    "```python\n",
    "sections.append(current_section)\n",
    "```\n",
    "\n",
    " **sections now contains:**\n",
    "\n",
    "```\n",
    "[\n",
    "  {\n",
    "    title: \"I. BACKGROUND\",\n",
    "    elements: [3 items],\n",
    "    page_start: 5\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "Now start a new section:\n",
    "\n",
    "```python\n",
    "current_section = {\n",
    "    \"title\": \"II. CHALLENGES\",\n",
    "    \"elements\": [],\n",
    "    \"page_start\": 6\n",
    "}\n",
    "```\n",
    "\n",
    " **State now:**\n",
    "\n",
    "```\n",
    "current_section = CHALLENGES (empty)\n",
    "sections = [BACKGROUND]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Iteration 6\n",
    "\n",
    "**Element:** `NarrativeText | \"There are many...\"`\n",
    "\n",
    "Append:\n",
    "\n",
    "```python\n",
    "current_section[\"elements\"].append(el)\n",
    "```\n",
    "\n",
    " **State:**\n",
    "\n",
    "```\n",
    "current_section:\n",
    "  title = \"II. CHALLENGES\"\n",
    "  elements = [\"There are many...\"]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  Iteration 7\n",
    "\n",
    "**Element:** `NarrativeText | \"Challenge 1 - ...\"`\n",
    "\n",
    "Append again.\n",
    "\n",
    " **State:**\n",
    "\n",
    "```\n",
    "current_section:\n",
    "  title = \"II. CHALLENGES\"\n",
    "  elements = [\n",
    "    \"There are many...\",\n",
    "    \"Challenge 1 - ...\"\n",
    "  ]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  Loop ends\n",
    "\n",
    "Now this code runs:\n",
    "\n",
    "```python\n",
    "if current_section[\"elements\"]:\n",
    "    sections.append(current_section)\n",
    "```\n",
    "\n",
    "This saves the **final section**, which otherwise would be lost.\n",
    "\n",
    "---\n",
    "\n",
    "##  Final output: `sections`\n",
    "\n",
    "```python\n",
    "[\n",
    "  {\n",
    "    \"title\": \"I. BACKGROUND\",\n",
    "    \"elements\": [\n",
    "      \"The purpose of this...\",\n",
    "      \"User research...\",\n",
    "      \"We conducted...\"\n",
    "    ],\n",
    "    \"page_start\": 5\n",
    "  },\n",
    "  {\n",
    "    \"title\": \"II. CHALLENGES\",\n",
    "    \"elements\": [\n",
    "      \"There are many...\",\n",
    "      \"Challenge 1 - ...\"\n",
    "    ],\n",
    "    \"page_start\": 6\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  What changed from before?\n",
    "\n",
    "Before:\n",
    "\n",
    "```\n",
    "7 independent elements\n",
    "```\n",
    "\n",
    "After:\n",
    "\n",
    "```\n",
    "2 meaningful sections\n",
    "```\n",
    "\n",
    "This is the **exact transformation** your code performs.\n",
    "\n",
    "---\n",
    "\n",
    "##  Why this matters\n",
    "\n",
    "* Chunking now respects **document meaning**\n",
    "* Retrieval returns **topic-complete answers**\n",
    "* LLM doesnt guess context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "924a3fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Figure 9. HDX Search view with Quality Measure counts.',\n",
       " 'elements': [<unstructured.documents.elements.NarrativeText at 0x2598bb2f2f0>],\n",
       " 'page_start': 28}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78271efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section wise chunking: grouping by titles and splitting large sections\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,       # or 500-700 tokens\n",
    "    chunk_overlap=200,     # optional\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \"]\n",
    "\n",
    ")\n",
    "\n",
    "chunks = []\n",
    "\n",
    "for sec in sections:\n",
    "    # merge section text\n",
    "    section_text = \"\\n\\n\".join(el.text for el in sec[\"elements\"])\n",
    "\n",
    "    # split section into chunks\n",
    "    sub_chunks = splitter.split_text(section_text)\n",
    "\n",
    "    # prepend title to each sub-chunk\n",
    "    for sub in sub_chunks:\n",
    "        cleaned = sub.lstrip(\" .\\n\")\n",
    "        chunks.append({\n",
    "            \"content\": f\"{sec['title']}\\n\\n{cleaned}\",\n",
    "            \"title\": sec['title'],                    # section title\n",
    "            \"page_start\": sec['page_start'],          # first page of section\n",
    "            \"page_end\": sec['elements'][-1].metadata.page_number,  # last page of section\n",
    "            \"source\": sec['elements'][0].metadata.filename,        # file name\n",
    "            \"category\": [el.category for el in sec[\"elements\"]]   # list of element types\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abe24f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 0 ---\n",
      "Goals\n",
      "\n",
      "The purpose of this Data Labeling project was for select members of the Data Nutrition Project team to research and prototype possible quality measures for humanitarian datasets that are hosted on the HDX platform, which is owned and managed by the UN Centre for Humanitarian Data. The scope included:\n",
      "\n",
      "User and Platform Research. We conducted user research with the Centre team (and additional stakeholders suggested by the Centre) to learn about 1) Different conceptions of data quality in the humanitarian sector; 2) How users find and select data on HDX, including priority of criteria; 3) The current DPT / HDX team QA workflow with regards to assessing data quality.\n",
      "\n",
      "Quality Measurement Prototype. Building on user research and an assessment of the state of the data and the needs in play, and using two preselected datasets as examples, we prototyped a quality measures label for HDX. The prototyping involved varying degrees of fidelity and was shaped by feedback from the Centre team.\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Goals\n",
      "\n",
      "Preliminary thoughts on Scalability. Through research and prototyping, we began to explore how this effort could scale, including paths toward automatability. Our findings are discussed in this report.\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Philosophy\n",
      "\n",
      "The Data Nutrition Project is a non-profit initiative that formed in 2018 to develop tools and practices to improve transparency into datasets. Our team is interdisciplinary, and we leverage insights from a variety of fields, including product development, data science, ethics, engineering, design, and education. Our approach with our Nutrition Labels for Datasets is threefold: 1) We encourage the creation, documentation, and publishing of higher quality data; 2) We enable transparency into datasets through our legible, extensible, interactive framework; and 3) Our Labels provide education about what kinds of information a user should ascertain before using a dataset. We bring this approach into our work with clients, where we prioritize user-centered design, realistic goals, and practitioner-focused outcomes, informed by our experience working in data transparency initiatives and with the real tradeoffs and tensions faced by data practitioners\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Philosophy\n",
      "\n",
      "In seeking to do work that is both applied and realizable, we aim to provide not only a long-term vision but also a roadmap with recommendations for future iterations of a project.\n"
     ]
    }
   ],
   "source": [
    "for i, ch in enumerate(chunks[:4]):\n",
    "    print(f\"\\n--- Chunk {i} ---\")\n",
    "    print(ch[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1b14d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Goals\\n\\nThe purpose of this Data Labeling project was for select members of the Data Nutrition Project team to research and prototype possible quality measures for humanitarian datasets that are hosted on the HDX platform, which is owned and managed by the UN Centre for Humanitarian Data. The scope included:\\n\\nUser and Platform Research. We conducted user research with the Centre team (and additional stakeholders suggested by the Centre) to learn about 1) Different conceptions of data quality in the humanitarian sector; 2) How users find and select data on HDX, including priority of criteria; 3) The current DPT / HDX team QA workflow with regards to assessing data quality.\\n\\nQuality Measurement Prototype. Building on user research and an assessment of the state of the data and the needs in play, and using two preselected datasets as examples, we prototyped a quality measures label for HDX. The prototyping involved varying degrees of fidelity and was shaped by feedback from the Centre team.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36de4acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'II. CHALLENGES\\n\\nThere are many challenges that can be impediments to dataset quality. This is certainly the case in the humanitarian sector, where crises unfold quickly and data capture will almost always be imperfect, often as a consequence of the need for rapid collection. Furthermore, on a more philosophical level, the assigning of rankings, scores, or grades to a dataset will always be tricky business, for the legitimacy of the scoring standards themselves can undermine the effort for scoring in the first place. We believe it is useful to explicitly enumerate these challenges before we describe our recommendations. The latter were formed in light of the former, which will be familiar to the HDX team and to others who have worked on dataset metrics, measures, and assessments.\\n\\nChallenge 1 - Identifying scoring methods that are succinct while not overly simplistic',\n",
       " 'title': 'II. CHALLENGES',\n",
       " 'page_start': 6,\n",
       " 'page_end': 7,\n",
       " 'source': 'F-62.pdf',\n",
       " 'category': ['NarrativeText',\n",
       "  'NarrativeText',\n",
       "  'NarrativeText',\n",
       "  'NarrativeText',\n",
       "  'NarrativeText',\n",
       "  'NarrativeText',\n",
       "  'NarrativeText',\n",
       "  'NarrativeText',\n",
       "  'NarrativeText',\n",
       "  'NarrativeText',\n",
       "  'NarrativeText',\n",
       "  'NarrativeText']}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8fd49ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'II. CHALLENGES\\n\\nChallenge 1 - Identifying scoring methods that are succinct while not overly simplistic\\n\\nScores are meant to provide information quickly and ease comparison, while inviting further exploration. They can, however, risk being reductive or overly simplistic. This is particularly difficult when comparing datasets whose provenances are entirely different. A score that is too simplistic will not only be useless but may also seem arbitrary. A single score to compare across inconsistent data types or domains may risk both. Depending on the scoring framework, there is the additional challenge of validating accuracy: what is the rubric by which this score was determined? How is accuracy of evaluation defined and ensured?\\n\\nChallenge 2 - Balancing scalable (quantitative) & comprehensive (qualitative) measures',\n",
       " 'title': 'II. CHALLENGES',\n",
       " 'page_start': 6,\n",
       " 'page_end': 7,\n",
       " 'source': 'F-62.pdf',\n",
       " 'category': ['NarrativeText',\n",
       "  'NarrativeText',\n",
       "  'NarrativeText',\n",
       "  'NarrativeText',\n",
       "  'NarrativeText',\n",
       "  'NarrativeText',\n",
       "  'NarrativeText',\n",
       "  'NarrativeText',\n",
       "  'NarrativeText',\n",
       "  'NarrativeText',\n",
       "  'NarrativeText',\n",
       "  'NarrativeText']}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8126fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections[0]\n",
    "section_text = \"\\n\\n\".join(el.text for el in sec[\"elements\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2de409f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Figure 11. Similar Datasets comparison sketch, to be refined in Phase 3.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638fe8d1",
   "metadata": {},
   "source": [
    "### **Generate embeddings and index with Chroma**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2163b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings and indexing...\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings and index with Chroma\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "chunk_docs = [\n",
    "    Document(\n",
    "        page_content=chunk[\"content\"],\n",
    "        metadata={\n",
    "            \"title\": chunk[\"title\"],\n",
    "            \"page_start\": chunk[\"page_start\"],\n",
    "            \"page_end\": chunk[\"page_end\"],\n",
    "            \"source\": chunk[\"source\"],\n",
    "            \"category\": \", \".join(chunk[\"category\"])  # convert list to string\n",
    "        }\n",
    "    )\n",
    "    for chunk in chunks\n",
    "]\n",
    "\n",
    "print(\"Generating embeddings and indexing...\")\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunk_docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_name=\"unstructured_test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f16c06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 relevant chunks:\n",
      "\n",
      "---\n",
      "Source: F-62.pdf\n",
      "Pages: 14 - 14\n",
      "Title: / Owner and Third-Party expert\n",
      "Content: / Owner and Third-Party expert\n",
      "\n",
      "organizations. These could be binary...\n",
      "\n",
      "---\n",
      "Source: F-62.pdf\n",
      "Pages: 14 - 14\n",
      "Title: / Owner and Third-Party expert\n",
      "Content: / Owner and Third-Party expert\n",
      "\n",
      "organizations. These could be binary...\n",
      "\n",
      "---\n",
      "Source: F-62.pdf\n",
      "Pages: 14 - 14\n",
      "Title: / Owner and Third-Party expert\n",
      "Content: / Owner and Third-Party expert\n",
      "\n",
      "organizations. These could be binary...\n",
      "\n",
      "---\n",
      "Source: F-62.pdf\n",
      "Pages: 14 - 14\n",
      "Title: / Owner and Third-Party expert\n",
      "Content: / Owner and Third-Party expert\n",
      "\n",
      "organizations. These could be binary...\n",
      "\n",
      "---\n",
      "Source: F-62.pdf\n",
      "Pages: 14 - 14\n",
      "Title: / Owner and Third-Party expert\n",
      "Content: / Owner and Third-Party expert\n",
      "\n",
      "organizations. These could be binary...\n"
     ]
    }
   ],
   "source": [
    "# Test retrieval\n",
    "vectorstore_retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 5}\n",
    ")\n",
    "\n",
    "# Test query\n",
    "query = \"Graduation rates of Students with disabilities in higher education institutions\"\n",
    "relevant_docs = vectorstore_retriever.invoke(query)\n",
    "\n",
    "print(f\"Found {len(relevant_docs)} relevant chunks:\")\n",
    "for doc in relevant_docs:\n",
    "    print(\"\\n---\")\n",
    "    print(f\"Source: {doc.metadata['source']}\")\n",
    "    print(f\"Pages: {doc.metadata['page_start']} - {doc.metadata['page_end']}\")\n",
    "    print(f\"Title: {doc.metadata['title']}\")\n",
    "    print(f\"Content: {doc.page_content[:500]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dcad3262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "Source: F-62.pdf\n",
      "Pages: 14 - 14\n",
      "Title: / Owner and Third-Party expert\n",
      "Content: / Owner and Third-Party expert\n",
      "\n",
      "organizations. These could be binary...\n",
      "\n",
      "---\n",
      "Source: F-62.pdf\n",
      "Pages: 14 - 14\n",
      "Title: / Owner and Third-Party expert\n",
      "Content: / Owner and Third-Party expert\n",
      "\n",
      "organizations. These could be binary...\n",
      "\n",
      "---\n",
      "Source: F-62.pdf\n",
      "Pages: 14 - 14\n",
      "Title: / Owner and Third-Party expert\n",
      "Content: / Owner and Third-Party expert\n",
      "\n",
      "organizations. These could be binary...\n",
      "\n",
      "---\n",
      "Source: F-62.pdf\n",
      "Pages: 14 - 14\n",
      "Title: / Owner and Third-Party expert\n",
      "Content: / Owner and Third-Party expert\n",
      "\n",
      "organizations. These could be binary...\n"
     ]
    }
   ],
   "source": [
    "similar_docs = vectorstore.similarity_search(\"Graduation rates of Students with disabilities in higher education institutions\")\n",
    "\n",
    "for doc in similar_docs:\n",
    "    print(\"\\n---\")\n",
    "    print(f\"Source: {doc.metadata['source']}\")\n",
    "    print(f\"Pages: {doc.metadata['page_start']} - {doc.metadata['page_end']}\")\n",
    "    print(f\"Title: {doc.metadata['title']}\")\n",
    "    print(f\"Content: {doc.page_content[:500]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c86e8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36a983cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Testing LLM Response Just with a minimal Prompt Template\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RunnablePassthrough\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_ollama\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OllamaLLM\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1412\u001b[39m, in \u001b[36m_handle_fromlist\u001b[39m\u001b[34m(module, fromlist, import_, recursive)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\The Leo Programmer\\Internships\\NRSC\\Assignments\\testing-models-huge-dataset\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\__init__.py:129\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr_name)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(attr_name: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m    128\u001b[39m     module_name = _dynamic_imports.get(attr_name)\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     result = \u001b[43mimport_attr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__spec__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m     \u001b[38;5;28mglobals\u001b[39m()[attr_name] = result\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\The Leo Programmer\\Internships\\NRSC\\Assignments\\testing-models-huge-dataset\\.venv\\Lib\\site-packages\\langchain_core\\_import_utils.py:35\u001b[39m, in \u001b[36mimport_attr\u001b[39m\u001b[34m(attr_name, module_name, package)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m         module = \u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodule_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     37\u001b[39m         msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodule \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not found (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     88\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\The Leo Programmer\\Internships\\NRSC\\Assignments\\testing-models-huge-dataset\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\passthrough.py:18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, RootModel\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m override\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     19\u001b[39m     Other,\n\u001b[32m     20\u001b[39m     Runnable,\n\u001b[32m     21\u001b[39m     RunnableParallel,\n\u001b[32m     22\u001b[39m     RunnableSerializable,\n\u001b[32m     23\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     RunnableConfig,\n\u001b[32m     26\u001b[39m     acall_func_with_variable_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     patch_config,\n\u001b[32m     31\u001b[39m )\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     33\u001b[39m     AddableDict,\n\u001b[32m     34\u001b[39m     ConfigurableFieldSpec,\n\u001b[32m     35\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\The Leo Programmer\\Internships\\NRSC\\Assignments\\testing-models-huge-dataset\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:44\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m override\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m beta_decorator\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallbacks\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmanager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsyncCallbackManager, CallbackManager\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mload\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mserializable\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     46\u001b[39m     Serializable,\n\u001b[32m     47\u001b[39m     SerializedConstructor,\n\u001b[32m     48\u001b[39m     SerializedNotImplemented,\n\u001b[32m     49\u001b[39m )\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     51\u001b[39m     RunnableConfig,\n\u001b[32m     52\u001b[39m     acall_func_with_variable_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m     62\u001b[39m     set_config_context,\n\u001b[32m     63\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\The Leo Programmer\\Internships\\NRSC\\Assignments\\testing-models-huge-dataset\\.venv\\Lib\\site-packages\\langchain_core\\callbacks\\manager.py:32\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mglobals\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_debug\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseMessage, get_buffer_string\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtracers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     33\u001b[39m     _configure_hooks,\n\u001b[32m     34\u001b[39m     _get_trace_callbacks,\n\u001b[32m     35\u001b[39m     _get_tracer_project,\n\u001b[32m     36\u001b[39m     _tracing_v2_is_enabled,\n\u001b[32m     37\u001b[39m     tracing_v2_callback_var,\n\u001b[32m     38\u001b[39m )\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtracers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlangchain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LangChainTracer\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtracers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstdout\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConsoleCallbackHandler\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\The Leo Programmer\\Internships\\NRSC\\Assignments\\testing-models-huge-dataset\\.venv\\Lib\\site-packages\\langchain_core\\tracers\\context.py:18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangsmith\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_helpers \u001b[38;5;28;01mas\u001b[39;00m ls_rh\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangsmith\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils \u001b[38;5;28;01mas\u001b[39;00m ls_utils\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtracers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlangchain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LangChainTracer\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtracers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrun_collector\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RunCollectorCallbackHandler\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\The Leo Programmer\\Internships\\NRSC\\Assignments\\testing-models-huge-dataset\\.venv\\Lib\\site-packages\\langchain_core\\tracers\\langchain.py:14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangsmith\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_trees \u001b[38;5;28;01mas\u001b[39;00m rt\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangsmith\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils \u001b[38;5;28;01mas\u001b[39;00m ls_utils\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtenacity\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     15\u001b[39m     Retrying,\n\u001b[32m     16\u001b[39m     retry_if_exception_type,\n\u001b[32m     17\u001b[39m     stop_after_attempt,\n\u001b[32m     18\u001b[39m     wait_exponential_jitter,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m override\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_runtime_environment\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\The Leo Programmer\\Internships\\NRSC\\Assignments\\testing-models-huge-dataset\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:28\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mabc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ABC, abstractmethod\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconcurrent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m futures\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _utils\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Import all built-in retry strategies for easier usage.\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mretry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m retry_base  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1331\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:935\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:991\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1087\u001b[39m, in \u001b[36mget_code\u001b[39m\u001b[34m(self, fullname)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1186\u001b[39m, in \u001b[36mget_data\u001b[39m\u001b[34m(self, path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Testing LLM Response Just with a minimal Prompt Template\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Your llama2 model for answering\n",
    "llm = OllamaLLM(model=\"qwen2.5:1.5b\")\n",
    "\n",
    "# Convert vectorstore to a retriever\n",
    "vectorstore_retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = \"\"\"\n",
    "Use the following context to answer the question as accurately as possible.\n",
    "If the answer is not present in the context, say \"Not available\".\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# Create the chain\n",
    "rag_chain = (\n",
    "    {\"context\": vectorstore_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "# Invoke with just the question string\n",
    "question = \"Graduation rates of Students with disabilities in higher education institutions\"\n",
    "answer = rag_chain.invoke(question)\n",
    "\n",
    "print(f\"Q: {question}\")\n",
    "print(\"Ans: \" + answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a49b00de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What are the challenges mentioned here?\n",
      "Ans: Not available\n"
     ]
    }
   ],
   "source": [
    "# Invoke with just the question string\n",
    "question = \"What are the challenges mentioned here?\"\n",
    "answer = rag_chain.invoke(question)\n",
    "\n",
    "print(f\"Q: {question}\")\n",
    "print(\"Ans: \" + answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "13519aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What was the primary purpose of the Data Labeling project conducted for the HDX platform?\n",
      "Ans: Not available.\n"
     ]
    }
   ],
   "source": [
    "# Invoke with just the question string\n",
    "question = \"What was the primary purpose of the Data Labeling project conducted for the HDX platform?\"\n",
    "answer = rag_chain.invoke(question)\n",
    "\n",
    "print(f\"Q: {question}\")\n",
    "print(\"Ans: \" + answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b4f95a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is identified as the most common challenge in dataset transparency efforts?\n",
      "Ans: Not available.\n"
     ]
    }
   ],
   "source": [
    "# Invoke with just the question string\n",
    "question = \"What is identified as the most common challenge in dataset transparency efforts?\"\n",
    "answer = rag_chain.invoke(question)\n",
    "\n",
    "print(f\"Q: {question}\")\n",
    "print(\"Ans: \" + answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5c5cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: How does the 'compare' feature proposed for Phase 3 depend on the 'HXL-ation' process?\n",
      "Ans: The 'compare' feature proposed for Phase 3 depends directly on the 'HXL-ation' process. Specifically, the context states that \"the addition of third party certifications and automated analyses by domain will provide the content for such comparison.\" This implies a dependency between the two processes as they work together to fulfill the need for robust dataset comparison in Phase 3.\n"
     ]
    }
   ],
   "source": [
    "# Invoke with just the question string\n",
    "question = \"How does the 'compare' feature proposed for Phase 3 depend on the 'HXL-ation' process?\"\n",
    "answer = rag_chain.invoke(question)\n",
    "\n",
    "print(f\"Q: {question}\")\n",
    "print(\"Ans: \" + answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b021076b",
   "metadata": {},
   "source": [
    "# **Implementing the Hybrid Retrieval**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa027e4",
   "metadata": {},
   "source": [
    "                             | DOCUMENTS |\n",
    "                              -----------\n",
    "                                   |\n",
    "                ------------------- -------------------\n",
    "                |                                     |\n",
    "                |                                     |\n",
    "        | Vector Index                       Keyword Index   \n",
    "         (Chroma +                             (BM25)       \n",
    "         nomic-embed)                      ------------------- \n",
    "        ------------------                            |\n",
    "                |                                     |\n",
    "                |                                     |\n",
    "                ------------------- -------------------\n",
    "                                   |\n",
    "                                   |\n",
    "                                   V\n",
    "                             Hybrid Retriever\n",
    "                                   |\n",
    "                                   |\n",
    "                                   V\n",
    "                               Re-Ranker\n",
    "                                   |\n",
    "                                   |\n",
    "                                   V\n",
    "                                  LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b9e0a2",
   "metadata": {},
   "source": [
    "### 1. BM25 Indexing (Keyword Indexing)\n",
    "\n",
    "BM25 computes a relevance score between a query 'q' and a document 'd' using three main components: Term Frequency (TF), Inverse Document Frequency (IDF) and Document Length Normalization.\n",
    "\n",
    "BM25 (Best Matching 25) is a ranking function used in information retrieval to estimate document relevance for a query, improving upon TF-IDF by incorporating term frequency saturation and document length normalization. It calculates a score based on IDF (inverse document frequency) and a frequency component that limits the impact of repeatedly appearing terms. [1, 2, 3]  \n",
    "The FormulaFor a query $Q$ with terms $q_1, ..., q_n$, the BM25 score of a document $D$ is:$\\text{Score}(D, Q) = \\sum_{i=1}^{n} \\text{IDF}(q_i) \\cdot \\frac{f(q_i, D) \\cdot (k_1 + 1)}{f(q_i, D) + k_1 \\cdot (1 - b + b \\cdot \\frac{|D|}{\\text{avgdl}})}$ [2, 4, 5]  \n",
    "Formula Components \n",
    "\n",
    " : Term frequency of query term $q_i$ in document $D$. \n",
    " : Length of document $D$ (number of words). \n",
    " : Average document length in the collection. \n",
    " : Free parameter (usually $1.2$$2.0$) that controls term frequency saturation. \n",
    " : Free parameter (usually $0.75$) that controls document length normalization. \n",
    " : Inverse Document Frequency, often calculated as:$\\text{IDF}(q_i) = \\ln\\left(\\frac{N - n(q_i) + 0.5}{n(q_i) + 0.5} + 1\\right)$ \n",
    "\n",
    "\t : Total number of documents. \n",
    "\t : Number of documents containing $q_i$. [4, 5, 6, 7, 8, 9]  \n",
    "\n",
    "Key Concepts \n",
    "\n",
    " Term Frequency Saturation: As $f(q_i, D)$ increases, the score increases, but it caps out, meaning multiple occurrences of a word matter less after a certain point. \n",
    " Document Length Normalization: The $\\frac{|D|}{\\text{avgdl}}$ term reduces scores for longer documents, ensuring short, concise documents are not unfairly penalized. [5, 10]  \n",
    "\n",
    "AI responses may include mistakes.\n",
    "\n",
    "[1]https://en.wikipedia.org/wiki/Okapi_BM25\n",
    "[2]https://www.luigisbox.com/search-glossary/bm25/\n",
    "[3]https://docs.langchain.com/oss/python/integrations/retrievers/bm25\n",
    "[4]https://docs.vespa.ai/en/ranking/bm25.html\n",
    "[5]https://www.geeksforgeeks.org/nlp/what-is-bm25-best-matching-25-algorithm/\n",
    "[6]https://www.kopp-online-marketing.com/what-is-bm25\n",
    "[7]https://www.youtube.com/watch?v=YL-3G5-xVYU\n",
    "[8]https://medium.com/@kimdoil1211/bm25-for-developers-a-guide-to-smarter-keyword-search-e6d83e8c8c8c\n",
    "[9]https://www.ai-bites.net/tf-idf-and-bm25-for-rag-a-complete-guide/\n",
    "[10]https://www.elastic.co/blog/practical-bm25-part-2-the-bm25-algorithm-and-its-variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68f46629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    chunk_docs,\n",
    "    bm25_variant=\"plus\",    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a630495c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'Figure 9. HDX Search view with Quality Measure counts.', 'page_start': 28, 'page_end': 31, 'source': 'F-62.pdf', 'category': 'NarrativeText'}, page_content='Figure 9. HDX Search view with Quality Measure counts.\\n\\nFigure 11. Similar Datasets comparison sketch, to be refined in Phase 3.'),\n",
       " Document(metadata={'title': 'Aid Memoir for a COR/AOR (March 2012)', 'page_start': 26, 'page_end': 26, 'source': 'F-62.pdf', 'category': 'NarrativeText, NarrativeText'}, page_content='Aid Memoir for a COR/AOR (March 2012)\\n\\nb. Frontier Technologies Hub, releasing the power of digital data for development: a guide to new\\n\\nopportunities (June 2019)'),\n",
       " Document(metadata={'title': 'IX. APPENDIX', 'page_start': 26, 'page_end': 26, 'source': 'F-62.pdf', 'category': 'NarrativeText, NarrativeText, NarrativeText'}, page_content='IX. APPENDIX\\n\\nFigure 1. Matrix aligning data quality principles across several organizations, with HDX in blue.\\n\\nDocuments cited:\\n\\na. USAID, Democratic Republic of Congo, How to conduct a data quality assessment (DQA): An'),\n",
       " Document(metadata={'title': 'VIII. CONCLUSION', 'page_start': 25, 'page_end': 25, 'source': 'F-62.pdf', 'category': 'NarrativeText, NarrativeText, NarrativeText'}, page_content='VIII. CONCLUSION\\n\\nIn summary, HDX already attends to dataset quality. We found that a lot could be gained simply by consolidating disparate elements from the HDX upload and review process, and making this information readily available to dataset users. We also found that summing the information that is provided within four discrete sections (with a numerator but no denominator) enables for a gentle indicator of quantity of information without penalizing others for not having that information.\\n\\nMany fields that involve data-driven decision making are only now starting to ask questions about dataset quality  questions that HDX has already answered and started to build into its systems. With a concrete, phased approach, HDX can implement quality measures for data in a way that meets its users needs and sets an example for many other fields. DNP looks forward to continued collaboration in this process.')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = bm25_retriever.invoke(\"retrieval augmented generation\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91b7118",
   "metadata": {},
   "source": [
    "**Decision Table:**\n",
    "\n",
    "| Question type        | Retrieval |\n",
    "| -------------------- | --------- |\n",
    "| Exact fact           | Lexical   |\n",
    "| Numbers / tables     | Lexical   |\n",
    "| Laws / policies      | Lexical   |\n",
    "| Headings / titles    | Lexical   |\n",
    "| Open-ended           | Semantic  |\n",
    "| Explanatory          | Semantic  |\n",
    "| User unsure of terms | Semantic  |\n",
    "| Research / discovery | Semantic  |\n",
    "\n",
    "**What is RRF?**\n",
    "\n",
    "RRF = Reciprocal Rank Fusion\n",
    "\n",
    "* ---> It is a ranking-level fusion technique\n",
    "* ---> It does NOT use scores\n",
    "* ---> It only uses positions (ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3300c2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def doc_hash(doc):\n",
    "    return hashlib.md5(doc.page_content.encode(\"utf-8\")).hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d6178a",
   "metadata": {},
   "source": [
    "## **Reciprocal Rank Fusion (RRF)**\n",
    "\n",
    "Reciprocal Rank Fusion (RRF) is a popular, unsupervised method used in Retrieval-Augmented Generation (RAG) to combine ranked results from multiple search systems (e.g., hybrid search combining semantic vector search and keyword-based sparse search) into a single, optimized, and more relevant ranking. [1, 2]  \n",
    "It is highly effective because it doesn't require training data or complex tuning, and it favors documents that consistently appear at the top of multiple search methods. [3, 4, 5, 6]  \n",
    "The RRF Formula \n",
    "The RRF score for a document $d$ is calculated by summing its reciprocal rank across all retrievers: [1]  \n",
    "$\\text{RRF}(d) = \\sum_{r \\in R} \\frac{1}{k + \\text{rank}(d)}$ \n",
    "\n",
    " : The document being scored. \n",
    " : The set of rankers (e.g., Vector Search, BM25). \n",
    " : The position of the document in the results list (starting from 1). \n",
    " : A constant used to minimize the impact of low-ranked documents (often set to 60). [1, 7]  \n",
    "\n",
    "Step-by-Step RRF Calculation \n",
    "\n",
    "1. Retrieve Results: Run the user query through multiple systems (e.g., Dense Vector search and Sparse BM25 search). \n",
    "2. Assign Scores: For each document in each result set, calculate its individual score using $\\frac{1}{k + \\text{rank}}$. \n",
    "\n",
    "\t Example: If a document is #1 in Vector search, its score is $\\frac{1}{60+1} = 0.01639$. \n",
    "\t Example: If the same document is #5 in BM25, its score is $\\frac{1}{60+5} = 0.01538$. \n",
    "\n",
    "3. Sum Scores: Add the scores from all retrievers for each unique document. \n",
    "4. Final Ranking: Sort the documents in descending order based on their total RRF score. [2, 3, 8, 9, 10]  \n",
    "\n",
    "Why RRF is Used in GenAI/RAG \n",
    "\n",
    " Robustness: Combines the semantic understanding of vector search with the keyword precision of traditional search. \n",
    " No Training Needed: Unlike Learn-to-Rank (LTR), RRF is an unsupervised algorithm. \n",
    " Small  Advantage: A $k$ value of 60 is generally chosen to provide a good balance between the influence of top-ranked and lower-ranked items. \n",
    " Handles Ties: Helps break ties among lower-ranked items effectively. [1, 2, 11, 12, 13]  \n",
    "\n",
    "Example RRF Calculation \n",
    "Imagine two documents ($A$ and $B$) retrieved by two systems ($S_1$, $S_2$). \n",
    "\n",
    "| Document [3, 14] | Rank ($S_1$) | Rank ($S_2$) | RRF Calculation ($k=60$) | Total Score  |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Doc A | 1 | 2 | $1/(60+1) + 1/(60+2)$ | $\\approx 0.0325$  |\n",
    "| Doc B | 4 | 1 | $1/(60+4) + 1/(60+1)$ | $\\approx 0.0320$  |\n",
    "\n",
    "In this scenario, Document A is prioritized slightly higher due to its stronger top-1 placement, even though both appear in the top 4 of both lists. \n",
    "Implementation Example (LlamaIndex) \n",
    " [15]  \n",
    "\n",
    "AI responses may include mistakes.\n",
    "\n",
    "[1]https://medium.com/@devalshah1619/mathematical-intuition-behind-reciprocal-rank-fusion-rrf-explained-in-2-mins-002df0cc5e2a\n",
    "[2]https://medium.com/@mudassar.hakim/designing-retrieval-in-rag-dense-sparse-and-the-rrf-merge-layer-bc176207de50\n",
    "[3]https://learn.microsoft.com/en-us/azure/search/hybrid-search-ranking\n",
    "[4]https://mycodingjourney.hashnode.dev/how-ai-ranks-better-with-rrf-the-genius-of-merging-search-results\n",
    "[5]https://www.youtube.com/watch?v=px4YBYrz0NU\n",
    "[6]https://www.paradedb.com/learn/search-concepts/reciprocal-rank-fusion\n",
    "[7]https://medium.com/dataseries/generative-ai-qa-model-using-chroma-and-mistral-7b-565088031e80\n",
    "[8]https://www.youtube.com/watch?v=6dDvfGrxFns\n",
    "[9]https://www.linkedin.com/pulse/newmind-ai-journal-62-newmind-ai-m4ynf\n",
    "[10]https://weaviate.io/blog/hybrid-search-explained\n",
    "[11]https://www.linkedin.com/pulse/newmind-ai-journal-62-newmind-ai-m4ynf\n",
    "[12]https://www.researchgate.net/publication/221301121_Reciprocal_Rank_Fusion_outperforms_Condorcet_and_Individual_Rank_Learning_Methods\n",
    "[13]https://jusky8.medium.com/learning-to-rank-for-information-retrieval-9a0bd9f0b27d\n",
    "[14]https://dev.to/lucash_ribeiro_dev/graph-augmented-hybrid-retrieval-and-multi-stage-re-ranking-a-framework-for-high-fidelity-chunk-50ca\n",
    "[15]https://developers.llamaindex.ai/python/examples/retrievers/reciprocal_rerank_fusion/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b56f3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Got 5 hybrid results\n"
     ]
    }
   ],
   "source": [
    "# Hybrid Retriever using RRF\n",
    "\n",
    "class HybridRetriever:\n",
    "    def __init__(self, bm25_retriever, vector_retriever, weights=[0.5, 0.5]):\n",
    "        self.bm25_retriever = bm25_retriever\n",
    "        self.vector_retriever = vector_retriever\n",
    "        self.bm25_weight = weights[0]\n",
    "        self.vector_weight = weights[1]\n",
    "\n",
    "    def invoke(self, query, k=5):\n",
    "        bm25_docs = self.bm25_retriever.invoke(query)\n",
    "        vector_docs = self.vector_retriever.invoke(query)\n",
    "\n",
    "        rrf_k = 60\n",
    "        doc_scores = {}\n",
    "        doc_map = {}\n",
    "\n",
    "        # BM25\n",
    "        for rank, doc in enumerate(bm25_docs, 1):\n",
    "            key = doc_hash(doc)\n",
    "            doc_scores[key] = self.bm25_weight / (rrf_k + rank)\n",
    "            doc_map[key] = doc\n",
    "\n",
    "        # Vector\n",
    "        for rank, doc in enumerate(vector_docs, 1):\n",
    "            key = doc_hash(doc)\n",
    "            score = self.vector_weight / (rrf_k + rank)\n",
    "            doc_scores[key] = doc_scores.get(key, 0) + score\n",
    "            doc_map[key] = doc\n",
    "\n",
    "        ranked = sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        return [doc_map[k] for k, _ in ranked[:k]]\n",
    "\n",
    "# Create hybrid retriever\n",
    "hybrid_retriever = HybridRetriever(\n",
    "    bm25_retriever=bm25_retriever,\n",
    "    vector_retriever=vectorstore_retriever,\n",
    "    weights=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "# Test it\n",
    "docs = hybrid_retriever.invoke(\"How does the 'compare' feature proposed for Phase 3 depend on the 'HXL-ation' process?\", k=5)\n",
    "print(f\"---> Got {len(docs)} hybrid results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feef5c6",
   "metadata": {},
   "source": [
    "**RE-RANKING (Stage-2 Retrieval)**\n",
    "\n",
    "A reranking model  also known as a cross-encoder  is a type of model that, given a query and document pair, will output a similarity score. We use this score to reorder the documents by relevance to our query.\n",
    "\n",
    "A two-stage retrieval system. The vector DB step will typically include a bi-encoder or sparse embedding model.\n",
    "A two-stage retrieval system. The vector DB step will typically include a bi-encoder or sparse embedding model.\n",
    "Search engineers have used rerankers in two-stage retrieval systems for a long time. In these two-stage systems, a first-stage model (an embedding model/retriever) retrieves a set of relevant documents from a larger dataset. Then, a second-stage model (the reranker) is used to rerank those documents retrieved by the first-stage model.\n",
    "\n",
    "We use two stages because retrieving a small set of documents from a large dataset is much faster than reranking a large set of documents  we'll discuss why this is the case soon  but TL;DR, rerankers are slow, and retrievers are fast.\n",
    "\n",
    "Why Rerankers?\n",
    "If a reranker is so much slower, why bother using them? The answer is that rerankers are much more accurate than embedding models.\n",
    "\n",
    "The intuition behind a bi-encoder's inferior accuracy is that bi-encoders must compress all of the possible meanings of a document into a single vector  meaning we lose information. Additionally, bi-encoders have no context on the query because we don't know the query until we receive it (we create embeddings before user query time).\n",
    "\n",
    "On the other hand, a reranker can receive the raw information directly into the large transformer computation, meaning less information loss. Because we are running the reranker at user query time, we have the added benefit of analyzing our document's meaning specific to the user query  rather than trying to produce a generic, averaged meaning.\n",
    "\n",
    "Rerankers avoid the information loss of bi-encoders  but they come with a different penalty  time.\n",
    "\n",
    "A bi-encoder model compresses the document or query meaning into a single vector. Note that the bi-encoder processes our query in the same way as it does documents, but at user query time.\n",
    "A bi-encoder model compresses the document or query meaning into a single vector. Note that the bi-encoder processes our query in the same way as it does documents, but at user query time.\n",
    "When using bi-encoder models with vector search, we frontload all of the heavy transformer computation to when we are creating the initial vectors  that means that when a user queries our system, we have already created the vectors, so all we need to do is:\n",
    "\n",
    "Run a single transformer computation to create the query vector.\n",
    "Compare the query vector to document vectors with cosine similarity (or another lightweight metric).\n",
    "With rerankers, we are not pre-computing anything. Instead, we're feeding our query and a single other document into the transformer, running a whole transformer inference step, and outputting a single similarity score.\n",
    "\n",
    "A reranker considers query and document to produce a single similarity score over a full transformer inference step. Note that document A here is equivalent to our query.\n",
    "A reranker considers query and document to produce a single similarity score over a full transformer inference step. Note that document A here is equivalent to our query.\n",
    "Given 40M records, if we use a small reranking model like BERT on a V100 GPU  we'd be waiting more than 50 hours to return a single query result [3]. We can do the same in <100ms with encoder models and vector search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e50d358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3445c11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_docs(query, docs, top_k=5):\n",
    "    \"\"\"\n",
    "    query: str\n",
    "    docs: List[Document]\n",
    "    top_k: int\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare (query, doc_text) pairs\n",
    "    pairs = [(query, doc.page_content) for doc in docs]\n",
    "\n",
    "    # Get relevance scores\n",
    "    scores = reranker.predict(pairs)\n",
    "\n",
    "    # Attach scores to docs\n",
    "    scored_docs = list(zip(docs, scores))\n",
    "\n",
    "    # Sort by score (descending)\n",
    "    scored_docs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Return top-k docs only\n",
    "    return [doc for doc, score in scored_docs[:top_k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a4a728da",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How does the 'compare' feature proposed for Phase 3 depend on the 'HXL-ation' process?\"\n",
    "candidate_docs = hybrid_retriever.invoke(query, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d4f29a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='db041ae1-00f5-4f25-926d-7930cc543bb7', metadata={'page_start': 21, 'category': 'NarrativeText, NarrativeText, NarrativeText', 'title': 'Rationale', 'page_end': 22, 'source': 'F-62.pdf'}, page_content='Rationale\\n\\nAnd, while the measures in Phase 1 are a helpful starting point to assess quality, more analysis is needed for robust dataset comparison. The addition of third party certifications and automated analyses by domain will provide the content for such comparison. Technical considerations for Phase 3 would be enumerated after the research, development, and design for Phases 2 and 3.'),\n",
       " Document(metadata={'title': 'Compare feature dependencies', 'page_start': 23, 'page_end': 24, 'source': 'F-62.pdf', 'category': 'NarrativeText, NarrativeText'}, page_content='Compare feature dependencies\\n\\nPhase 3 considerations include the addition of domain-specific metadata, third-party certification metrics, and the ability to compare and see additional, related datasets'),\n",
       " Document(metadata={'title': 'Compare feature dependencies', 'page_start': 23, 'page_end': 24, 'source': 'F-62.pdf', 'category': 'NarrativeText, NarrativeText'}, page_content='Compare feature dependencies\\n\\non HDX. Multiple conversations with the Centre and its users highlighted the critical importance of data selection. However, the notion of comparing and contrasting datasets requires standardized metadata, some of which is already collected, but much of which is not programmatically accessible. In particular, the usefulness of the compare feature, which requires additional research but could appear, for example, within the Quality Measures tab on the dataset page or the search results returned after submitting a query  increases significantly with the inclusion of technical information about the dataset that would be made available through the HXL-ation process. This is no doubt a challenge, considering that the majority of datasets are not yet HXLated. There is an open question about how much metadata must be available on HDX datasets for the compare feature to be useful.'),\n",
       " Document(metadata={'title': 'Resource identification', 'page_start': 24, 'page_end': 24, 'source': 'F-62.pdf', 'category': 'NarrativeText'}, page_content='Resource identification\\n\\nEach of the recommendations made in this report will require resources from the Centre and, in some cases, beyond the Centre. This echoes a common refrain in technology processes and projects about resource management, and thus requires consideration within the context of roadmap prioritization across the larger team. Phase 1 will require design and technical resources for implementation, though we have tried to scope this phase to be relatively small with respect to back-end changes. Phases 2 and 3 will require additional resources, especially for the trusted org and third party validation programs and UX / Product Management / Development resources for the compare datasets feature set. Additionally, any work with third parties requires not only building but also maintaining relationships over time.'),\n",
       " Document(metadata={'title': 'Prototype directions', 'page_start': 11, 'page_end': 11, 'source': 'F-62.pdf', 'category': 'NarrativeText, ListItem, NarrativeText'}, page_content='Prototype directions\\n\\n1.\\t Comparability:\\tfeatures\\tto\\tsupport\\tdataset\\tselection\\n\\nThroughout the interviews, we heard that a primary use case for data quality assessment on HDX (and more broadly in the sector) was the enabling of dataset selection, either for a particular need at hand, to join with other external or proprietary data (e.g. Combine several datasets about a particular geography), or to compare against similar datasets to assess which is best aligned for a particular use (e.g. Identifying which administrative boundary dataset is appropriate if there are several to choose from). To support this particular use case of dataset selection, which we felt was best aligned to the data principle of comparability, we proposed features that support the direct comparing and contrasting of datasets based on metadata comparison (fig. 2)')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a029b486",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_docs = rerank_docs(query, candidate_docs, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f4b5a28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'Compare feature dependencies', 'page_start': 23, 'page_end': 24, 'source': 'F-62.pdf', 'category': 'NarrativeText, NarrativeText'}, page_content='Compare feature dependencies\\n\\non HDX. Multiple conversations with the Centre and its users highlighted the critical importance of data selection. However, the notion of comparing and contrasting datasets requires standardized metadata, some of which is already collected, but much of which is not programmatically accessible. In particular, the usefulness of the compare feature, which requires additional research but could appear, for example, within the Quality Measures tab on the dataset page or the search results returned after submitting a query  increases significantly with the inclusion of technical information about the dataset that would be made available through the HXL-ation process. This is no doubt a challenge, considering that the majority of datasets are not yet HXLated. There is an open question about how much metadata must be available on HDX datasets for the compare feature to be useful.'),\n",
       " Document(metadata={'title': 'Compare feature dependencies', 'page_start': 23, 'page_end': 24, 'source': 'F-62.pdf', 'category': 'NarrativeText, NarrativeText'}, page_content='Compare feature dependencies\\n\\nPhase 3 considerations include the addition of domain-specific metadata, third-party certification metrics, and the ability to compare and see additional, related datasets'),\n",
       " Document(id='db041ae1-00f5-4f25-926d-7930cc543bb7', metadata={'page_start': 21, 'category': 'NarrativeText, NarrativeText, NarrativeText', 'title': 'Rationale', 'page_end': 22, 'source': 'F-62.pdf'}, page_content='Rationale\\n\\nAnd, while the measures in Phase 1 are a helpful starting point to assess quality, more analysis is needed for robust dataset comparison. The addition of third party certifications and automated analyses by domain will provide the content for such comparison. Technical considerations for Phase 3 would be enumerated after the research, development, and design for Phases 2 and 3.'),\n",
       " Document(metadata={'title': 'Resource identification', 'page_start': 24, 'page_end': 24, 'source': 'F-62.pdf', 'category': 'NarrativeText'}, page_content='Resource identification\\n\\nEach of the recommendations made in this report will require resources from the Centre and, in some cases, beyond the Centre. This echoes a common refrain in technology processes and projects about resource management, and thus requires consideration within the context of roadmap prioritization across the larger team. Phase 1 will require design and technical resources for implementation, though we have tried to scope this phase to be relatively small with respect to back-end changes. Phases 2 and 3 will require additional resources, especially for the trusted org and third party validation programs and UX / Product Management / Development resources for the compare datasets feature set. Additionally, any work with third parties requires not only building but also maintaining relationships over time.'),\n",
       " Document(metadata={'title': 'Prototype directions', 'page_start': 11, 'page_end': 11, 'source': 'F-62.pdf', 'category': 'NarrativeText, ListItem, NarrativeText'}, page_content='Prototype directions\\n\\n1.\\t Comparability:\\tfeatures\\tto\\tsupport\\tdataset\\tselection\\n\\nThroughout the interviews, we heard that a primary use case for data quality assessment on HDX (and more broadly in the sector) was the enabling of dataset selection, either for a particular need at hand, to join with other external or proprietary data (e.g. Combine several datasets about a particular geography), or to compare against similar datasets to assess which is best aligned for a particular use (e.g. Identifying which administrative boundary dataset is appropriate if there are several to choose from). To support this particular use case of dataset selection, which we felt was best aligned to the data principle of comparability, we proposed features that support the direct comparing and contrasting of datasets based on metadata comparison (fig. 2)')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f77d8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='281ff060-a184-43b4-8b83-b8b8653753d1', metadata={'page_end': 5, 'source': 'F-62.pdf', 'title': 'Philosophy', 'page_start': 5, 'category': 'NarrativeText'}, page_content='Philosophy\\n\\nThe Data Nutrition Project is a non-profit initiative that formed in 2018 to develop tools and practices to improve transparency into datasets. Our team is interdisciplinary, and we leverage insights from a variety of fields, including product development, data science, ethics, engineering, design, and education. Our approach with our Nutrition Labels for Datasets is threefold: 1) We encourage the creation, documentation, and publishing of higher quality data; 2) We enable transparency into datasets through our legible, extensible, interactive framework; and 3) Our Labels provide education about what kinds of information a user should ascertain before using a dataset. We bring this approach into our work with clients, where we prioritize user-centered design, realistic goals, and practitioner-focused outcomes, informed by our experience working in data transparency initiatives and with the real tradeoffs and tensions faced by data practitioners'),\n",
       " Document(metadata={'title': 'Research', 'page_start': 10, 'page_end': 10, 'source': 'F-62.pdf', 'category': 'NarrativeText, NarrativeText, NarrativeText'}, page_content='Research\\n\\nIn parallel, we conducted interviews with stakeholders that represented key points along the data collection, processing, hosting, and use timeline, including data partners (IOM, Humanitarian OpenStreetMap Team) and several within the Centre (Data Partnerships, Data Responsibility, organization onboarding, product development, quality assessment process, and others), in order to understand how the Centre thinks about quality, to learn about existing mechanisms for identifying and surfacing quality issues, and to explore future scenarios for expanding or adjusting quality assessment practices.\\n\\nFigure 1. Matrix aligning data'),\n",
       " Document(metadata={'title': 'for the data quality principle of credibility.', 'page_start': 12, 'page_end': 13, 'source': 'F-62.pdf', 'category': 'ListItem, NarrativeText, NarrativeText, NarrativeText'}, page_content='for the data quality principle of credibility.\\n\\nThe last two prototype directions are related to fitness for purpose - assessing whether what is represented in the dataset is appropriate for use (complete, timely, relevant, accurate). We found fitness for purpose metrics to be the most challenging due to the distribution of responsibility in dataset management, and the realities of data collection in humanitarian situations. Stated simply, it is very hard to assess quality without an ideal ground truth dataset against which to compare, or without access to information about the collection and processing practices of the data owner. To facilitate our analysis, we approached these measures along two axes: the assessor (data owner vs. third party), and the type of assessment (qualitative vs. quantitative) (fig. 5)'),\n",
       " Document(metadata={'title': 'Compare feature dependencies', 'page_start': 23, 'page_end': 24, 'source': 'F-62.pdf', 'category': 'NarrativeText, NarrativeText'}, page_content='Compare feature dependencies\\n\\non HDX. Multiple conversations with the Centre and its users highlighted the critical importance of data selection. However, the notion of comparing and contrasting datasets requires standardized metadata, some of which is already collected, but much of which is not programmatically accessible. In particular, the usefulness of the compare feature, which requires additional research but could appear, for example, within the Quality Measures tab on the dataset page or the search results returned after submitting a query  increases significantly with the inclusion of technical information about the dataset that would be made available through the HXL-ation process. This is no doubt a challenge, considering that the majority of datasets are not yet HXLated. There is an open question about how much metadata must be available on HDX datasets for the compare feature to be useful.'),\n",
       " Document(metadata={'title': 'Prototype directions', 'page_start': 11, 'page_end': 11, 'source': 'F-62.pdf', 'category': 'NarrativeText, ListItem, NarrativeText'}, page_content='Prototype directions\\n\\n1.\\t Comparability:\\tfeatures\\tto\\tsupport\\tdataset\\tselection\\n\\nThroughout the interviews, we heard that a primary use case for data quality assessment on HDX (and more broadly in the sector) was the enabling of dataset selection, either for a particular need at hand, to join with other external or proprietary data (e.g. Combine several datasets about a particular geography), or to compare against similar datasets to assess which is best aligned for a particular use (e.g. Identifying which administrative boundary dataset is appropriate if there are several to choose from). To support this particular use case of dataset selection, which we felt was best aligned to the data principle of comparability, we proposed features that support the direct comparing and contrasting of datasets based on metadata comparison (fig. 2)')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Explain me about data nutrition project?\"\n",
    "candidate_docs = hybrid_retriever.invoke(query, k=20)\n",
    "candidate_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "92bf9f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='281ff060-a184-43b4-8b83-b8b8653753d1', metadata={'page_end': 5, 'source': 'F-62.pdf', 'title': 'Philosophy', 'page_start': 5, 'category': 'NarrativeText'}, page_content='Philosophy\\n\\nThe Data Nutrition Project is a non-profit initiative that formed in 2018 to develop tools and practices to improve transparency into datasets. Our team is interdisciplinary, and we leverage insights from a variety of fields, including product development, data science, ethics, engineering, design, and education. Our approach with our Nutrition Labels for Datasets is threefold: 1) We encourage the creation, documentation, and publishing of higher quality data; 2) We enable transparency into datasets through our legible, extensible, interactive framework; and 3) Our Labels provide education about what kinds of information a user should ascertain before using a dataset. We bring this approach into our work with clients, where we prioritize user-centered design, realistic goals, and practitioner-focused outcomes, informed by our experience working in data transparency initiatives and with the real tradeoffs and tensions faced by data practitioners'),\n",
       " Document(metadata={'title': 'Research', 'page_start': 10, 'page_end': 10, 'source': 'F-62.pdf', 'category': 'NarrativeText, NarrativeText, NarrativeText'}, page_content='Research\\n\\nIn parallel, we conducted interviews with stakeholders that represented key points along the data collection, processing, hosting, and use timeline, including data partners (IOM, Humanitarian OpenStreetMap Team) and several within the Centre (Data Partnerships, Data Responsibility, organization onboarding, product development, quality assessment process, and others), in order to understand how the Centre thinks about quality, to learn about existing mechanisms for identifying and surfacing quality issues, and to explore future scenarios for expanding or adjusting quality assessment practices.\\n\\nFigure 1. Matrix aligning data'),\n",
       " Document(metadata={'title': 'for the data quality principle of credibility.', 'page_start': 12, 'page_end': 13, 'source': 'F-62.pdf', 'category': 'ListItem, NarrativeText, NarrativeText, NarrativeText'}, page_content='for the data quality principle of credibility.\\n\\nThe last two prototype directions are related to fitness for purpose - assessing whether what is represented in the dataset is appropriate for use (complete, timely, relevant, accurate). We found fitness for purpose metrics to be the most challenging due to the distribution of responsibility in dataset management, and the realities of data collection in humanitarian situations. Stated simply, it is very hard to assess quality without an ideal ground truth dataset against which to compare, or without access to information about the collection and processing practices of the data owner. To facilitate our analysis, we approached these measures along two axes: the assessor (data owner vs. third party), and the type of assessment (qualitative vs. quantitative) (fig. 5)'),\n",
       " Document(metadata={'title': 'Prototype directions', 'page_start': 11, 'page_end': 11, 'source': 'F-62.pdf', 'category': 'NarrativeText, ListItem, NarrativeText'}, page_content='Prototype directions\\n\\n1.\\t Comparability:\\tfeatures\\tto\\tsupport\\tdataset\\tselection\\n\\nThroughout the interviews, we heard that a primary use case for data quality assessment on HDX (and more broadly in the sector) was the enabling of dataset selection, either for a particular need at hand, to join with other external or proprietary data (e.g. Combine several datasets about a particular geography), or to compare against similar datasets to assess which is best aligned for a particular use (e.g. Identifying which administrative boundary dataset is appropriate if there are several to choose from). To support this particular use case of dataset selection, which we felt was best aligned to the data principle of comparability, we proposed features that support the direct comparing and contrasting of datasets based on metadata comparison (fig. 2)'),\n",
       " Document(metadata={'title': 'Compare feature dependencies', 'page_start': 23, 'page_end': 24, 'source': 'F-62.pdf', 'category': 'NarrativeText, NarrativeText'}, page_content='Compare feature dependencies\\n\\non HDX. Multiple conversations with the Centre and its users highlighted the critical importance of data selection. However, the notion of comparing and contrasting datasets requires standardized metadata, some of which is already collected, but much of which is not programmatically accessible. In particular, the usefulness of the compare feature, which requires additional research but could appear, for example, within the Quality Measures tab on the dataset page or the search results returned after submitting a query  increases significantly with the inclusion of technical information about the dataset that would be made available through the HXL-ation process. This is no doubt a challenge, considering that the majority of datasets are not yet HXLated. There is an open question about how much metadata must be available on HDX datasets for the compare feature to be useful.')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_docs = rerank_docs(query, candidate_docs, top_k=5)\n",
    "final_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d2123d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured Context:\n",
      "\n",
      "[Source 1]\n",
      "Document: F-62.pdf\n",
      "Section: Philosophy\n",
      "Pages: 55\n",
      "\n",
      "Content:\n",
      "Philosophy\n",
      "\n",
      "The Data Nutrition Project is a non-profit initiative that formed in 2018 to develop tools and practices to improve transparency into datasets. Our team is interdisciplinary, and we leverage insights from a variety of fields, including product development, data science, ethics, engineering, design, and education. Our approach with our Nutrition Labels for Datasets is threefold: 1) We encourage the creation, documentation, and publishing of higher quality data; 2) We enable transparency into datasets through our legible, extensible, interactive framework; and 3) Our Labels provide education about what kinds of information a user should ascertain before using a dataset. We bring this approach into our work with clients, where we prioritize user-centered design, realistic goals, and practitioner-focused outcomes, informed by our experience working in data transparency initiatives and with the real tradeoffs and tensions faced by data practitioners\n",
      "\n",
      "---\n",
      "\n",
      "[Source 2]\n",
      "Document: F-62.pdf\n",
      "Section: Research\n",
      "Pages: 1010\n",
      "\n",
      "Content:\n",
      "Research\n",
      "\n",
      "In parallel, we conducted interviews with stakeholders that represented key points along the data collection, processing, hosting, and use timeline, including data partners (IOM, Humanitarian OpenStreetMap Team) and several within the Centre (Data Partnerships, Data Responsibility, organization onboarding, product development, quality assessment process, and others), in order to understand how the Centre thinks about quality, to learn about existing mechanisms for identifying and surfacing quality issues, and to explore future scenarios for expanding or adjusting quality assessment practices.\n",
      "\n",
      "Figure 1. Matrix aligning data\n",
      "\n",
      "---\n",
      "\n",
      "[Source 3]\n",
      "Document: F-62.pdf\n",
      "Section: for the data quality principle of credibility.\n",
      "Pages: 1213\n",
      "\n",
      "Content:\n",
      "for the data quality principle of credibility.\n",
      "\n",
      "The last two prototype directions are related to fitness for purpose - assessing whether what is represented in the dataset is appropriate for use (complete, timely, relevant, accurate). We found fitness for purpose metrics to be the most challenging due to the distribution of responsibility in dataset management, and the realities of data collection in humanitarian situations. Stated simply, it is very hard to assess quality without an ideal ground truth dataset against which to compare, or without access to information about the collection and processing practices of the data owner. To facilitate our analysis, we approached these measures along two axes: the assessor (data owner vs. third party), and the type of assessment (qualitative vs. quantitative) (fig. 5)\n",
      "\n",
      "---\n",
      "\n",
      "[Source 4]\n",
      "Document: F-62.pdf\n",
      "Section: Prototype directions\n",
      "Pages: 1111\n",
      "\n",
      "Content:\n",
      "Prototype directions\n",
      "\n",
      "1.\t Comparability:\tfeatures\tto\tsupport\tdataset\tselection\n",
      "\n",
      "Throughout the interviews, we heard that a primary use case for data quality assessment on HDX (and more broadly in the sector) was the enabling of dataset selection, either for a particular need at hand, to join with other external or proprietary data (e.g. Combine several datasets about a particular geography), or to compare against similar datasets to assess which is best aligned for a particular use (e.g. Identifying which administrative boundary dataset is appropriate if there are several to choose from). To support this particular use case of dataset selection, which we felt was best aligned to the data principle of comparability, we proposed features that support the direct comparing and contrasting of datasets based on metadata comparison (fig. 2)\n",
      "\n",
      "---\n",
      "\n",
      "[Source 5]\n",
      "Document: F-62.pdf\n",
      "Section: Compare feature dependencies\n",
      "Pages: 2324\n",
      "\n",
      "Content:\n",
      "Compare feature dependencies\n",
      "\n",
      "on HDX. Multiple conversations with the Centre and its users highlighted the critical importance of data selection. However, the notion of comparing and contrasting datasets requires standardized metadata, some of which is already collected, but much of which is not programmatically accessible. In particular, the usefulness of the compare feature, which requires additional research but could appear, for example, within the Quality Measures tab on the dataset page or the search results returned after submitting a query  increases significantly with the inclusion of technical information about the dataset that would be made available through the HXL-ation process. This is no doubt a challenge, considering that the majority of datasets are not yet HXLated. There is an open question about how much metadata must be available on HDX datasets for the compare feature to be useful.\n"
     ]
    }
   ],
   "source": [
    "def build_structured_context(docs):\n",
    "    context_blocks = []\n",
    "    source_map = {}\n",
    "\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        context_blocks.append(\n",
    "            f\"\"\"\n",
    "[Source {i}]\n",
    "Document: {doc.metadata['source']}\n",
    "Section: {doc.metadata.get('title', 'N/A')}\n",
    "Pages: {doc.metadata.get('page_start')}{doc.metadata.get('page_end')}\n",
    "\n",
    "Content:\n",
    "{doc.page_content}\n",
    "\"\"\".strip()\n",
    "        )\n",
    "\n",
    "        source_map[i] = {\n",
    "            \"file\": doc.metadata[\"source\"],\n",
    "            \"section\": doc.metadata.get(\"title\"),\n",
    "            \"pages\": f\"{doc.metadata.get('page_start')}{doc.metadata.get('page_end')}\"\n",
    "        }\n",
    "\n",
    "    return \"\\n\\n---\\n\\n\".join(context_blocks), source_map\n",
    "\n",
    "structured_context, source_map = build_structured_context(final_docs)\n",
    "print(\"Structured Context:\\n\")\n",
    "print(structured_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e5a9da",
   "metadata": {},
   "source": [
    "### **LLM Integration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c0f558",
   "metadata": {},
   "source": [
    "temperature = 0\n",
    " Always pick highest-probability next token\n",
    "\n",
    "top_p = 1\n",
    " No token filtering\n",
    "\n",
    "repeat_penalty = 1\n",
    " No penalty for repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "49d8ec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Initializing the Qwen2.5:1.5b model\n",
    "llm = OllamaLLM(\n",
    "    model=\"qwen2.5:1.5b\",\n",
    "    temperature=0.0,\n",
    "    top_p=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b5f165",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a research assistant answering questions strictly from the provided document context.\n",
    "\n",
    "CRITICAL RULES (NON-NEGOTIABLE):\n",
    "1. Use ONLY the information explicitly stated in the context.\n",
    "2. Do NOT use prior knowledge, assumptions, interpretations, or reasoning beyond the text.\n",
    "3. Every factual sentence MUST end with a citation in the form [Source X].\n",
    "4. If a question has multiple sub-questions, ALL parts must be answered.\n",
    "5. If ANY part of the question cannot be answered from the context, DO NOT partially answer.\n",
    "\n",
    "MISSING INFORMATION HANDLING:\n",
    "If required information is missing or unclear, respond ONLY with:\n",
    "\"I couldnt find this information in the available documents.\"\n",
    "                                                   \n",
    "CRITICAL ANSWERABILITY RULE:\n",
    "The question may contain multiple sub-questions.\n",
    "You must answer ONLY if ALL sub-questions are explicitly and clearly answered in the provided context.\n",
    "\n",
    "If ANY sub-question is missing, unclear, or indirectly implied,\n",
    "respond ONLY with:\n",
    "\n",
    "\"I could not find information related to this question according to the provided documents.\"\n",
    "\n",
    "Do not provide partial answers.\n",
    "Do not summarize unrelated sections.\n",
    "Do not include Sources Summary when refusing.\n",
    "\n",
    "\n",
    "PROHIBITED BEHAVIOR:\n",
    "- Do NOT speculate or infer timelines, durations, or participants.\n",
    "- Do NOT explain why the information is missing.\n",
    "- Do NOT summarize document structure or page counts.\n",
    "- Do NOT reinterpret or restate the user's question.\n",
    "- Do NOT include phrases like \"it appears\", \"based on the information\", or \"indicates that\".\n",
    "\n",
    "CONTEXT:\n",
    "The following are retrieved document sections. Each section is identified by a source number.                                                                                                   \n",
    "\n",
    "{context}\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "ANSWER FORMAT:\n",
    "- Use bullet points if applicable.\n",
    "- Each sentence must end with one or more citations.\n",
    "- Do NOT include a references list.\n",
    "- Do NOT repeat the context.\n",
    "\n",
    "ANSWER:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "734e30a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    prompt_template\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7e25d2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_reranked_sources(docs):\n",
    "    \"\"\"\n",
    "    Convert reranked Document objects into a clean, readable source list\n",
    "    \"\"\"\n",
    "    formatted = []\n",
    "\n",
    "    for i, doc in enumerate(docs):\n",
    "        meta = doc.metadata or {}\n",
    "\n",
    "        source = meta.get(\"source\", \"Unknown\")\n",
    "        title = meta.get(\"title\", \"Unknown\")\n",
    "        page_start = meta.get(\"page_start\", \"?\")\n",
    "        page_end = meta.get(\"page_end\", \"?\")\n",
    "\n",
    "        formatted.append(            \n",
    "            f\"[{i+1}] Source: {source}\\n\"\n",
    "            f\"Title: {title}\\n\"\n",
    "            f\"Pages: {page_start}{page_end}\"\n",
    "        )\n",
    "\n",
    "    return \"\\n\\n\".join(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9b3346c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query(\n",
    "    query: str,\n",
    "    *,\n",
    "    hybrid_retriever,\n",
    "    reranker,\n",
    "    rag_chain,\n",
    "    top_k_retrieval: int = 20,\n",
    "    top_k_rerank: int = 5\n",
    "):\n",
    "    \"\"\"\n",
    "    End-to-end RAG pipeline:\n",
    "    Query  Hybrid Retrieval  Re-ranking  Structured Context  LLM Answer\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Stage-1: Hybrid Retrieval (BM25 + Vector)\n",
    "    candidate_docs = hybrid_retriever.invoke(\n",
    "        query,\n",
    "        k=top_k_retrieval\n",
    "    )\n",
    "\n",
    "    if not candidate_docs:\n",
    "        return \"I couldnt find relevant information for this question in the documents.\"\n",
    "\n",
    "    # 2. Stage-2: Re-ranking (Cross-encoder)\n",
    "    reranked_docs = rerank_docs(\n",
    "        query=query,\n",
    "        docs=candidate_docs,\n",
    "        top_k=top_k_rerank\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    if not reranked_docs:\n",
    "        return \"I found documents, but none were relevant enough after re-ranking.\"\n",
    "\n",
    "    # 3. Build structured context with source indices\n",
    "    context_text = build_structured_context(reranked_docs)\n",
    "\n",
    "    # 4. LLM generation\n",
    "    response = rag_chain.invoke({\n",
    "        \"context\": context_text,\n",
    "        \"question\": query\n",
    "    })\n",
    "\n",
    "    sources_summary = format_reranked_sources(reranked_docs)\n",
    "\n",
    "    return response, sources_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a0809f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      "\n",
      "('I could not find information related to this question in the provided document sections. Could you please clarify what specific detail you are looking for or share additional documents?', '[0] Source: F-62.pdf\\nTitle: Philosophy\\nPages: 55\\n\\n[1] Source: F-62.pdf\\nTitle: Recommendations\\nPages: 1515\\n\\n[2] Source: F-62.pdf\\nTitle: for the data quality principle of credibility.\\nPages: 1213\\n\\n[3] Source: F-62.pdf\\nTitle: number of categories and against a common framework.\\nPages: 1314\\n\\n[4] Source: F-62.pdf\\nTitle: / Owner and Third-Party expert\\nPages: 1414')\n"
     ]
    }
   ],
   "source": [
    "query = \"Graduation rates of Students with disabilities in higher education institutions\"\n",
    "\n",
    "response = answer_query(\n",
    "    query=query,\n",
    "    hybrid_retriever=hybrid_retriever,\n",
    "    reranker=reranker,\n",
    "    rag_chain=rag_chain,\n",
    "    top_k_retrieval=20,\n",
    "    top_k_rerank=5\n",
    ")\n",
    "\n",
    "print(\"LLM Response:\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7ba50c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      "\n",
      "The Data Nutrition Project is a non-profit initiative that was established in 2018 with the goal of developing tools and practices to enhance transparency into datasets. The team behind this project consists of individuals from various disciplines, including product development, data science, ethics, engineering, design, and education. They approach their work using three key methods: encouraging higher quality data creation and documentation, making datasets transparent through an interactive framework that provides educational information about the dataset's attributes and usage, and offering education on what specific types of information users should investigate before utilizing a dataset.\n",
      "\n",
      "The projects methodology involves interviews with stakeholders who represent different points along the data collection, processing, hosting, and use timeline. These stakeholders include both external entities like the IOM and Humanitarian OpenStreetMap Team as well as internal elements within the Centre such as Data Partnerships, Data Responsibility, organization onboarding, product development, quality assessment process, etc. The interviews help in understanding how the centre thinks about data quality and identifying existing mechanisms for detecting quality issues.\n",
      "\n",
      "To ensure their work aligns with these principles, they adopt a three-pronged approach involving comparing datasets to facilitate selection based on metadata (comparability), enabling educational awareness around what constitutes good dataset information, and assessing fitness for purposei.e., whether the data is appropriate for its intended use. Fitness for purpose assessment faces challenges related to responsibility distribution in managing datasets and dealing with limited access to quality metrics due to practical constraints inherent in humanitarian contexts.\n",
      "\n",
      "The project has developed several prototype directions that further refine their strategies. For instance, they have focused on making dataset selection straightforward by suggesting features that help compare datasets based on metadata comparisons (fig. 2). They also emphasize the importance of standardized metadata for enhancing the utility of the \"compare\" feature, which is crucial when considering technical information needed to use this tool effectively.\n",
      "\n",
      "The document does not provide explicit details about the projects specific strategies or achievements but presents a comprehensive framework that addresses transparency in data provision and evaluation based on ethical considerations and practical challenges inherent in real-world contexts.\n",
      "\n",
      "---> Sources Summary:\n",
      "[0] Source: F-62.pdf\n",
      "Title: Philosophy\n",
      "Pages: 55\n",
      "\n",
      "[1] Source: F-62.pdf\n",
      "Title: Research\n",
      "Pages: 1010\n",
      "\n",
      "[2] Source: F-62.pdf\n",
      "Title: for the data quality principle of credibility.\n",
      "Pages: 1213\n",
      "\n",
      "[3] Source: F-62.pdf\n",
      "Title: Prototype directions\n",
      "Pages: 1111\n",
      "\n",
      "[4] Source: F-62.pdf\n",
      "Title: Compare feature dependencies\n",
      "Pages: 2324\n"
     ]
    }
   ],
   "source": [
    "query = \"Explain me about data nutrition project?\"\n",
    "\n",
    "response, sources_summary = answer_query(\n",
    "    query=query,\n",
    "    hybrid_retriever=hybrid_retriever,\n",
    "    reranker=reranker,\n",
    "    rag_chain=rag_chain,\n",
    "    top_k_retrieval=20,\n",
    "    top_k_rerank=5\n",
    ")\n",
    "\n",
    "print(\"LLM Response:\\n\")\n",
    "print(response)\n",
    "print(\"\\n---> Sources Summary:\")\n",
    "print(sources_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "670f6a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      "\n",
      "The Impact on Existing Data Processes and Systems is as follows:\n",
      "\n",
      "Currently, data organizations upload their datasets to HDX either in bulk (using the HDX / CKAN APIs) or manually (using the upload form process). Many dataset quality measures are already collected during these processes. We recommend that additional information could be gathered through updating the API and the form. Our Phase 1 recommendation does not require this additional infrastructure, but instead utilizes only information that HDX already collects. In Phase 2 and beyond, there are additional automated and manual processes in which more metadata is gathered, some of which could be leveraged as quality measures. The particulars of what is gathered and when, as well as how to collect more data automatically or otherwise, require further exploration.\n",
      "\n",
      "---> Sources Summary:\n",
      "[0] Source: F-62.pdf\n",
      "Title: VII. ADDITIONAL CONSIDERATIONS\n",
      "Pages: 2323\n",
      "\n",
      "[1] Source: F-62.pdf\n",
      "Title: Technical Considerations\n",
      "Pages: 1920\n",
      "\n",
      "[2] Source: F-62.pdf\n",
      "Title: III. KEY FINDINGS\n",
      "Pages: 89\n",
      "\n",
      "[3] Source: F-62.pdf\n",
      "Title: Technical Considerations\n",
      "Pages: 1920\n"
     ]
    }
   ],
   "source": [
    "query = \"what is the impact of on existing data processes and systems\"\n",
    "\n",
    "response, sources_summary = answer_query(\n",
    "    query=query,\n",
    "    hybrid_retriever=hybrid_retriever,\n",
    "    reranker=reranker,\n",
    "    rag_chain=rag_chain,\n",
    "    top_k_retrieval=20,\n",
    "    top_k_rerank=5\n",
    ")\n",
    "\n",
    "print(\"LLM Response:\\n\")\n",
    "print(response)\n",
    "print(\"\\n---> Sources Summary:\")\n",
    "print(sources_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3102442f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      "\n",
      "I couldnt find this information in the available documents.\n",
      "\n",
      "---> Sources Summary:\n",
      "[1] Source: F-62.pdf\n",
      "Title: Phase 2\n",
      "Pages: 2121\n",
      "\n",
      "[2] Source: F-62.pdf\n",
      "Title: Goals\n",
      "Pages: 55\n",
      "\n",
      "[3] Source: F-62.pdf\n",
      "Title: Update Frequency & Last Updated date*\n",
      "Pages: 2020\n",
      "\n",
      "[4] Source: F-62.pdf\n",
      "Title: II. CHALLENGES\n",
      "Pages: 67\n",
      "\n",
      "[5] Source: F-62.pdf\n",
      "Title: II. CHALLENGES\n",
      "Pages: 67\n"
     ]
    }
   ],
   "source": [
    "query = \"When did the research campaign held? and how many days? and by whom?\"\n",
    "\n",
    "response, sources_summary = answer_query(\n",
    "    query=query,\n",
    "    hybrid_retriever=hybrid_retriever,\n",
    "    reranker=reranker,\n",
    "    rag_chain=rag_chain,\n",
    "    top_k_retrieval=20,\n",
    "    top_k_rerank=5\n",
    ")\n",
    "\n",
    "print(\"LLM Response:\\n\")\n",
    "print(response)\n",
    "print(\"\\n---> Sources Summary:\")\n",
    "print(sources_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5141d304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      "\n",
      "-I couldnt find this information in the available documents.\n",
      "\n",
      "---> Sources Summary:\n",
      "[1] Source: F-62.pdf\n",
      "Title: Phase 2\n",
      "Pages: 2121\n",
      "\n",
      "[2] Source: F-62.pdf\n",
      "Title: Goals\n",
      "Pages: 55\n",
      "\n",
      "[3] Source: F-62.pdf\n",
      "Title: Update Frequency & Last Updated date*\n",
      "Pages: 2020\n",
      "\n",
      "[4] Source: F-62.pdf\n",
      "Title: II. CHALLENGES\n",
      "Pages: 67\n",
      "\n",
      "[5] Source: F-62.pdf\n",
      "Title: II. CHALLENGES\n",
      "Pages: 67\n"
     ]
    }
   ],
   "source": [
    "query = \"When did the research campaign held? and how many days? and by whom?\"\n",
    "\n",
    "response, sources_summary = answer_query(\n",
    "    query=query,\n",
    "    hybrid_retriever=hybrid_retriever,\n",
    "    reranker=reranker,\n",
    "    rag_chain=rag_chain,\n",
    "    top_k_retrieval=20,\n",
    "    top_k_rerank=5\n",
    ")\n",
    "\n",
    "print(\"LLM Response:\\n\")\n",
    "print(response)\n",
    "print(\"\\n---> Sources Summary:\")\n",
    "print(sources_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "81b11638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      "\n",
      "- Research was conducted in Phase 2 of the project.\n",
      "- The research campaign took place from pages 21 to 21 of Document F-62.pdf.\n",
      "- The study was led by the Data Nutrition Project team.\n",
      "\n",
      "---> Sources Summary:\n",
      "[1] Source: F-62.pdf\n",
      "Title: Phase 2\n",
      "Pages: 2121\n",
      "\n",
      "[2] Source: F-62.pdf\n",
      "Title: Goals\n",
      "Pages: 55\n",
      "\n",
      "[3] Source: F-62.pdf\n",
      "Title: Update Frequency & Last Updated date*\n",
      "Pages: 2020\n",
      "\n",
      "[4] Source: F-62.pdf\n",
      "Title: II. CHALLENGES\n",
      "Pages: 67\n",
      "\n",
      "[5] Source: F-62.pdf\n",
      "Title: II. CHALLENGES\n",
      "Pages: 67\n"
     ]
    }
   ],
   "source": [
    "query = \"When did the research campaign held? and how many days? and by whom?\"\n",
    "\n",
    "response, sources_summary = answer_query(\n",
    "    query=query,\n",
    "    hybrid_retriever=hybrid_retriever,\n",
    "    reranker=reranker,\n",
    "    rag_chain=rag_chain,\n",
    "    top_k_retrieval=20,\n",
    "    top_k_rerank=5\n",
    ")\n",
    "\n",
    "print(\"LLM Response:\\n\")\n",
    "print(response)\n",
    "print(\"\\n---> Sources Summary:\")\n",
    "print(sources_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "19227733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      "\n",
      "- The research campaign and design sprint took place from February into early March 2023. \n",
      "- This period lasted for **5 weeks**.\n",
      "- The research was conducted by the DNP team, as outlined in Source [Source 1].\n",
      "\n",
      "---> Sources Summary:\n",
      "[1] Source: F-62.pdf\n",
      "Title: VIII. CONCLUSION\n",
      "Pages: 2525\n",
      "\n",
      "[2] Source: F-62.pdf\n",
      "Title: Rationale\n",
      "Pages: 2122\n",
      "\n",
      "[3] Source: F-62.pdf\n",
      "Title: Goals\n",
      "Pages: 55\n",
      "\n",
      "[4] Source: F-62.pdf\n",
      "Title: II. CHALLENGES\n",
      "Pages: 67\n"
     ]
    }
   ],
   "source": [
    "query = \"When did the research campaign and design sprint held? and how many days? and by whom?\"\n",
    "\n",
    "response, sources_summary = answer_query(\n",
    "    query=query,\n",
    "    hybrid_retriever=hybrid_retriever,\n",
    "    reranker=reranker,\n",
    "    rag_chain=rag_chain,\n",
    "    top_k_retrieval=20,\n",
    "    top_k_rerank=5\n",
    ")\n",
    "\n",
    "print(\"LLM Response:\\n\")\n",
    "print(response)\n",
    "print(\"\\n---> Sources Summary:\")\n",
    "print(sources_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0bab7ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      "\n",
      "Based on the information provided, there is no explicit mention of when the research campaign was held. Therefore, I couldnt find this information in the available documents.\n",
      "\n",
      "---> Sources Summary:\n",
      "[1] Source: F-62.pdf\n",
      "Title: Prototype directions\n",
      "Pages: 1111\n",
      "\n",
      "[2] Source: F-62.pdf\n",
      "Title: Phase 2\n",
      "Pages: 2121\n",
      "\n",
      "[3] Source: F-62.pdf\n",
      "Title: Goals\n",
      "Pages: 55\n",
      "\n",
      "[4] Source: F-62.pdf\n",
      "Title: II. CHALLENGES\n",
      "Pages: 67\n",
      "\n",
      "[5] Source: F-62.pdf\n",
      "Title: Update Frequency & Last Updated date*\n",
      "Pages: 2020\n"
     ]
    }
   ],
   "source": [
    "query = \"When did the research campaign held?\"\n",
    "\n",
    "response, sources_summary = answer_query(\n",
    "    query=query,\n",
    "    hybrid_retriever=hybrid_retriever,\n",
    "    reranker=reranker,\n",
    "    rag_chain=rag_chain,\n",
    "    top_k_retrieval=20,\n",
    "    top_k_rerank=5\n",
    ")\n",
    "\n",
    "print(\"LLM Response:\\n\")\n",
    "print(response)\n",
    "print(\"\\n---> Sources Summary:\")\n",
    "print(sources_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bc9dd5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      "\n",
      "I couldnt find this information in the available documents.\n",
      "\n",
      "---> Sources Summary:\n",
      "[1] Source: F-62.pdf\n",
      "Title: Phase 2\n",
      "Pages: 2121\n",
      "\n",
      "[2] Source: F-62.pdf\n",
      "Title: Goals\n",
      "Pages: 55\n",
      "\n",
      "[3] Source: F-62.pdf\n",
      "Title: Update Frequency & Last Updated date*\n",
      "Pages: 2020\n",
      "\n",
      "[4] Source: F-62.pdf\n",
      "Title: II. CHALLENGES\n",
      "Pages: 67\n",
      "\n",
      "[5] Source: F-62.pdf\n",
      "Title: II. CHALLENGES\n",
      "Pages: 67\n"
     ]
    }
   ],
   "source": [
    "# Responses with Temperature - 0, Top P = 0\n",
    "\n",
    "query = \"When did the research campaign held? and how many days? and by whom?\"\n",
    "\n",
    "response, sources_summary = answer_query(\n",
    "    query=query,\n",
    "    hybrid_retriever=hybrid_retriever,\n",
    "    reranker=reranker,\n",
    "    rag_chain=rag_chain,\n",
    "    top_k_retrieval=20,\n",
    "    top_k_rerank=5\n",
    ")\n",
    "\n",
    "print(\"LLM Response:\\n\")\n",
    "print(response)\n",
    "print(\"\\n---> Sources Summary:\")\n",
    "print(sources_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "daf01116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      "\n",
      "- The research and interviews conducted in the first two weeks of our sprint.\n",
      "\n",
      "---> Sources Summary:\n",
      "[1] Source: F-62.pdf\n",
      "Title: Prototype directions\n",
      "Pages: 1111\n",
      "\n",
      "[2] Source: F-62.pdf\n",
      "Title: Phase 2\n",
      "Pages: 2121\n",
      "\n",
      "[3] Source: F-62.pdf\n",
      "Title: Goals\n",
      "Pages: 55\n",
      "\n",
      "[4] Source: F-62.pdf\n",
      "Title: II. CHALLENGES\n",
      "Pages: 67\n",
      "\n",
      "[5] Source: F-62.pdf\n",
      "Title: Update Frequency & Last Updated date*\n",
      "Pages: 2020\n"
     ]
    }
   ],
   "source": [
    "query = \"When did the research campaign held?\"\n",
    "\n",
    "response, sources_summary = answer_query(\n",
    "    query=query,\n",
    "    hybrid_retriever=hybrid_retriever,\n",
    "    reranker=reranker,\n",
    "    rag_chain=rag_chain,\n",
    "    top_k_retrieval=20,\n",
    "    top_k_rerank=5\n",
    ")\n",
    "\n",
    "print(\"LLM Response:\\n\")\n",
    "print(response)\n",
    "print(\"\\n---> Sources Summary:\")\n",
    "print(sources_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20eb8ec",
   "metadata": {},
   "source": [
    "Yes, a 1.5B parameter model **will definitely hallucinate**, and generally at higher rates than larger models. Here's what research shows: [arxiv](https://arxiv.org/html/2512.22416v1)\n",
    "\n",
    "## Hallucination Tendency in Small Models\n",
    "\n",
    "**Smaller models like 1.5B parameters exhibit higher hallucination scores and greater tendency to generate factually incorrect content**. Research on the Qwen2.5 series specifically found that the 1.5B version shows higher hallucination variability compared to both smaller (0.5B) and larger (3B) versions, suggesting intermediate-sized models may have more unstable factual grounding due to incomplete knowledge retention during pretraining. [arxiv](https://arxiv.org/html/2512.22416v1)\n",
    "\n",
    "## Parameter Size Impact\n",
    "\n",
    "The general trend shows **hallucination rates decrease as parameter size increases**, though the relationship isn't strictly linear. Models with 7-9 billion parameters consistently outperform smaller models in terms of factual consistency and stable outputs. For example, SeaLLM 1.5B produces some of the highest hallucination rates among tested models. [openreview](https://openreview.net/pdf?id=AGsrWqu0dh)\n",
    "\n",
    "## Important Exception\n",
    "\n",
    "While the trend favors larger models, **training quality matters more than size alone**. Intel's Neural-chat 7B achieved just 2.8% hallucination ratelower than GPT-4's 3% despite GPT-4 having ~1.8 trillion parameters. This demonstrates that well-optimized smaller models with good training data can outperform poorly trained larger ones. [intel](https://www.intel.com/content/www/us/en/developer/articles/technical/do-smaller-models-hallucinate-more.html)\n",
    "\n",
    "### *For our RAG and semantic search work, we're using a 1.5B model locally via Ollama, so there are more hallucinations, and we have to implement strong retrieval-based grounding and fact-checking in your pipeline to mitigate this.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
