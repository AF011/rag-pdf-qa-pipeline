{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e88e7db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\The Leo Programmer\\Internships\\NRSC\\Assignments\\testing-models-huge-dataset\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Ollama LLM and Embeddings\n",
      "Loading ALL PDFs\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM, OllamaEmbeddings\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "\n",
    "print(\"Setup Ollama LLM and Embeddings\")\n",
    "print(\"Loading ALL PDFs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3b79ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PDF files found: 1076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing for Object Streams\n",
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n",
      "parsing for Object Streams\n",
      "invalid pdf header: b'\\r\\n\\r\\n\\r'\n",
      "CAUTION: startxref found while searching for %%EOF. The file might be truncated and some data might not be read.\n",
      "EOF marker not found\n",
      "Ignoring wrong pointing object 1 65536 (offset 0)\n",
      "Ignoring wrong pointing object 15 65536 (offset 0)\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      "parsing for Object Streams\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(4)\n",
      "parsing for Object Streams\n",
      "invalid pdf header: b'\\n<!DO'\n",
      "EOF marker not found\n",
      "Ignoring wrong pointing object 2 65536 (offset 0)\n",
      "Ignoring wrong pointing object 35 65536 (offset 0)\n",
      "Ignoring wrong pointing object 55 65536 (offset 0)\n",
      "Ignoring wrong pointing object 74 65536 (offset 0)\n",
      "Ignoring wrong pointing object 92 65536 (offset 0)\n",
      "Ignoring wrong pointing object 112 65536 (offset 0)\n",
      "Ignoring wrong pointing object 139 65536 (offset 0)\n",
      "Ignoring wrong pointing object 158 65536 (offset 0)\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      "parsing for Object Streams\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      "EOF marker not found\n",
      "Ignoring wrong pointing object 2 65536 (offset 0)\n",
      "Ignoring wrong pointing object 44 65536 (offset 0)\n",
      "Ignoring wrong pointing object 72 65536 (offset 0)\n",
      "Ignoring wrong pointing object 99 65536 (offset 0)\n",
      "Ignoring wrong pointing object 125 65536 (offset 0)\n",
      "Ignoring wrong pointing object 153 65536 (offset 0)\n",
      "Ignoring wrong pointing object 190 65536 (offset 0)\n",
      "Ignoring wrong pointing object 218 65536 (offset 0)\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      "XRef object at 1266 can not be read, some object may be missing\n",
      "Ignoring wrong pointing object 38 0 (offset 0)\n",
      "Ignoring wrong pointing object 39 0 (offset 0)\n",
      "Ignoring wrong pointing object 40 0 (offset 0)\n",
      "Ignoring wrong pointing object 41 0 (offset 0)\n",
      "Ignoring wrong pointing object 42 0 (offset 0)\n",
      "Ignoring wrong pointing object 43 0 (offset 0)\n",
      "Ignoring wrong pointing object 44 0 (offset 0)\n",
      "Ignoring wrong pointing object 45 0 (offset 0)\n",
      "Ignoring wrong pointing object 46 0 (offset 0)\n",
      "Ignoring wrong pointing object 47 0 (offset 0)\n",
      "Ignoring wrong pointing object 48 0 (offset 0)\n",
      "Ignoring wrong pointing object 49 0 (offset 0)\n",
      "Ignoring wrong pointing object 50 0 (offset 0)\n",
      "Ignoring wrong pointing object 51 0 (offset 0)\n",
      "Ignoring wrong pointing object 52 0 (offset 0)\n",
      "Ignoring wrong pointing object 53 0 (offset 0)\n",
      "Ignoring wrong pointing object 54 0 (offset 0)\n",
      "Ignoring wrong pointing object 55 0 (offset 0)\n",
      "Ignoring wrong pointing object 56 0 (offset 0)\n",
      "Ignoring wrong pointing object 57 0 (offset 0)\n",
      "Ignoring wrong pointing object 58 0 (offset 0)\n",
      "Ignoring wrong pointing object 59 0 (offset 0)\n",
      "Ignoring wrong pointing object 60 0 (offset 0)\n",
      "Ignoring wrong pointing object 61 0 (offset 0)\n",
      "Ignoring wrong pointing object 62 0 (offset 0)\n",
      "Ignoring wrong pointing object 63 0 (offset 0)\n",
      "Ignoring wrong pointing object 64 0 (offset 0)\n",
      "Ignoring wrong pointing object 65 0 (offset 0)\n",
      "Ignoring wrong pointing object 66 0 (offset 0)\n",
      "Ignoring wrong pointing object 67 0 (offset 0)\n",
      "Ignoring wrong pointing object 68 0 (offset 0)\n",
      "Ignoring wrong pointing object 69 0 (offset 0)\n",
      "Ignoring wrong pointing object 70 0 (offset 0)\n",
      "Ignoring wrong pointing object 71 0 (offset 0)\n",
      "Ignoring wrong pointing object 72 0 (offset 0)\n",
      "Ignoring wrong pointing object 73 0 (offset 0)\n",
      "Ignoring wrong pointing object 74 0 (offset 0)\n",
      "Ignoring wrong pointing object 75 0 (offset 0)\n",
      "Ignoring wrong pointing object 76 0 (offset 0)\n",
      "Ignoring wrong pointing object 77 0 (offset 0)\n",
      "Ignoring wrong pointing object 78 0 (offset 0)\n",
      "Ignoring wrong pointing object 79 0 (offset 0)\n",
      "Ignoring wrong pointing object 80 0 (offset 0)\n",
      "Ignoring wrong pointing object 81 0 (offset 0)\n",
      "Ignoring wrong pointing object 82 0 (offset 0)\n",
      "Ignoring wrong pointing object 83 0 (offset 0)\n",
      "Ignoring wrong pointing object 84 0 (offset 0)\n",
      "Ignoring wrong pointing object 85 0 (offset 0)\n",
      "Ignoring wrong pointing object 86 0 (offset 0)\n",
      "Ignoring wrong pointing object 87 0 (offset 0)\n",
      "Ignoring wrong pointing object 88 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 90 0 (offset 0)\n",
      "Ignoring wrong pointing object 91 0 (offset 0)\n",
      "Ignoring wrong pointing object 92 0 (offset 0)\n",
      "Ignoring wrong pointing object 93 0 (offset 0)\n",
      "Ignoring wrong pointing object 94 0 (offset 0)\n",
      "Ignoring wrong pointing object 95 0 (offset 0)\n",
      "Ignoring wrong pointing object 96 0 (offset 0)\n",
      "Ignoring wrong pointing object 97 0 (offset 0)\n",
      "Ignoring wrong pointing object 98 0 (offset 0)\n",
      "Ignoring wrong pointing object 99 0 (offset 0)\n",
      "Ignoring wrong pointing object 100 0 (offset 0)\n",
      "Ignoring wrong pointing object 101 0 (offset 0)\n",
      "Ignoring wrong pointing object 102 0 (offset 0)\n",
      "Ignoring wrong pointing object 103 0 (offset 0)\n",
      "Ignoring wrong pointing object 104 0 (offset 0)\n",
      "Ignoring wrong pointing object 105 0 (offset 0)\n",
      "Ignoring wrong pointing object 106 0 (offset 0)\n",
      "Ignoring wrong pointing object 107 0 (offset 0)\n",
      "Ignoring wrong pointing object 108 0 (offset 0)\n",
      "Ignoring wrong pointing object 109 0 (offset 0)\n",
      "Ignoring wrong pointing object 110 0 (offset 0)\n",
      "Ignoring wrong pointing object 111 0 (offset 0)\n",
      "Ignoring wrong pointing object 112 0 (offset 0)\n",
      "Ignoring wrong pointing object 113 0 (offset 0)\n",
      "Ignoring wrong pointing object 114 0 (offset 0)\n",
      "Ignoring wrong pointing object 115 0 (offset 0)\n",
      "Ignoring wrong pointing object 116 0 (offset 0)\n",
      "Ignoring wrong pointing object 117 0 (offset 0)\n",
      "Ignoring wrong pointing object 118 0 (offset 0)\n",
      "Ignoring wrong pointing object 119 0 (offset 0)\n",
      "Ignoring wrong pointing object 120 0 (offset 0)\n",
      "Ignoring wrong pointing object 121 0 (offset 0)\n",
      "Ignoring wrong pointing object 122 0 (offset 0)\n",
      "Ignoring wrong pointing object 123 0 (offset 0)\n",
      "Ignoring wrong pointing object 124 0 (offset 0)\n",
      "Ignoring wrong pointing object 125 0 (offset 0)\n",
      "Ignoring wrong pointing object 126 0 (offset 0)\n",
      "Ignoring wrong pointing object 127 0 (offset 0)\n",
      "Ignoring wrong pointing object 128 0 (offset 0)\n",
      "Ignoring wrong pointing object 129 0 (offset 0)\n",
      "Ignoring wrong pointing object 130 0 (offset 0)\n",
      "Ignoring wrong pointing object 131 0 (offset 0)\n",
      "Ignoring wrong pointing object 132 0 (offset 0)\n",
      "Ignoring wrong pointing object 133 0 (offset 0)\n",
      "Ignoring wrong pointing object 134 0 (offset 0)\n",
      "Ignoring wrong pointing object 135 0 (offset 0)\n",
      "Ignoring wrong pointing object 136 0 (offset 0)\n",
      "Ignoring wrong pointing object 137 0 (offset 0)\n",
      "Ignoring wrong pointing object 138 0 (offset 0)\n",
      "Ignoring wrong pointing object 139 0 (offset 0)\n",
      "Ignoring wrong pointing object 140 0 (offset 0)\n",
      "Ignoring wrong pointing object 141 0 (offset 0)\n",
      "Ignoring wrong pointing object 142 0 (offset 0)\n",
      "Ignoring wrong pointing object 143 0 (offset 0)\n",
      "Ignoring wrong pointing object 144 0 (offset 0)\n",
      "Ignoring wrong pointing object 145 0 (offset 0)\n",
      "Ignoring wrong pointing object 146 0 (offset 0)\n",
      "Ignoring wrong pointing object 147 0 (offset 0)\n",
      "Ignoring wrong pointing object 148 0 (offset 0)\n",
      "Ignoring wrong pointing object 149 0 (offset 0)\n",
      "Ignoring wrong pointing object 150 0 (offset 0)\n",
      "Ignoring wrong pointing object 151 0 (offset 0)\n",
      "Ignoring wrong pointing object 152 0 (offset 0)\n",
      "Ignoring wrong pointing object 153 0 (offset 0)\n",
      "Ignoring wrong pointing object 154 0 (offset 0)\n",
      "incorrect startxref pointer(3)\n",
      "parsing for Object Streams\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      "Ignoring wrong pointing object 15 0 (offset 0)\n",
      "Ignoring wrong pointing object 41 0 (offset 0)\n",
      "Ignoring wrong pointing object 43 0 (offset 0)\n",
      "Ignoring wrong pointing object 59 0 (offset 0)\n",
      "Ignoring wrong pointing object 170 0 (offset 0)\n",
      "Ignoring wrong pointing object 203 0 (offset 0)\n",
      "Ignoring wrong pointing object 519 0 (offset 0)\n",
      "incorrect startxref pointer(4)\n",
      "parsing for Object Streams\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(4)\n",
      "parsing for Object Streams\n",
      "EOF marker not found\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      "Ignoring wrong pointing object 255 0 (offset 0)\n",
      "Ignoring wrong pointing object 257 0 (offset 0)\n",
      "incorrect startxref pointer(3)\n",
      "Ignoring wrong pointing object 2 65536 (offset 0)\n",
      "Ignoring wrong pointing object 44 65536 (offset 0)\n",
      "Ignoring wrong pointing object 72 65536 (offset 0)\n",
      "Ignoring wrong pointing object 99 65536 (offset 0)\n",
      "Ignoring wrong pointing object 125 65536 (offset 0)\n",
      "Ignoring wrong pointing object 153 65536 (offset 0)\n",
      "Ignoring wrong pointing object 190 65536 (offset 0)\n",
      "Ignoring wrong pointing object 218 65536 (offset 0)\n",
      "Ignoring wrong pointing object 23 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "invalid pdf header: b'\\r\\n\\r\\n\\r'\n",
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n",
      "incorrect startxref pointer(4)\n",
      "parsing for Object Streams\n",
      "incorrect startxref pointer(4)\n",
      "parsing for Object Streams\n",
      "incorrect startxref pointer(3)\n",
      "parsing for Object Streams\n",
      "invalid pdf header: b'LZ``@'\n",
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(4)\n",
      "parsing for Object Streams\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      "invalid pdf header: b'\\r\\n\\r\\n\\r'\n",
      "CAUTION: startxref found while searching for %%EOF. The file might be truncated and some data might not be read.\n",
      "EOF marker not found\n",
      "Ignoring wrong pointing object 2 65536 (offset 0)\n",
      "Ignoring wrong pointing object 35 65536 (offset 0)\n",
      "Ignoring wrong pointing object 55 65536 (offset 0)\n",
      "Ignoring wrong pointing object 74 65536 (offset 0)\n",
      "Ignoring wrong pointing object 94 65536 (offset 0)\n",
      "Ignoring wrong pointing object 121 65536 (offset 0)\n",
      "Ignoring wrong pointing object 140 65536 (offset 0)\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(4)\n",
      "parsing for Object Streams\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(4)\n",
      "parsing for Object Streams\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      "parsing for Object Streams\n",
      "incorrect startxref pointer(3)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 2 65536 (offset 0)\n",
      "Ignoring wrong pointing object 39 65536 (offset 0)\n",
      "Ignoring wrong pointing object 77 65536 (offset 0)\n",
      "Ignoring wrong pointing object 116 65536 (offset 0)\n",
      "Ignoring wrong pointing object 147 65536 (offset 0)\n",
      "Ignoring wrong pointing object 178 65536 (offset 0)\n",
      "Ignoring wrong pointing object 204 65536 (offset 0)\n",
      "Ignoring wrong pointing object 229 65536 (offset 0)\n",
      "Ignoring wrong pointing object 266 65536 (offset 0)\n",
      "Ignoring wrong pointing object 305 65536 (offset 0)\n",
      "Ignoring wrong pointing object 308 65536 (offset 0)\n",
      "Ignoring wrong pointing object 342 65536 (offset 0)\n",
      "Ignoring wrong pointing object 379 65536 (offset 0)\n",
      "Ignoring wrong pointing object 400 65536 (offset 0)\n",
      "Ignoring wrong pointing object 403 65536 (offset 0)\n",
      "Ignoring wrong pointing object 406 65536 (offset 0)\n",
      "Ignoring wrong pointing object 409 65536 (offset 0)\n",
      "Ignoring wrong pointing object 412 65536 (offset 0)\n",
      "Ignoring wrong pointing object 415 65536 (offset 0)\n",
      "incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(4)\n",
      "parsing for Object Streams\n",
      "incorrect startxref pointer(3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CORRUPTED FILES LIST:\n",
      "  1. 3P5D3UKXU2R6I2TK4OJSLL6LGIQJ4NY5.pdf\n",
      "  2. 6HTC5FVAQW3DVHYRD7PVJGBBQS7GRZTL.pdf\n",
      "  3. DEAHZFTA4CQDFDYMRX2NPJCKEHYPIK2Z.pdf\n",
      "  4. MDQ4BAARW6OTVBNBQE7BACYBNCCTWQDO.pdf\n",
      "  5. SW62D5RJMAPDJWHDMA5DLJWWLMSYZE26.pdf\n",
      "\n",
      "SUMMARY:\n",
      "Total PDFs:         1076\n",
      "Valid PDFs:         1071\n",
      "Corrupted PDFs:        5\n",
      "Corruption rate:    0.5%\n",
      "\n",
      "Corrupted files saved to: corrupted_pdfs.txt\n",
      "\n",
      "Loading VALID PDFs only...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1076 [00:04<08:43,  2.03it/s]parsing for Object Streams\n",
      "  4%|▍         | 43/1076 [01:06<09:21,  1.84it/s]  incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n",
      "Object 47 0 found\n",
      "  5%|▌         | 54/1076 [01:09<05:53,  2.89it/s]parsing for Object Streams\n",
      "  6%|▌         | 61/1076 [01:14<13:45,  1.23it/s]Unexpected escaped string: C\n",
      "Unexpected escaped string: C\n",
      "  6%|▌         | 63/1076 [01:15<10:28,  1.61it/s]invalid pdf header: b'\\r\\n\\r\\n\\r'\n",
      "CAUTION: startxref found while searching for %%EOF. The file might be truncated and some data might not be read.\n",
      "EOF marker not found\n",
      "Error loading file ..\\data\\pdf\\3P5D3UKXU2R6I2TK4OJSLL6LGIQJ4NY5.pdf: Stream has ended unexpectedly\n",
      "  7%|▋         | 75/1076 [02:03<1:17:00,  4.62s/it]Ignoring wrong pointing object 1 65536 (offset 0)\n",
      "Ignoring wrong pointing object 15 65536 (offset 0)\n",
      "  8%|▊         | 87/1076 [02:07<16:38,  1.01s/it]  Error loading file ..\\data\\pdf\\4GJGAIUVBMLM3W7O5SV4EKDNKC4DVOCL.pdf: File has not been decrypted\n",
      "incorrect startxref pointer(3)\n",
      "  9%|▉         | 100/1076 [02:15<17:33,  1.08s/it]Unexpected escaped string: .\n",
      "Unexpected escaped string: R\n",
      " 11%|█         | 113/1076 [02:23<14:40,  1.09it/s]incorrect startxref pointer(3)\n",
      " 11%|█▏        | 123/1076 [02:25<07:54,  2.01it/s]parsing for Object Streams\n",
      " 12%|█▏        | 129/1076 [02:31<16:02,  1.02s/it]incorrect startxref pointer(3)\n",
      " 13%|█▎        | 140/1076 [02:39<11:23,  1.37it/s]incorrect startxref pointer(4)\n",
      "parsing for Object Streams\n",
      " 14%|█▎        | 146/1076 [02:42<07:00,  2.21it/s]invalid pdf header: b'\\n<!DO'\n",
      "EOF marker not found\n",
      "Error loading file ..\\data\\pdf\\6HTC5FVAQW3DVHYRD7PVJGBBQS7GRZTL.pdf: Stream has ended unexpectedly\n",
      " 17%|█▋        | 184/1076 [04:03<29:20,  1.97s/it]  Ignoring wrong pointing object 2 65536 (offset 0)\n",
      "Ignoring wrong pointing object 35 65536 (offset 0)\n",
      "Ignoring wrong pointing object 55 65536 (offset 0)\n",
      "Ignoring wrong pointing object 74 65536 (offset 0)\n",
      "Ignoring wrong pointing object 92 65536 (offset 0)\n",
      "Ignoring wrong pointing object 112 65536 (offset 0)\n",
      "Ignoring wrong pointing object 139 65536 (offset 0)\n",
      "Ignoring wrong pointing object 158 65536 (offset 0)\n",
      " 17%|█▋        | 185/1076 [04:05<28:08,  1.90s/it]incorrect startxref pointer(3)\n",
      " 25%|██▍       | 266/1076 [05:42<15:01,  1.11s/it]  incorrect startxref pointer(3)\n",
      " 26%|██▋       | 284/1076 [05:45<02:58,  4.43it/s]incorrect startxref pointer(3)\n",
      " 28%|██▊       | 298/1076 [05:54<10:11,  1.27it/s]parsing for Object Streams\n",
      " 28%|██▊       | 300/1076 [05:55<06:58,  1.85it/s]incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      " 31%|███       | 332/1076 [06:00<02:23,  5.18it/s]EOF marker not found\n",
      "Error loading file ..\\data\\pdf\\DEAHZFTA4CQDFDYMRX2NPJCKEHYPIK2Z.pdf: Stream has ended unexpectedly\n",
      " 33%|███▎      | 353/1076 [06:17<04:59,  2.41it/s]Ignoring wrong pointing object 2 65536 (offset 0)\n",
      "Ignoring wrong pointing object 44 65536 (offset 0)\n",
      "Ignoring wrong pointing object 72 65536 (offset 0)\n",
      "Ignoring wrong pointing object 99 65536 (offset 0)\n",
      "Ignoring wrong pointing object 125 65536 (offset 0)\n",
      "Ignoring wrong pointing object 153 65536 (offset 0)\n",
      "Ignoring wrong pointing object 190 65536 (offset 0)\n",
      "Ignoring wrong pointing object 218 65536 (offset 0)\n",
      " 35%|███▍      | 373/1076 [06:22<03:09,  3.71it/s]incorrect startxref pointer(3)\n",
      " 38%|███▊      | 407/1076 [06:33<02:51,  3.91it/s]incorrect startxref pointer(3)\n",
      "XRef object at 1266 can not be read, some object may be missing\n",
      "Ignoring wrong pointing object 38 0 (offset 0)\n",
      "Ignoring wrong pointing object 39 0 (offset 0)\n",
      "Ignoring wrong pointing object 40 0 (offset 0)\n",
      "Ignoring wrong pointing object 41 0 (offset 0)\n",
      "Ignoring wrong pointing object 42 0 (offset 0)\n",
      "Ignoring wrong pointing object 43 0 (offset 0)\n",
      "Ignoring wrong pointing object 44 0 (offset 0)\n",
      "Ignoring wrong pointing object 45 0 (offset 0)\n",
      "Ignoring wrong pointing object 46 0 (offset 0)\n",
      "Ignoring wrong pointing object 47 0 (offset 0)\n",
      "Ignoring wrong pointing object 48 0 (offset 0)\n",
      "Ignoring wrong pointing object 49 0 (offset 0)\n",
      "Ignoring wrong pointing object 50 0 (offset 0)\n",
      "Ignoring wrong pointing object 51 0 (offset 0)\n",
      "Ignoring wrong pointing object 52 0 (offset 0)\n",
      "Ignoring wrong pointing object 53 0 (offset 0)\n",
      "Ignoring wrong pointing object 54 0 (offset 0)\n",
      "Ignoring wrong pointing object 55 0 (offset 0)\n",
      "Ignoring wrong pointing object 56 0 (offset 0)\n",
      "Ignoring wrong pointing object 57 0 (offset 0)\n",
      "Ignoring wrong pointing object 58 0 (offset 0)\n",
      "Ignoring wrong pointing object 59 0 (offset 0)\n",
      "Ignoring wrong pointing object 60 0 (offset 0)\n",
      "Ignoring wrong pointing object 61 0 (offset 0)\n",
      "Ignoring wrong pointing object 62 0 (offset 0)\n",
      "Ignoring wrong pointing object 63 0 (offset 0)\n",
      "Ignoring wrong pointing object 64 0 (offset 0)\n",
      "Ignoring wrong pointing object 65 0 (offset 0)\n",
      "Ignoring wrong pointing object 66 0 (offset 0)\n",
      "Ignoring wrong pointing object 67 0 (offset 0)\n",
      "Ignoring wrong pointing object 68 0 (offset 0)\n",
      "Ignoring wrong pointing object 69 0 (offset 0)\n",
      "Ignoring wrong pointing object 70 0 (offset 0)\n",
      "Ignoring wrong pointing object 71 0 (offset 0)\n",
      "Ignoring wrong pointing object 72 0 (offset 0)\n",
      "Ignoring wrong pointing object 73 0 (offset 0)\n",
      "Ignoring wrong pointing object 74 0 (offset 0)\n",
      "Ignoring wrong pointing object 75 0 (offset 0)\n",
      "Ignoring wrong pointing object 76 0 (offset 0)\n",
      "Ignoring wrong pointing object 77 0 (offset 0)\n",
      "Ignoring wrong pointing object 78 0 (offset 0)\n",
      "Ignoring wrong pointing object 79 0 (offset 0)\n",
      "Ignoring wrong pointing object 80 0 (offset 0)\n",
      "Ignoring wrong pointing object 81 0 (offset 0)\n",
      "Ignoring wrong pointing object 82 0 (offset 0)\n",
      "Ignoring wrong pointing object 83 0 (offset 0)\n",
      "Ignoring wrong pointing object 84 0 (offset 0)\n",
      "Ignoring wrong pointing object 85 0 (offset 0)\n",
      "Ignoring wrong pointing object 86 0 (offset 0)\n",
      "Ignoring wrong pointing object 87 0 (offset 0)\n",
      "Ignoring wrong pointing object 88 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 90 0 (offset 0)\n",
      "Ignoring wrong pointing object 91 0 (offset 0)\n",
      "Ignoring wrong pointing object 92 0 (offset 0)\n",
      "Ignoring wrong pointing object 93 0 (offset 0)\n",
      "Ignoring wrong pointing object 94 0 (offset 0)\n",
      "Ignoring wrong pointing object 95 0 (offset 0)\n",
      "Ignoring wrong pointing object 96 0 (offset 0)\n",
      "Ignoring wrong pointing object 97 0 (offset 0)\n",
      "Ignoring wrong pointing object 98 0 (offset 0)\n",
      "Ignoring wrong pointing object 99 0 (offset 0)\n",
      "Ignoring wrong pointing object 100 0 (offset 0)\n",
      "Ignoring wrong pointing object 101 0 (offset 0)\n",
      "Ignoring wrong pointing object 102 0 (offset 0)\n",
      "Ignoring wrong pointing object 103 0 (offset 0)\n",
      "Ignoring wrong pointing object 104 0 (offset 0)\n",
      "Ignoring wrong pointing object 105 0 (offset 0)\n",
      "Ignoring wrong pointing object 106 0 (offset 0)\n",
      "Ignoring wrong pointing object 107 0 (offset 0)\n",
      "Ignoring wrong pointing object 108 0 (offset 0)\n",
      "Ignoring wrong pointing object 109 0 (offset 0)\n",
      "Ignoring wrong pointing object 110 0 (offset 0)\n",
      "Ignoring wrong pointing object 111 0 (offset 0)\n",
      "Ignoring wrong pointing object 112 0 (offset 0)\n",
      "Ignoring wrong pointing object 113 0 (offset 0)\n",
      "Ignoring wrong pointing object 114 0 (offset 0)\n",
      "Ignoring wrong pointing object 115 0 (offset 0)\n",
      "Ignoring wrong pointing object 116 0 (offset 0)\n",
      "Ignoring wrong pointing object 117 0 (offset 0)\n",
      "Ignoring wrong pointing object 118 0 (offset 0)\n",
      "Ignoring wrong pointing object 119 0 (offset 0)\n",
      "Ignoring wrong pointing object 120 0 (offset 0)\n",
      "Ignoring wrong pointing object 121 0 (offset 0)\n",
      "Ignoring wrong pointing object 122 0 (offset 0)\n",
      "Ignoring wrong pointing object 123 0 (offset 0)\n",
      "Ignoring wrong pointing object 124 0 (offset 0)\n",
      "Ignoring wrong pointing object 125 0 (offset 0)\n",
      "Ignoring wrong pointing object 126 0 (offset 0)\n",
      "Ignoring wrong pointing object 127 0 (offset 0)\n",
      "Ignoring wrong pointing object 128 0 (offset 0)\n",
      "Ignoring wrong pointing object 129 0 (offset 0)\n",
      "Ignoring wrong pointing object 130 0 (offset 0)\n",
      "Ignoring wrong pointing object 131 0 (offset 0)\n",
      "Ignoring wrong pointing object 132 0 (offset 0)\n",
      "Ignoring wrong pointing object 133 0 (offset 0)\n",
      "Ignoring wrong pointing object 134 0 (offset 0)\n",
      "Ignoring wrong pointing object 135 0 (offset 0)\n",
      "Ignoring wrong pointing object 136 0 (offset 0)\n",
      "Ignoring wrong pointing object 137 0 (offset 0)\n",
      "Ignoring wrong pointing object 138 0 (offset 0)\n",
      "Ignoring wrong pointing object 139 0 (offset 0)\n",
      "Ignoring wrong pointing object 140 0 (offset 0)\n",
      "Ignoring wrong pointing object 141 0 (offset 0)\n",
      "Ignoring wrong pointing object 142 0 (offset 0)\n",
      "Ignoring wrong pointing object 143 0 (offset 0)\n",
      "Ignoring wrong pointing object 144 0 (offset 0)\n",
      "Ignoring wrong pointing object 145 0 (offset 0)\n",
      "Ignoring wrong pointing object 146 0 (offset 0)\n",
      "Ignoring wrong pointing object 147 0 (offset 0)\n",
      "Ignoring wrong pointing object 148 0 (offset 0)\n",
      "Ignoring wrong pointing object 149 0 (offset 0)\n",
      "Ignoring wrong pointing object 150 0 (offset 0)\n",
      "Ignoring wrong pointing object 151 0 (offset 0)\n",
      "Ignoring wrong pointing object 152 0 (offset 0)\n",
      "Ignoring wrong pointing object 153 0 (offset 0)\n",
      "Ignoring wrong pointing object 154 0 (offset 0)\n",
      " 42%|████▏     | 457/1076 [07:08<06:24,  1.61it/s]incorrect startxref pointer(3)\n",
      " 43%|████▎     | 461/1076 [07:09<05:06,  2.01it/s]parsing for Object Streams\n",
      " 43%|████▎     | 466/1076 [07:10<03:10,  3.21it/s]incorrect startxref pointer(3)\n",
      " 44%|████▍     | 474/1076 [07:23<18:29,  1.84s/it]incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      " 45%|████▍     | 479/1076 [07:24<08:40,  1.15it/s]incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(3)\n",
      " 45%|████▍     | 483/1076 [07:25<04:13,  2.34it/s]incorrect startxref pointer(3)\n",
      " 45%|████▌     | 488/1076 [07:25<02:27,  3.98it/s]Ignoring wrong pointing object 15 0 (offset 0)\n",
      "Ignoring wrong pointing object 41 0 (offset 0)\n",
      "Ignoring wrong pointing object 43 0 (offset 0)\n",
      "Ignoring wrong pointing object 59 0 (offset 0)\n",
      "Ignoring wrong pointing object 170 0 (offset 0)\n",
      "Ignoring wrong pointing object 203 0 (offset 0)\n",
      "Ignoring wrong pointing object 519 0 (offset 0)\n",
      " 47%|████▋     | 504/1076 [07:41<03:17,  2.90it/s]incorrect startxref pointer(4)\n",
      "parsing for Object Streams\n",
      "Object 218 0 not defined.\n",
      "Object 216 0 not defined.\n",
      "Error loading file ..\\data\\pdf\\ILRVVACIV2JDSO4LHLATCOCKSEQYZCMZ.pdf: Invalid object in /Pages\n",
      " 49%|████▊     | 523/1076 [07:55<08:56,  1.03it/s]incorrect startxref pointer(3)\n",
      " 50%|█████     | 542/1076 [09:01<22:50,  2.57s/it]  incorrect startxref pointer(3)\n",
      " 56%|█████▌    | 605/1076 [09:57<10:02,  1.28s/it]incorrect startxref pointer(4)\n",
      "parsing for Object Streams\n",
      "Object 70 0 not defined.\n",
      "Object 66 0 not defined.\n",
      "Error loading file ..\\data\\pdf\\LPA7M5D76YBCPXXCRVU7ZYECI6ODH24E.pdf: 'NoneType' object is not subscriptable\n",
      " 58%|█████▊    | 624/1076 [10:48<06:45,  1.12it/s]  EOF marker not found\n",
      "Error loading file ..\\data\\pdf\\MDQ4BAARW6OTVBNBQE7BACYBNCCTWQDO.pdf: Stream has ended unexpectedly\n",
      " 59%|█████▊    | 631/1076 [10:57<10:01,  1.35s/it]incorrect startxref pointer(3)\n",
      " 59%|█████▉    | 633/1076 [10:59<08:15,  1.12s/it]incorrect startxref pointer(3)\n",
      " 61%|██████    | 653/1076 [11:21<05:20,  1.32it/s]incorrect startxref pointer(3)\n",
      " 61%|██████    | 657/1076 [11:22<03:01,  2.30it/s]Ignoring wrong pointing object 255 0 (offset 0)\n",
      "Ignoring wrong pointing object 257 0 (offset 0)\n",
      " 62%|██████▏   | 668/1076 [11:30<02:56,  2.31it/s]incorrect startxref pointer(3)\n",
      " 63%|██████▎   | 678/1076 [11:38<05:19,  1.25it/s]Ignoring wrong pointing object 2 65536 (offset 0)\n",
      "Ignoring wrong pointing object 44 65536 (offset 0)\n",
      "Ignoring wrong pointing object 72 65536 (offset 0)\n",
      "Ignoring wrong pointing object 99 65536 (offset 0)\n",
      "Ignoring wrong pointing object 125 65536 (offset 0)\n",
      "Ignoring wrong pointing object 153 65536 (offset 0)\n",
      "Ignoring wrong pointing object 190 65536 (offset 0)\n",
      "Ignoring wrong pointing object 218 65536 (offset 0)\n",
      " 63%|██████▎   | 681/1076 [11:40<03:59,  1.65it/s]Ignoring wrong pointing object 23 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      " 64%|██████▍   | 689/1076 [11:49<08:15,  1.28s/it]Multiple definitions in dictionary at byte 0x6e80 for key /im15\n",
      " 65%|██████▌   | 700/1076 [11:51<03:02,  2.06it/s]invalid pdf header: b'\\r\\n\\r\\n\\r'\n",
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n",
      " 67%|██████▋   | 717/1076 [11:56<01:58,  3.02it/s]incorrect startxref pointer(4)\n",
      "parsing for Object Streams\n",
      "Object 187 0 not defined.\n",
      "Object 179 0 not defined.\n",
      "Error loading file ..\\data\\pdf\\P7MWMCFFFSYYNCKYBTUACYK2SLL32AB5.pdf: 'NoneType' object is not subscriptable\n",
      " 69%|██████▉   | 746/1076 [12:08<01:49,  3.00it/s]incorrect startxref pointer(4)\n",
      "parsing for Object Streams\n",
      "Object 210 0 not defined.\n",
      "Object 209 0 not defined.\n",
      "Error loading file ..\\data\\pdf\\QBU5BZSBYX6YRLYVHQU4VCFMBYAHDHLU.pdf: Invalid object in /Pages\n",
      " 70%|██████▉   | 750/1076 [12:09<01:34,  3.46it/s]incorrect startxref pointer(3)\n",
      " 70%|██████▉   | 753/1076 [12:25<15:30,  2.88s/it]Multiple definitions in dictionary at byte 0x7382 for key /im15\n",
      " 71%|███████▏  | 768/1076 [12:33<04:46,  1.08it/s]parsing for Object Streams\n",
      " 72%|███████▏  | 772/1076 [12:39<05:40,  1.12s/it]invalid pdf header: b'LZ``@'\n",
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n",
      " 72%|███████▏  | 777/1076 [13:08<22:56,  4.60s/it]incorrect startxref pointer(3)\n",
      " 72%|███████▏  | 779/1076 [13:08<14:46,  2.98s/it]incorrect startxref pointer(4)\n",
      "parsing for Object Streams\n",
      "Object 745 0 not defined.\n",
      "Object 705 0 not defined.\n",
      "Error loading file ..\\data\\pdf\\R7YJNQZ3EFASORAHOJYEDNW3ZDWBNO4K.pdf: 'NoneType' object is not subscriptable\n",
      " 74%|███████▎  | 793/1076 [13:53<04:35,  1.03it/s]incorrect startxref pointer(3)\n",
      " 76%|███████▌  | 820/1076 [15:42<37:46,  8.85s/it]incorrect startxref pointer(3)\n",
      " 78%|███████▊  | 839/1076 [15:48<02:50,  1.39it/s]invalid pdf header: b'\\r\\n\\r\\n\\r'\n",
      "CAUTION: startxref found while searching for %%EOF. The file might be truncated and some data might not be read.\n",
      "EOF marker not found\n",
      "Error loading file ..\\data\\pdf\\SW62D5RJMAPDJWHDMA5DLJWWLMSYZE26.pdf: Stream has ended unexpectedly\n",
      " 79%|███████▉  | 853/1076 [16:30<07:20,  1.97s/it]Ignoring wrong pointing object 2 65536 (offset 0)\n",
      "Ignoring wrong pointing object 35 65536 (offset 0)\n",
      "Ignoring wrong pointing object 55 65536 (offset 0)\n",
      "Ignoring wrong pointing object 74 65536 (offset 0)\n",
      "Ignoring wrong pointing object 94 65536 (offset 0)\n",
      "Ignoring wrong pointing object 121 65536 (offset 0)\n",
      "Ignoring wrong pointing object 140 65536 (offset 0)\n",
      " 81%|████████▏ | 876/1076 [17:47<09:19,  2.80s/it]incorrect startxref pointer(3)\n",
      " 84%|████████▎ | 901/1076 [18:04<05:40,  1.94s/it]PdfReadError(\"Invalid Elementary Object starting with b')' @7652883: b' PM)\\\\r\\\\n/Title (pages))\\\\r\\\\n/Author (Unknown)\\\\r\\\\n/Producer (Acrobat PDFWriter 3.02 for '\")\n",
      " 87%|████████▋ | 937/1076 [19:08<10:12,  4.41s/it]incorrect startxref pointer(3)\n",
      " 87%|████████▋ | 940/1076 [19:08<05:43,  2.53s/it]incorrect startxref pointer(4)\n",
      "parsing for Object Streams\n",
      "Object 52 0 not defined.\n",
      "Object 54 0 not defined.\n",
      "Error loading file ..\\data\\pdf\\W432ODS2OFAWYUFA5RQ3B7OWKDQWFXCD.pdf: Invalid object in /Pages\n",
      " 88%|████████▊ | 943/1076 [19:11<04:17,  1.93s/it]incorrect startxref pointer(3)\n",
      " 88%|████████▊ | 948/1076 [19:16<03:42,  1.74s/it]incorrect startxref pointer(4)\n",
      "parsing for Object Streams\n",
      "Object 299 0 not defined.\n",
      "Object 298 0 not defined.\n",
      "Error loading file ..\\data\\pdf\\WCILDJ3BDTTDKHJ3HGRQD2SF45E55AXN.pdf: Invalid object in /Pages\n",
      " 89%|████████▉ | 958/1076 [19:27<01:46,  1.11it/s]incorrect startxref pointer(3)\n",
      " 90%|████████▉ | 968/1076 [19:42<02:52,  1.60s/it]incorrect startxref pointer(3)\n",
      " 91%|█████████▏| 984/1076 [19:48<00:32,  2.80it/s]incorrect startxref pointer(3)\n",
      "parsing for Object Streams\n",
      " 92%|█████████▏| 992/1076 [19:51<00:27,  3.01it/s]incorrect startxref pointer(3)\n",
      " 94%|█████████▍| 1009/1076 [20:18<04:07,  3.69s/it]Ignoring wrong pointing object 16 0 (offset 0)\n",
      " 95%|█████████▍| 1017/1076 [20:28<01:22,  1.40s/it]Ignoring wrong pointing object 2 65536 (offset 0)\n",
      "Ignoring wrong pointing object 39 65536 (offset 0)\n",
      "Ignoring wrong pointing object 77 65536 (offset 0)\n",
      "Ignoring wrong pointing object 116 65536 (offset 0)\n",
      "Ignoring wrong pointing object 147 65536 (offset 0)\n",
      "Ignoring wrong pointing object 178 65536 (offset 0)\n",
      "Ignoring wrong pointing object 204 65536 (offset 0)\n",
      "Ignoring wrong pointing object 229 65536 (offset 0)\n",
      "Ignoring wrong pointing object 266 65536 (offset 0)\n",
      "Ignoring wrong pointing object 305 65536 (offset 0)\n",
      "Ignoring wrong pointing object 308 65536 (offset 0)\n",
      "Ignoring wrong pointing object 342 65536 (offset 0)\n",
      "Ignoring wrong pointing object 379 65536 (offset 0)\n",
      "Ignoring wrong pointing object 400 65536 (offset 0)\n",
      "Ignoring wrong pointing object 403 65536 (offset 0)\n",
      "Ignoring wrong pointing object 406 65536 (offset 0)\n",
      "Ignoring wrong pointing object 409 65536 (offset 0)\n",
      "Ignoring wrong pointing object 412 65536 (offset 0)\n",
      "Ignoring wrong pointing object 415 65536 (offset 0)\n",
      " 95%|█████████▌| 1023/1076 [20:45<01:25,  1.62s/it]incorrect startxref pointer(3)\n",
      "incorrect startxref pointer(4)\n",
      "parsing for Object Streams\n",
      "Object 1586 0 not defined.\n",
      "Object 1580 0 not defined.\n",
      "Error loading file ..\\data\\pdf\\YFPURNDOL6TDJBBMD6FIMGPZ64OBYAQ6.pdf: Invalid object in /Pages\n",
      " 96%|█████████▋| 1037/1076 [21:47<00:58,  1.51s/it]incorrect startxref pointer(3)\n",
      "100%|██████████| 1076/1076 [22:09<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded: 13380 pages from valid PDFs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Identify ALL corrupted PDFs and calculate percentages\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pypdf import PdfReader\n",
    "import pandas as pd\n",
    "\n",
    "pdf_dir = Path(\"../data/pdf\")\n",
    "all_pdfs = list(pdf_dir.glob(\"*.pdf\"))\n",
    "print(f\"Total PDF files found: {len(all_pdfs)}\")\n",
    "\n",
    "corrupted_files = []\n",
    "valid_files = []\n",
    "\n",
    "for pdf_file in all_pdfs:\n",
    "    try:\n",
    "        with open(pdf_file, 'rb') as f:\n",
    "            pdf_reader = PdfReader(f)\n",
    "            # If we reach here, PDF is readable\n",
    "            valid_files.append(pdf_file.name)\n",
    "    except Exception:\n",
    "        corrupted_files.append(pdf_file.name)\n",
    "\n",
    "# Create results\n",
    "print(\"\\nCORRUPTED FILES LIST:\")\n",
    "for i, corrupt_file in enumerate(corrupted_files, 1):\n",
    "    print(f\"{i:3d}. {corrupt_file}\")\n",
    "\n",
    "print(f\"\\nSUMMARY:\")\n",
    "print(f\"Total PDFs:         {len(all_pdfs):4d}\")\n",
    "print(f\"Valid PDFs:         {len(valid_files):4d}\")\n",
    "print(f\"Corrupted PDFs:     {len(corrupted_files):4d}\")\n",
    "print(f\"Corruption rate:    {len(corrupted_files)/len(all_pdfs)*100:.1f}%\")\n",
    "\n",
    "# Save corrupted list to file\n",
    "with open(\"corrupted_pdfs.txt\", \"w\") as f:\n",
    "    f.write(\"CORRUPTED PDF FILES:\\n\")\n",
    "    for corrupt_file in corrupted_files:\n",
    "        f.write(f\"{corrupt_file}\\n\")\n",
    "    \n",
    "print(\"\\nCorrupted files saved to: corrupted_pdfs.txt\")\n",
    "\n",
    "# Load only VALID PDFs\n",
    "print(\"\\nLoading VALID PDFs only...\")\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    path=\"../data/pdf\",\n",
    "    glob=\"**/*.pdf\",\n",
    "    loader_cls=PyPDFLoader,\n",
    "    show_progress=True,\n",
    "    silent_errors=True  # Skip corrupted files automatically\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "print(f\"Successfully loaded: {len(documents)} pages from valid PDFs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c99bb65",
   "metadata": {},
   "source": [
    "* Total PDFs:     1076 files (100.0%)\n",
    "* Fully Valid:    1062 files (98.7%) \n",
    "* Problematic:     14 files ( 1.3%)\n",
    "* Successfully loaded pages: 13011 pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b061cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 13,011 pages into smart chunks...\n",
      "Total chunks created: 41781\n",
      "\n",
      "Metadata verification (sample chunks):\n",
      "Chunk 1:\n",
      "  Filename: 08036c5a50a93da84c5c45ba468c58159d75281e.pdf\n",
      "  Page: 0\n",
      "  Start position: 0\n",
      "  Preview: THE CENTRE FOR HUMANITARIAN DATA  \n",
      " 1\n",
      "DECEMBER 2020\n",
      "1     Because there are well-established and accepted standards and mechanisms for sharing financi...\n",
      "\n",
      "Chunk 2:\n",
      "  Filename: 08036c5a50a93da84c5c45ba468c58159d75281e.pdf\n",
      "  Page: 0\n",
      "  Start position: 775\n",
      "  Preview: risks for crisis-affected people, humanitarian organizations and donors.\n",
      "• Donors regularly request data from the organizations they fund in order to ...\n",
      "\n",
      "Chunk 3:\n",
      "  Filename: 08036c5a50a93da84c5c45ba468c58159d75281e.pdf\n",
      "  Page: 0\n",
      "  Start position: 1480\n",
      "  Preview: limitation.\n",
      "• Donors and humanitarian organizations can take the following steps to minimize risks while \n",
      "maximizing benefits when sharing sensitive d...\n",
      "\n",
      "Generating embeddings and indexing...\n",
      "Vector database complete:\n",
      "- 41,781 total chunks indexed\n",
      "- Average chunk size: 827 characters\n",
      "- Storage location: ./chroma_db/\n",
      "- Ready for RAG queries\n"
     ]
    }
   ],
   "source": [
    "# Split documents with complete metadata preservation\n",
    "\n",
    "print(\"Processing 13,011 pages into smart chunks...\")\n",
    "\n",
    "# Ensure all documents have proper metadata\n",
    "for doc in documents:\n",
    "    # PyPDFLoader usually adds these, but ensure they're present\n",
    "    if 'page' not in doc.metadata:\n",
    "        doc.metadata['page'] = 1\n",
    "    if 'source' not in doc.metadata:\n",
    "        doc.metadata['source'] = 'unknown.pdf'\n",
    "\n",
    "# Intelligent text splitter with document structure awareness\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,           # Optimal size for RAG\n",
    "    chunk_overlap=200,         # Context preservation\n",
    "    length_function=len,\n",
    "    add_start_index=True,      # Track exact position in original doc\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],  # Paragraphs > Sentences > Words\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Total chunks created: {len(chunks)}\")\n",
    "\n",
    "# Verify metadata preservation (first 3 chunks)\n",
    "print(\"\\nMetadata verification (sample chunks):\")\n",
    "for i in range(min(3, len(chunks))):\n",
    "    chunk = chunks[i]\n",
    "    print(f\"Chunk {i+1}:\")\n",
    "    print(f\"  Filename: {Path(chunk.metadata['source']).name}\")\n",
    "    print(f\"  Page: {chunk.metadata['page']}\")\n",
    "    print(f\"  Start position: {chunk.metadata.get('start_index', 'N/A')}\")\n",
    "    print(f\"  Preview: {chunk.page_content[:150]}...\")\n",
    "    print()\n",
    "\n",
    "# Create persistent Chroma vector database\n",
    "print(\"Generating embeddings and indexing...\")\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_name=\"pdf_documents\"\n",
    ")\n",
    "\n",
    "print(f\"Vector database complete:\")\n",
    "print(f\"- {len(chunks):,} total chunks indexed\")\n",
    "print(f\"- Average chunk size: {sum(len(c.page_content) for c in chunks)//len(chunks)} characters\")\n",
    "print(f\"- Storage location: ./chroma_db/\")\n",
    "print(f\"- Ready for RAG queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdd01003",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m vectorstore = \u001b[43mChroma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./chroma_db\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpdf_documents\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\The Leo Programmer\\Internships\\NRSC\\Assignments\\testing-models-huge-dataset\\.venv\\Lib\\site-packages\\langchain_chroma\\vectorstores.py:1431\u001b[39m, in \u001b[36mChroma.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, ids, collection_name, persist_directory, host, port, headers, chroma_cloud_api_key, tenant, database, client_settings, client, collection_metadata, collection_configuration, ssl, **kwargs)\u001b[39m\n\u001b[32m   1429\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1430\u001b[39m     ids = [doc.id \u001b[38;5;28;01mif\u001b[39;00m doc.id \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(uuid.uuid4()) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m-> \u001b[39m\u001b[32m1431\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1433\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1434\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1435\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1436\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1437\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1438\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1439\u001b[39m \u001b[43m    \u001b[49m\u001b[43mport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1440\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mssl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1441\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1442\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchroma_cloud_api_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchroma_cloud_api_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1444\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1445\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1446\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1447\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1448\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_configuration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1449\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1450\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\The Leo Programmer\\Internships\\NRSC\\Assignments\\testing-models-huge-dataset\\.venv\\Lib\\site-packages\\langchain_chroma\\vectorstores.py:1365\u001b[39m, in \u001b[36mChroma.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, host, port, headers, chroma_cloud_api_key, tenant, database, client_settings, client, collection_metadata, collection_configuration, ssl, **kwargs)\u001b[39m\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbatch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[32m   1359\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[32m   1360\u001b[39m         api=chroma_collection._client,\n\u001b[32m   1361\u001b[39m         ids=ids,\n\u001b[32m   1362\u001b[39m         metadatas=metadatas,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   1363\u001b[39m         documents=texts,\n\u001b[32m   1364\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m         chroma_collection.add_texts(\n\u001b[32m   1366\u001b[39m             texts=batch[\u001b[32m3\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m batch[\u001b[32m3\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m [],\n\u001b[32m   1367\u001b[39m             metadatas=batch[\u001b[32m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m batch[\u001b[32m2\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   1368\u001b[39m             ids=batch[\u001b[32m0\u001b[39m],\n\u001b[32m   1369\u001b[39m         )\n\u001b[32m   1370\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1371\u001b[39m     chroma_collection.add_texts(texts=texts, metadatas=metadatas, ids=ids)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_name=\"pdf_documents\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8f8e3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vector database for queries...\n",
      "Found 5 relevant chunks:\n",
      "\n",
      "Chunk 1:\n",
      "  Source: GGLQFBLQF5BLQKGOXFHVYVU6CRHUFVLU.pdf\n",
      "  Page: 0\n",
      "  Content: District enrollment (public and nonpublic school-age students ? with and without disabilities) on the first Wednesday \n",
      "in October 1,179\n",
      "Special education classification rate 11%\n",
      "Enrollment of preschoo...\n",
      "\n",
      "Chunk 2:\n",
      "  Source: GGLQFBLQF5BLQKGOXFHVYVU6CRHUFVLU.pdf\n",
      "  Page: 0\n",
      "  Content: District enrollment (public and nonpublic school-age students ? with and without disabilities) on the first Wednesday \n",
      "in October 1,179\n",
      "Special education classification rate 11%\n",
      "Enrollment of preschoo...\n",
      "\n",
      "Chunk 3:\n",
      "  Source: MNMNOYBE6LSE2QDETWHNV3TQWBUOYADX.pdf\n",
      "  Page: 20\n",
      "  Content: |                                                                                                                                                   |\n",
      "| With a disability:                              ...\n",
      "\n",
      "Chunk 4:\n",
      "  Source: MNMNOYBE6LSE2QDETWHNV3TQWBUOYADX.pdf\n",
      "  Page: 20\n",
      "  Content: |                                                                                                                                                   |\n",
      "| With a disability:                              ...\n",
      "\n",
      "Chunk 5:\n",
      "  Source: QMNB4F4EQHGQDRKO7QIJWTN6TUMGKQXB.pdf\n",
      "  Page: 0\n",
      "  Content: District enrollment (public and nonpublic school-age students ? with and without disabilities) on the first Wednesday \n",
      "in October 1,997\n",
      "Special education classification rate 15.7%\n",
      "Enrollment of presch...\n",
      "Ollama LLM and Embeddings setup complete.\n",
      "Initializing Ollama LLM and Embeddings...\n"
     ]
    }
   ],
   "source": [
    "# Load ChromaDB and test retrieval\n",
    "print(\"Loading vector database for queries...\")\n",
    "\n",
    "# Load your created database\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"pdf_documents\"\n",
    ")\n",
    "\n",
    "# Test retrieval \n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 5}\n",
    ")\n",
    "\n",
    "# Test query\n",
    "query = \"Graduation rates of Students with disabilities in higher education institutions\"\n",
    "relevant_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"Found {len(relevant_docs)} relevant chunks:\")\n",
    "for i, doc in enumerate(relevant_docs):\n",
    "    print(f\"\\nChunk {i+1}:\")\n",
    "    print(f\"  Source: {Path(doc.metadata['source']).name}\")\n",
    "    print(f\"  Page: {doc.metadata['page']}\")\n",
    "    print(f\"  Content: {doc.page_content[:200]}...\")\n",
    "\n",
    "print(\"Ollama LLM and Embeddings setup complete.\")\n",
    "print(\"Initializing Ollama LLM and Embeddings...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d36289a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RAG with specific document questions\n",
    "test_questions = [\n",
    "    \"What is the total Farm Bill investment amount mentioned for New Mexico projects?\",\n",
    "    \"What irrigation improvements does Mike Sporcic recommend in the Holistic Irrigation Technology program?\",\n",
    "    \"How many wild chinook salmon parr were PIT tagged in Idaho streams during July and August 2001?\",\n",
    "    \"What was the average parr-to-smolt survival rate to Lower Granite Dam for Idaho and Oregon streams in 2002?\",\n",
    "    \"What organization did Rep. John P. Murtha praise for economic development in Cambria and Somerset counties?\"\n",
    "    \"How many people attended the JARI annual report meeting on March 27, 2008?\",\n",
    "    \"How many organizations populate the HDX Data Grids with reference to 125 data sources?\",\n",
    "    \"What percentage of relevant, complete crisis data is available across 27 humanitarian operations locations?\",\n",
    "    \"What is the data completeness percentage for Afghanistan and Central African Republic (CAR)?\",\n",
    "    \"How many times more are Data Grids datasets downloaded compared to the average HDX dataset?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60daf2c1",
   "metadata": {},
   "source": [
    "**LLama Model Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b47a22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\The Leo Programmer\\Internships\\NRSC\\Assignments\\testing-models-huge-dataset\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_core.chains'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moutput_parsers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StrOutputParser\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLMChain\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Initialize LLM\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_core.chains'"
     ]
    }
   ],
   "source": [
    "# context_4k_limit_prompt - Perplexity-style for 4K Llama\n",
    "\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Your llama2 model for answering\n",
    "llm = OllamaLLM(model=\"llama2\")\n",
    "\n",
    "context_4k_limit_prompt = \"\"\"\n",
    "You are analyzing a dataset of multiple PDF documents.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Answer using ONLY the provided context - NO external knowledge  \n",
    "2. Cite sources inline with [1], [2], etc. after each sentence/paragraph\n",
    "3. List ONLY relevant source filenames at bottom\n",
    "\n",
    "CONTEXT (from PDF documents):\n",
    "{context}\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "RULES:\n",
    "- Use [1], [2] etc. immediately after sentences using that chunk\n",
    "- Extract exact numbers/dates/names from context only\n",
    "- If not in context: \"Not found in provided documents\"\n",
    "- Keep answer concise (under 200 words)\n",
    "\n",
    "FORMAT REQUIRED:\n",
    "Answer using ONLY the context above.\n",
    "\n",
    "Sources:\n",
    "[1] filename1.pdf\n",
    "[2] filename2.pdf\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "# Format function for citations\n",
    "def format_docs(docs):\n",
    "    formatted = []\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        source_name = Path(doc.metadata['source']).name\n",
    "        formatted.append(f\"[{i}] {doc.page_content}\\nSource: {source_name} (page {doc.metadata['page']})\")\n",
    "    return \"\\n\\n\".join(formatted)\n",
    "\n",
    "# RAG chain with your prompt\n",
    "rag_chain_4k = (\n",
    "    {\"context\": retriever | format_docs, \"question\": lambda x: x}\n",
    "    | ChatPromptTemplate.from_template(context_4k_limit_prompt)\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"Testing RAG with document-specific questions: Llama 4K context limit model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825de823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RAG performance (Llama 4K context limit)...\n",
      "\n",
      "Q1: What is the total Farm Bill investment amount mentioned for New Mexico projects?\n",
      "Time: 6.605s\n",
      "Answer: The total Farm Bill investment amount mentioned for New Mexico projects is not found in the provided documents.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Q2: What irrigation improvements does Mike Sporcic recommend in the Holistic Irrigation Technology program?\n",
      "Time: 13.868s\n",
      "Answer: Mike Sporcic recommends several irrigation improvements in the Holistic Irrigation Technology program, including:\n",
      "\n",
      "* Installing high flow structures to improve irrigation efficiency by uniformly applying water with less time and labor (page 3)\n",
      "* Laser leveling to increase irrigation application uniformity and overall efficiency (page 3)\n",
      "* Measuring soil moisture to identify appropriate times for irrigation, preventing plant stress conditions, and improving crop yields and profit margins (page 3)\n",
      "\n",
      "These improvements are expected to require a significant commitment to management but are deemed worth the effort.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Q3: How many wild chinook salmon parr were PIT tagged in Idaho streams during July and August 2001?\n",
      "Time: 9.927s\n",
      "Answer: Based on the provided context, we can determine that 10,242 wild chinook salmon parr were PIT tagged in Idaho streams during July and August 2001. This information is found on page 2 of the document.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Q4: What was the average parr-to-smolt survival rate to Lower Granite Dam for Idaho and Oregon streams in 2002?\n",
      "Time: 9.264s\n",
      "Answer: The average parr-to-smolt survival rate to Lower Granite Dam for Idaho and Oregon streams in 2002 was estimated to be 14.3% based on the data provided in the context.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Q5: What organization did Rep. John P. Murtha praise for economic development in Cambria and Somerset counties?How many people attended the JARI annual report meeting on March 27, 2008?\n",
      "Time: 10.292s\n",
      "Answer: The organization that Rep. John P. Murtha praised for economic development in Cambria and Somerset counties is the \"Johnstown Area Regional Industries\" (JARI). According to the context, more than 110 people attended the JARI annual report meeting on March 27, 2008.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Q6: How many organizations populate the HDX Data Grids with reference to 125 data sources?\n",
      "Time: 15.529s\n",
      "Answer: According to the provided documents, there are 20 organizations that contribute data to the HDX Data Grids with reference to 125 data sources. This information can be found in the following documents:\n",
      "\n",
      "* [1] page 14: \"The number of organizations starting with an initial 28 organizations has grown to over 300 organizations as of July 2020.\"\n",
      "* [2] page 12: \"The following 28 organizations share data that is included in the Data Grid.\"\n",
      "* [3] page 18: \"Out of the 293 organizations sharing data on HDX, 18 contribute data that is included in the Data Grids, with reference to 175 data sources.\"\n",
      "\n",
      "Therefore, the answer to the question is 20.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Q7: What percentage of relevant, complete crisis data is available across 27 humanitarian operations locations?\n",
      "Time: 22.995s\n",
      "Answer: According to the provided context, at the start of 2023, it is estimated that 73% of relevant, complete crisis data is available across 25 humanitarian operations locations. This percentage is based on the analysis of the HDX Data Grids, which divide the most important crisis data into six categories: affected people; coordination and context; food security and nutrition; geography and infrastructure; health and education; and population and socio-economy. The Data Grids include an average of 20-30 datasets per location, and the completeness of all Data Grids combined was 43% in mid-2020. If we add the data that is relevant but incomplete, the total is 72%.\n",
      "\n",
      "It is worth noting that HDX includes data about all countries in the world, but the analysis concentrates on 25 locations with Humanitarian Response Plans (HRPs). In 2022, 32% of all datasets downloaded from HDX were related to an HRP location.\n",
      "\n",
      "Overall, while there is some progress in increasing the availability and completeness of crisis data, there is still a significant gap in data availability across humanitarian operations locations.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Q8: What is the data completeness percentage for Afghanistan and Central African Republic (CAR)?\n",
      "Time: 11.557s\n",
      "Answer: The data completeness percentage for Afghanistan and Central African Republic (CAR) is not explicitly stated in the provided documents. However, according to the HDX Data Grid, Afghanistan has a data completeness percentage of 63%, while CAR has a percentage of 33%. These numbers can be found on page 4 of [1] and page 6 of [2], respectively.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Q9: How many times more are Data Grids datasets downloaded compared to the average HDX dataset?\n",
      "Time: 12.364s\n",
      "Answer: According to the provided context, Data Grids datasets are downloaded almost five times more than the average HDX dataset. Specifically, [2] states that in 2021, Data Grids datasets were downloaded over 1.8 million times, while [5] estimates that in 2022, 69% of relevant, complete crisis data is available across 27 humanitarian operations. These numbers suggest a significant disparity between the number of downloads for Data Grids and average HDX datasets.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "---> SUMMARY (Llama 4K):\n",
      "Average response time: 12.489 seconds\n",
      "Total time for 9 questions: 112.401 seconds\n",
      "Individual times: ['6.605s', '13.868s', '9.927s', '9.264s', '10.292s', '15.529s', '22.995s', '11.557s', '12.364s']\n",
      "\n",
      "Results saved to model_results dictionary\n",
      "Ready for 32K model comparison...\n"
     ]
    }
   ],
   "source": [
    "# Testing RAG with timing + results storage\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Dictionary to store results for model comparison\n",
    "model_results = {\n",
    "    \"model\": \"llama3.2_4k\",\n",
    "    \"test_questions\": test_questions.copy(),\n",
    "    \"times\": [],\n",
    "    \"answers\": [],\n",
    "    \"avg_time\": None\n",
    "}\n",
    "\n",
    "print(\"Testing RAG performance (Llama 4K context limit)...\")\n",
    "total_time = 0\n",
    "\n",
    "for i, q in enumerate(test_questions, 1):\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    answer = rag_chain_4k.invoke(q)\n",
    "    \n",
    "    end_time = time.perf_counter()\n",
    "    question_time = end_time - start_time\n",
    "    \n",
    "    total_time += question_time\n",
    "    \n",
    "    model_results[\"times\"].append(question_time)\n",
    "    model_results[\"answers\"].append(answer)\n",
    "    \n",
    "    print(f\"\\nQ{i}: {q}\")\n",
    "    print(f\"Time: {question_time:.3f}s\")\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "# Calculate average\n",
    "avg_time = total_time / len(test_questions)\n",
    "model_results[\"avg_time\"] = avg_time\n",
    "\n",
    "print(f\"\\n---> SUMMARY (Llama 4K):\")\n",
    "print(f\"Average response time: {avg_time:.3f} seconds\")\n",
    "print(f\"Total time for {len(test_questions)} questions: {total_time:.3f} seconds\")\n",
    "print(f\"Individual times: {[f'{t:.3f}s' for t in model_results['times']]}\")\n",
    "\n",
    "# Save for later model comparison\n",
    "print(f\"\\nResults saved to model_results dictionary\")\n",
    "print(f\"Ready for 32K model comparison...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa7bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your llama2 model for answering\n",
    "qwen_llm = OllamaLLM(model=\"qwen2.5:1.5b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3105d22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2_4k', 'test_questions': ['What is the total Farm Bill investment amount mentioned for New Mexico projects?', 'What irrigation improvements does Mike Sporcic recommend in the Holistic Irrigation Technology program?', 'How many wild chinook salmon parr were PIT tagged in Idaho streams during July and August 2001?', 'What was the average parr-to-smolt survival rate to Lower Granite Dam for Idaho and Oregon streams in 2002?', 'What organization did Rep. John P. Murtha praise for economic development in Cambria and Somerset counties?How many people attended the JARI annual report meeting on March 27, 2008?', 'How many organizations populate the HDX Data Grids with reference to 125 data sources?', 'What percentage of relevant, complete crisis data is available across 27 humanitarian operations locations?', 'What is the data completeness percentage for Afghanistan and Central African Republic (CAR)?', 'How many times more are Data Grids datasets downloaded compared to the average HDX dataset?'], 'times': [6.605375799990725, 13.867919700001949, 9.926693699992029, 9.263871700008167, 10.292349499999546, 15.528666700003669, 22.995374500009348, 11.557003499998245, 12.363973999992595], 'answers': ['The total Farm Bill investment amount mentioned for New Mexico projects is not found in the provided documents.', 'Mike Sporcic recommends several irrigation improvements in the Holistic Irrigation Technology program, including:\\n\\n* Installing high flow structures to improve irrigation efficiency by uniformly applying water with less time and labor (page 3)\\n* Laser leveling to increase irrigation application uniformity and overall efficiency (page 3)\\n* Measuring soil moisture to identify appropriate times for irrigation, preventing plant stress conditions, and improving crop yields and profit margins (page 3)\\n\\nThese improvements are expected to require a significant commitment to management but are deemed worth the effort.', 'Based on the provided context, we can determine that 10,242 wild chinook salmon parr were PIT tagged in Idaho streams during July and August 2001. This information is found on page 2 of the document.', 'The average parr-to-smolt survival rate to Lower Granite Dam for Idaho and Oregon streams in 2002 was estimated to be 14.3% based on the data provided in the context.', 'The organization that Rep. John P. Murtha praised for economic development in Cambria and Somerset counties is the \"Johnstown Area Regional Industries\" (JARI). According to the context, more than 110 people attended the JARI annual report meeting on March 27, 2008.', 'According to the provided documents, there are 20 organizations that contribute data to the HDX Data Grids with reference to 125 data sources. This information can be found in the following documents:\\n\\n* [1] page 14: \"The number of organizations starting with an initial 28 organizations has grown to over 300 organizations as of July 2020.\"\\n* [2] page 12: \"The following 28 organizations share data that is included in the Data Grid.\"\\n* [3] page 18: \"Out of the 293 organizations sharing data on HDX, 18 contribute data that is included in the Data Grids, with reference to 175 data sources.\"\\n\\nTherefore, the answer to the question is 20.', 'According to the provided context, at the start of 2023, it is estimated that 73% of relevant, complete crisis data is available across 25 humanitarian operations locations. This percentage is based on the analysis of the HDX Data Grids, which divide the most important crisis data into six categories: affected people; coordination and context; food security and nutrition; geography and infrastructure; health and education; and population and socio-economy. The Data Grids include an average of 20-30 datasets per location, and the completeness of all Data Grids combined was 43% in mid-2020. If we add the data that is relevant but incomplete, the total is 72%.\\n\\nIt is worth noting that HDX includes data about all countries in the world, but the analysis concentrates on 25 locations with Humanitarian Response Plans (HRPs). In 2022, 32% of all datasets downloaded from HDX were related to an HRP location.\\n\\nOverall, while there is some progress in increasing the availability and completeness of crisis data, there is still a significant gap in data availability across humanitarian operations locations.', 'The data completeness percentage for Afghanistan and Central African Republic (CAR) is not explicitly stated in the provided documents. However, according to the HDX Data Grid, Afghanistan has a data completeness percentage of 63%, while CAR has a percentage of 33%. These numbers can be found on page 4 of [1] and page 6 of [2], respectively.', 'According to the provided context, Data Grids datasets are downloaded almost five times more than the average HDX dataset. Specifically, [2] states that in 2021, Data Grids datasets were downloaded over 1.8 million times, while [5] estimates that in 2022, 69% of relevant, complete crisis data is available across 27 humanitarian operations. These numbers suggest a significant disparity between the number of downloads for Data Grids and average HDX datasets.'], 'avg_time': 12.489025455555142}\n"
     ]
    }
   ],
   "source": [
    "print(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4beda1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RAG with document-specific questions: Qwen 32K context limit model\n"
     ]
    }
   ],
   "source": [
    "# context_32k_limit_prompt - Enhanced for 32K context window\n",
    "\n",
    "# Qwen model for answering\n",
    "qwen_llm = OllamaLLM(model=\"qwen2.5:1.5b\")\n",
    "\n",
    "context_32k_limit_prompt = \"\"\"\n",
    "You are an expert research assistant analyzing a comprehensive dataset of multiple PDF documents.\n",
    "\n",
    "IMPORTANT INSTRUCTIONS:\n",
    "1. Answer using ONLY the provided context below - NO external knowledge or training data\n",
    "2. This dataset contains diverse technical, scientific, and professional PDF documents\n",
    "3. Cite sources inline with [1], [2], etc. after each relevant sentence/paragraph\n",
    "4. At the end, list ONLY the source filenames used (no full paths)\n",
    "\n",
    "EXTENDED CONTEXT (from multiple PDF documents):\n",
    "{context}\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "ANSWERING RULES:\n",
    "- Use [1], [2], etc. immediately after sentences referencing specific chunks\n",
    "- Extract precise numbers, dates, names, percentages from context only\n",
    "- Provide comprehensive answers using all relevant context available\n",
    "- If information not found: \"Not found in provided documents\"\n",
    "- Maintain factual accuracy - quote directly when possible\n",
    "\n",
    "REQUIRED OUTPUT FORMAT:\n",
    "\n",
    "Answer your question using ONLY the context above. Be thorough but concise.\n",
    "\n",
    "Sources used:\n",
    "[1] filename1.pdf\n",
    "[2] filename2.pdf\n",
    "[3] filename3.pdf\n",
    "etc.\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "# RAG chain for 32K model\n",
    "rag_chain_32k = (\n",
    "    {\"context\": retriever | format_docs, \"question\": lambda x: x}\n",
    "    | ChatPromptTemplate.from_template(context_32k_limit_prompt)\n",
    "    | qwen_llm  # Your 32K model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(\"Testing RAG with document-specific questions: Qwen 32K context limit model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695599be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RAG performance (qwen2.5:1.5b 32K context limit)...\n",
      "\n",
      "Q1: What is the total Farm Bill investment amount mentioned for New Mexico projects?\n",
      "Time: 4.333s\n",
      "Answer: Not found in provided documents.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Q2: What irrigation improvements does Mike Sporcic recommend in the Holistic Irrigation Technology program?\n",
      "Time: 1.669s\n",
      "Answer: Mike Sporcic, a conservation advocate with ideas, recommends several irrigation improvements in the Holistic Irrigation Technology (HIT) program. The recommended solutions include high flow turnouts, laser leveling, and measuring soil moisture to identify appropriate times for irrigating crops to prevent plant stress conditions and improve crop yields. These practices reduce evaporation of water, thereby conserving resources.\n",
      "\n",
      "Sources used:\n",
      "[1] 2WE4HZPD57KVPL4RQKCB4PUG42SQ2RMJ.pdf\n",
      "[2] 2WE4HZPD57KVPL4RQKCB4PUG42SQ2RMJ.pdf\n",
      "[3] 2WE4HZPD57KVPL4RQKCB4PUG42SQ2RMJ.pdf\n",
      "\n",
      "NOT FOUND IN PROVIDED DOCUMENTS\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Q3: How many wild chinook salmon parr were PIT tagged in Idaho streams during July and August 2001?\n",
      "Time: 0.747s\n",
      "Answer: The total number of wild chinook salmon parr PIT tagged in Idaho streams during July and August 2001 was 10,242.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Q4: What was the average parr-to-smolt survival rate to Lower Granite Dam for Idaho and Oregon streams in 2002?\n",
      "Time: 3.574s\n",
      "Answer: The average parr-to-smolt survival rate to Lower Granite Dam for Idaho and Oregon streams in 2002 was 14.3%.\n",
      "\n",
      "Sources used:\n",
      "[1] Detections at Dams\n",
      "[2] iv\n",
      "5) Larger fish at release were detected at a significantly higher rate the following spring and summer than their smaller cohorts (P <0.001).\n",
      "6) Fish that migrated through Lower Granite Dam in April and May were significantly larger at release than fish that migrated after May (P = 0.0007).  \n",
      "7) In 2002, the peak detections at Lower Granite Dam of parr tagged during the late summer in 2001 (from the 11 streams in Idaho and 4 streams in Oregon) occurred during moderate flows of 86.7 kcfs on 4 May.  The 50th and 90th percentile passage occurred on 3 and 29 May, respectively.\n",
      "Source: 3RCHLDD2YCPDNLHEV4AVKEPBYJP5UBZB.pdf (page 17)\n",
      "\n",
      "The average parr-to-smolt survival estimates for the wild stocks from Idaho and Oregon streams to Lower Granite Dam were as follows:\n",
      "Migration year\n",
      "1993 15.3\n",
      "1994 18.8\n",
      "1995 13.5\n",
      "1996 20.6\n",
      "1997 20.8\n",
      "1998 24.4\n",
      "1999 19.9\n",
      "2000 17.7\n",
      "2001 19.5\n",
      "2002 14.3\n",
      "\n",
      "These estimates were revised and show an overall decrease in parr-to-smolt survival rates over time, with lower rates observed after the year 2002 due to higher parr densities in natal rearing areas and possibly cooler spring conditions contributing to reduced growth rates in fish released during those years compared to earlier periods.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Q5: What organization did Rep. John P. Murtha praise for economic development in Cambria and Somerset counties?How many people attended the JARI annual report meeting on March 27, 2008?\n",
      "Time: 1.014s\n",
      "Answer: Rep. John P. Murtha praised Cambria and Somerset counties for economic development in a speech at the JARI annual report meeting on March 27, 2008. More than 110 people attended the event. \n",
      "\n",
      "Sources used:\n",
      "[1] filename1.pdf\n",
      "[2] filename2.pdf\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Q6: How many organizations populate the HDX Data Grids with reference to 125 data sources?\n",
      "Time: 1.096s\n",
      "Answer: Answering your question using ONLY the provided documents, we do not find precise information on how many organizations populate the HDX Data Grids with reference to 125 data sources. The relevant information is mixed and does not provide a clear answer to this specific query. Therefore:\n",
      "\n",
      "Answer: Not found in provided documents\n",
      "\n",
      "Sources used:\n",
      "[1] filename1.pdf\n",
      "[2] filename2.pdf\n",
      "[3] filename3.pdf\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Q7: What percentage of relevant, complete crisis data is available across 27 humanitarian operations locations?\n",
      "Time: 0.751s\n",
      "Answer: The percentage of relevant, complete crisis data available across 27 humanitarian operations locations is 89%. This is derived from the analysis of the Data Grids in [1].\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Q8: What is the data completeness percentage for Afghanistan and Central African Republic (CAR)?\n",
      "Time: 0.774s\n",
      "Answer: The data completeness percentage for Afghanistan and Central African Republic (CAR) is 63 percent, which represents their most relevant and comprehensive data. This reflects the high level of data availability across these two locations compared to other operations such as Venezuela.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Q9: How many times more are Data Grids datasets downloaded compared to the average HDX dataset?\n",
      "Time: 1.655s\n",
      "Answer: Data Grids datasets are downloaded approximately four times more than the average HDX dataset. Specifically, they account for about 40% of total downloads (Source: [2], page 5). This is evidenced by their high frequency in download statistics and their content that addresses specific needs related to humanitarian crises and data completeness improvements.\n",
      "\n",
      "Sources used:\n",
      "[1] d5b25fe1a9b3ab5d54dfc8855984d7a7bb669878.pdf (page 15)\n",
      "[2] 5f1daaa6087c0d2d803b23997270dc8d79a1eb40.pdf (page 4)\n",
      "\n",
      "Not found in provided documents\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "---> SUMMARY (qwen2.5:1.5b 3K):\n",
      "Average response time: 1.735 seconds\n",
      "Total time for 9 questions: 15.612 seconds\n",
      "Individual times: ['4.333s', '1.669s', '0.747s', '3.574s', '1.014s', '1.096s', '0.751s', '0.774s', '1.655s']\n",
      "\n",
      "Results saved to model_results dictionary\n",
      "Ready for 32K model comparison...\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store results for model comparison\n",
    "model_results = {\n",
    "    \"model\": \"qwen2.5:1.5b\",\n",
    "    \"test_questions\": test_questions.copy(),\n",
    "    \"times\": [],\n",
    "    \"answers\": [],\n",
    "    \"avg_time\": None\n",
    "}\n",
    "\n",
    "print(\"Testing RAG performance (qwen2.5:1.5b 32K context limit)...\")\n",
    "total_time = 0\n",
    "\n",
    "for i, q in enumerate(test_questions, 1):\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    answer = rag_chain_32k.invoke(q)\n",
    "    \n",
    "    end_time = time.perf_counter()\n",
    "    question_time = end_time - start_time\n",
    "    \n",
    "    total_time += question_time\n",
    "    \n",
    "    model_results[\"times\"].append(question_time)\n",
    "    model_results[\"answers\"].append(answer)\n",
    "    \n",
    "    print(f\"\\nQ{i}: {q}\")\n",
    "    print(f\"Time: {question_time:.3f}s\")\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "# Calculate average\n",
    "avg_time = total_time / len(test_questions)\n",
    "model_results[\"avg_time\"] = avg_time\n",
    "\n",
    "print(f\"\\n---> SUMMARY (qwen2.5:1.5b 3K):\")\n",
    "print(f\"Average response time: {avg_time:.3f} seconds\")\n",
    "print(f\"Total time for {len(test_questions)} questions: {total_time:.3f} seconds\")\n",
    "print(f\"Individual times: {[f'{t:.3f}s' for t in model_results['times']]}\")\n",
    "\n",
    "# Save for later model comparison\n",
    "print(f\"\\nResults saved to model_results dictionary\")\n",
    "print(f\"Ready for 32K model comparison...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95d45f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RAG with document-specific questions: Gemma 32K context limit model\n"
     ]
    }
   ],
   "source": [
    "# Testing RAG with Gemma 32K model\n",
    "\n",
    "gemma_llm = OllamaLLM(model=\"gemma3:1b\")\n",
    "\n",
    "# RAG chain for 32K gemma model\n",
    "rag_chain_gemma_32k = (\n",
    "    {\"context\": retriever | format_docs, \"question\": lambda x: x}\n",
    "    | ChatPromptTemplate.from_template(context_32k_limit_prompt)\n",
    "    | gemma_llm  # Your 32K model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(\"Testing RAG with document-specific questions: Gemma 32K context limit model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0cd64b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Testing: gemma3:1b\n",
      "================================================================================\n",
      "\n",
      "Q1: What is the total Farm Bill investment amount mentioned for New Mexico projects?\n",
      "\n",
      "RETRIEVED DOCUMENTS (5):\n",
      "  [1] KV25SHM4P3UZHVNNEAE3OZSJ23D3BXZH.pdf\n",
      "     Page: 0\n",
      "     Preview: in the Enterprise Roadmap. Include a description of how the investment includes or\n",
      "will achieve programmatic or technical innovation. \n",
      " MIDAS is align...\n",
      "\n",
      "  [2] V7S4LR4S6BF5I3AFUOXHPTZC4RMCD6ZE.pdf\n",
      "     Page: 9\n",
      "     Preview: Exhibit 300: FBI Data Integration and Visualization System (DIVS) (Revision 2) \n",
      "Page 10 of 13 \n",
      "5. Technical Reference Model (TRM) Table: \n",
      "To demonstra...\n",
      "\n",
      "  [3] V7S4LR4S6BF5I3AFUOXHPTZC4RMCD6ZE.pdf\n",
      "     Page: 8\n",
      "     Preview: percentages in the column can, but are not required to, add up to 100%. \n",
      " \n",
      "5. Technical Reference Model (TRM) Table: \n",
      "To demonstrate how this major IT...\n",
      "\n",
      "Retrieve: 0.976s | Answer: 3.709s | Total: 4.685s\n",
      "Answer: Not found in provided documents\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Q2: What irrigation improvements does Mike Sporcic recommend in the Holistic Irrigation Technology program?\n",
      "\n",
      "RETRIEVED DOCUMENTS (5):\n",
      "  [1] 2WE4HZPD57KVPL4RQKCB4PUG42SQ2RMJ.pdf\n",
      "     Page: 3\n",
      "     Preview: Fischer, all of the New Mexico\n",
      "Natural Resources Conservation\n",
      "Service.\n",
      "     The Holistic Irrigation Technology\n",
      "has some 22 points that can guide\n",
      "irrig...\n",
      "\n",
      "  [2] 2WE4HZPD57KVPL4RQKCB4PUG42SQ2RMJ.pdf\n",
      "     Page: 3\n",
      "     Preview: that are learning and working on this.”\n",
      "     “There is still tons of work out\n",
      "there to do.  I just can’t emphasize\n",
      "that enough.”\n",
      "     In addition to h...\n",
      "\n",
      "  [3] 2WE4HZPD57KVPL4RQKCB4PUG42SQ2RMJ.pdf\n",
      "     Page: 3\n",
      "     Preview: Natural Resources Reporter\n",
      "( 4 )\n",
      "Natural Resources Reporter\n",
      "( 3 )\n",
      "Holistic Irrigation Technology Provides Answers\n",
      "Drought Response Heralded As Hard Wo...\n",
      "\n",
      "Retrieve: 0.112s | Answer: 1.425s | Total: 1.537s\n",
      "Answer: Mike Sporcic recommends the Holistic Irrigation Technology program, which includes points regarding high flow turnouts, laser leveling, and metering to help identify appropriate times to irrigate, thereby preventing plant stress conditions, and improving crop yields and quality.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Q3: How many wild chinook salmon parr were PIT tagged in Idaho streams during July and August 2001?\n",
      "\n",
      "RETRIEVED DOCUMENTS (5):\n",
      "  [1] 3RCHLDD2YCPDNLHEV4AVKEPBYJP5UBZB.pdf\n",
      "     Page: 10\n",
      "     Preview: 5\n",
      "Figure 1.  Wild spring/summer chinook salmon parr were PIT tagged during 2001 in the\n",
      "following streams:  1−Bear Valley Creek, 2−Elk Creek, 3−Marsh C...\n",
      "\n",
      "  [2] 3RCHLDD2YCPDNLHEV4AVKEPBYJP5UBZB.pdf\n",
      "     Page: 2\n",
      "     Preview: Army Corps of Engineers.  \n",
      "In 1991, the Bonneville Power Administration began a cooperative effort with\n",
      "NMFS to expand tagging and interrogation of wi...\n",
      "\n",
      "  [3] 3RCHLDD2YCPDNLHEV4AVKEPBYJP5UBZB.pdf\n",
      "     Page: 2\n",
      "     Preview: Dam.\n",
      "We continued to tag fish from Idaho after 1992.  Principal results from our\n",
      "tagging and interrogation during 2001-2002 are listed below:\n",
      "1) In Ju...\n",
      "\n",
      "Retrieve: 0.086s | Answer: 0.953s | Total: 1.039s\n",
      "Answer: 10,242\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Q4: What was the average parr-to-smolt survival rate to Lower Granite Dam for Idaho and Oregon streams in 2002?\n",
      "\n",
      "RETRIEVED DOCUMENTS (5):\n",
      "  [1] 3RCHLDD2YCPDNLHEV4AVKEPBYJP5UBZB.pdf\n",
      "     Page: 17\n",
      "     Preview: Detections at Dams\n",
      "Based on expanded detections (1,382 fish) at Lower Granite Dam from 11 April\n",
      "to 5 July 2002, estimated survival from parr to smolt ...\n",
      "\n",
      "  [2] 3RCHLDD2YCPDNLHEV4AVKEPBYJP5UBZB.pdf\n",
      "     Page: 3\n",
      "     Preview: iv\n",
      "5) Larger fish at release were detected at a significantly higher rate the following\n",
      "spring and sum\n",
      "mer than their smaller cohorts (P <0.001).\n",
      "6) F...\n",
      "\n",
      "  [3] 3RCHLDD2YCPDNLHEV4AVKEPBYJP5UBZB.pdf\n",
      "     Page: 39\n",
      "     Preview: 34\n",
      "Parr-to-sm\n",
      "olt survival estimates for the individual populations have been quite\n",
      "variable over these years ranging from 6.0% for South Fork of the ...\n",
      "\n",
      "Retrieve: 0.125s | Answer: 1.734s | Total: 1.859s\n",
      "Answer: The estimated parr-to-smolt survival estimates for individual populations have been quite variable over these years ranging from 6.0% for South Fork of the Salmon River fish in 1996 to 47.6% for Elk Creek fish in 1998. The higher parr densities observed in natal rearing areas in summer 2001 may have contributed to the lower parr-to-smolt survival estimates to Lower Granite Dam in 2002 than in the last several years.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Q5: What organization did Rep. John P. Murtha praise for economic development in Cambria and Somerset counties?How many people attended the JARI annual report meeting on March 27, 2008?\n",
      "\n",
      "RETRIEVED DOCUMENTS (5):\n",
      "  [1] 4GJOQXDXU2XKJOU5NUAAVWW7LS4LSYA7.pdf\n",
      "     Page: 0\n",
      "     Preview: March 27, 2008 - Murtha Addresses JARI Meeting\n",
      "\n",
      "Daily American\n",
      "\n",
      "http://www.dailyamerican.com/\n",
      "\n",
      "\n",
      "Murtha addresses JARI meeting \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "By SANDY WO...\n",
      "\n",
      "  [2] RLKGPI2MJLO7AEAI772IBBKWBRRWISBF.pdf\n",
      "     Page: 3\n",
      "     Preview: in Kansas and this user fee proposal would have harmed the local and state economy, as well as individual pilots across\n",
      "the state. \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Attend...\n",
      "\n",
      "  [3] WJFP7CI5XSOBSZZUQGR3FKMENNTPAKKC.pdf\n",
      "     Page: 3\n",
      "     Preview: I appreciated the opportunity to meet many officers and members. Special thanks to Wabaunsee County Farm Bureau\n",
      "President Ken Flagler and Osage County...\n",
      "\n",
      "Retrieve: 0.071s | Answer: 2.674s | Total: 2.745s\n",
      "Answer: Murtha addressed business leaders, entrepreneurs, economic development officers, and elected officials from across Cambria and Somerset counties Monday at the Johnstown Area Regional Industries (JARI) annual report meeting. The meeting was held at the Holiday Inn in Johnstown and more than 110 attended. Murtha said in an interview, before serving as the keynote speaker, that he was excited about what was taking place in Cambria and Somerset counties.\n",
      "\n",
      "The meeting was held at the Holiday Inn in Johnstown and more than 110 attended. Murtha said in an interview, before serving as the keynote speaker, that he was excited about what was taking place in Cambria and Somerset counties.\n",
      "\n",
      "&ldquo;Thirty years ago we saw all kinds of problems in employment &mdash; the steel mills which were such a bonus for us, but on the other hand they were closing down and we knew we had to diversify to attract not only the older people but the younger people,&rdquo; he said.\n",
      "\n",
      "Not found in provided documents.\n",
      "\n",
      "Source: [1] filename1.pdf\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Q6: How many organizations populate the HDX Data Grids with reference to 125 data sources?\n",
      "\n",
      "RETRIEVED DOCUMENTS (5):\n",
      "  [1] d5b25fe1a9b3ab5d54dfc8855984d7a7bb669878.pdf\n",
      "     Page: 14\n",
      "     Preview: number of organizations on HDX, the number of datasets, and the number of unique \n",
      "users. The charts below provide an overview of our progress for the ...\n",
      "\n",
      "  [2] b4eb68dd1d92f8c56b25e6d52948ba6c8ca8ec83.pdf\n",
      "     Page: 12\n",
      "     Preview: 8. CONTRIBUTING ORGANIZATIONS\n",
      "The following 28 organizations share data that is included in the Data Grid. An organization on HDX can be a legal \n",
      "enti...\n",
      "\n",
      "  [3] 879ec9e7fed8f827f29acd1f83f3bb75e002360f.pdf\n",
      "     Page: 18\n",
      "     Preview: 21\n",
      "9. CONTRIBUTING ORGANIZATIONS\n",
      "The Centre for Humanitarian Data   centre.humdata.org    |    Join our mailing list   bit.ly/humdatamailing    |    T...\n",
      "\n",
      "Retrieve: 0.063s | Answer: 1.124s | Total: 1.187s\n",
      "Answer: 20 organizations populate the HDX Data Grids with reference to 125 data sources.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Q7: What percentage of relevant, complete crisis data is available across 27 humanitarian operations locations?\n",
      "\n",
      "RETRIEVED DOCUMENTS (5):\n",
      "  [1] 879ec9e7fed8f827f29acd1f83f3bb75e002360f.pdf\n",
      "     Page: 3\n",
      "     Preview: related to an HRP location./three.sups \n",
      "At the start of 2023, we estimate that 73 percent of relevant, complete crisis data is available across 25 \n",
      "hu...\n",
      "\n",
      "  [2] 5f1daaa6087c0d2d803b23997270dc8d79a1eb40.pdf\n",
      "     Page: 3\n",
      "     Preview: were downloaded over 1.8 million times. Although HDX includes data about all countries in the world, we \n",
      "concentrate here on 27 locations with Humanit...\n",
      "\n",
      "  [3] d5b25fe1a9b3ab5d54dfc8855984d7a7bb669878.pdf\n",
      "     Page: 19\n",
      "     Preview: operations. \n",
      "We have created the HDX Data Grid as a way to measure data completeness across the \n",
      "humanitarian operations that we cover. The Data Grid ...\n",
      "\n",
      "Retrieve: 0.095s | Answer: 0.921s | Total: 1.016s\n",
      "Answer: Not found in provided documents.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Q8: What is the data completeness percentage for Afghanistan and Central African Republic (CAR)?\n",
      "\n",
      "RETRIEVED DOCUMENTS (5):\n",
      "  [1] 5f1daaa6087c0d2d803b23997270dc8d79a1eb40.pdf\n",
      "     Page: 23\n",
      "     Preview: completeness for a location refers to the proportion of sub-categories that are complete in the location.\n",
      "Sub-categories are considered empty if no da...\n",
      "\n",
      "  [2] d5b25fe1a9b3ab5d54dfc8855984d7a7bb669878.pdf\n",
      "     Page: 19\n",
      "     Preview: operations. \n",
      "We have created the HDX Data Grid as a way to measure data completeness across the \n",
      "humanitarian operations that we cover. The Data Grid ...\n",
      "\n",
      "  [3] 5f1daaa6087c0d2d803b23997270dc8d79a1eb40.pdf\n",
      "     Page: 4\n",
      "     Preview: complete. If the sub-category contains only incomplete datasets, then that sub-category is considered  incomplete. A \n",
      "sub-category is empty if no data...\n",
      "\n",
      "Retrieve: 0.059s | Answer: 0.975s | Total: 1.034s\n",
      "Answer: Not found in provided documents\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Q9: How many times more are Data Grids datasets downloaded compared to the average HDX dataset?\n",
      "\n",
      "RETRIEVED DOCUMENTS (5):\n",
      "  [1] d5b25fe1a9b3ab5d54dfc8855984d7a7bb669878.pdf\n",
      "     Page: 15\n",
      "     Preview: 16 OCHA CENTRE FOR HUMANITARIAN DATA | SEPTEMBER 2020\n",
      "The number of datasets \n",
      "The number of datasets available on HDX has steadily grown to over 17,00...\n",
      "\n",
      "  [2] 5f1daaa6087c0d2d803b23997270dc8d79a1eb40.pdf\n",
      "     Page: 4\n",
      "     Preview: in the Data Grids are downloaded almost four times more than the average dataset on HDX. Trusted partnerships \n",
      "and focused advocacy eﬀorts have led to...\n",
      "\n",
      "  [3] 879ec9e7fed8f827f29acd1f83f3bb75e002360f.pdf\n",
      "     Page: 5\n",
      "     Preview: in the Data Grids are downloaded almost five times more than the average dataset on HDX.\n",
      "   • South Sudan, Afghanistan and Somalia have the most compl...\n",
      "\n",
      "Retrieve: 0.067s | Answer: 2.998s | Total: 3.064s\n",
      "Answer: Data Grids are downloaded almost five times more than the average dataset on HDX. [2]\n",
      "\n",
      "20 The number of unique visitors\n",
      "Source: d5b25fe1a9b3ab5d54dfc8855984d7a7bb669878.pdf (page 15)\n",
      "\n",
      "23 There is an open question about how much metadata must be available on HDX datasets for the “compare” feature to be useful. [4]\n",
      "\n",
      "4 Quality Measures for Humanitarian Data on HDX. Multiple conversations with the Centre and its users highlighted the critical importance of data selection. [3]\n",
      "\n",
      "5 Data Grids are downloaded over 1.8 million times. [5]\n",
      "\n",
      "69 percent of relevant, complete crisis data is available across 27 humanitarian operations, based on the analysis of the Data Grids. [6]\n",
      "\n",
      "7 Data Grids include 482 unique datasets, with a range of 12-22 datasets per location. [7]\n",
      "\n",
      "879ec9e7fed8f827f29acd1f83f3bb75e002360f.pdf (page 5)\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "SUMMARY gemma3:1b:\n",
      "Avg total time: 2.019s | Retrieve+Answer breakdown\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store results for model comparison\n",
    "model_results = {\n",
    "    \"model\": \"gemma3:1b\",\n",
    "    \"test_questions\": test_questions.copy(),\n",
    "    \"times\": [],\n",
    "    \"answers\": [],\n",
    "    \"avg_time\": None\n",
    "}\n",
    "\n",
    "# Cell: RAG with Retrieved Documents Display (Production Version)\n",
    "def test_rag_with_sources(model_name, llm_model, rag_chain):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Testing: {model_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    model_results = {\n",
    "        \"model\": model_name,\n",
    "        \"times\": [],\n",
    "        \"answers\": [],\n",
    "        \"retrieved_docs\": [],\n",
    "        \"avg_time\": None\n",
    "    }\n",
    "    \n",
    "    total_time = 0\n",
    "    \n",
    "    for i, question in enumerate(test_questions, 1):\n",
    "        print(f\"\\nQ{i}: {question}\")\n",
    "        \n",
    "        # Retrieve documents FIRST (before LLM)\n",
    "        start_retrieve = time.perf_counter()\n",
    "        retrieved_docs = retriever.invoke(question)\n",
    "        retrieve_time = time.perf_counter() - start_retrieve\n",
    "        \n",
    "        # Show retrieved documents with FULL metadata\n",
    "        print(f\"\\nRETRIEVED DOCUMENTS ({len(retrieved_docs)}):\")\n",
    "        for j, doc in enumerate(retrieved_docs[:3], 1):  # Top 3 docs\n",
    "            print(f\"  [{j}] {Path(doc.metadata['source']).name}\")\n",
    "            print(f\"     Page: {doc.metadata['page']}\")\n",
    "            print(f\"     Preview: {doc.page_content[:150]}...\")\n",
    "            print()\n",
    "        \n",
    "        # Generate answer\n",
    "        start_answer = time.perf_counter()\n",
    "        answer = rag_chain.invoke(question)\n",
    "        answer_time = time.perf_counter() - start_answer\n",
    "        \n",
    "        total_time += (retrieve_time + answer_time)\n",
    "        model_results[\"times\"].append(retrieve_time + answer_time)\n",
    "        model_results[\"answers\"].append(answer)\n",
    "        model_results[\"retrieved_docs\"].append([\n",
    "            {\"filename\": Path(d.metadata['source']).name, \"page\": d.metadata['page'], \"preview\": d.page_content[:100]} \n",
    "            for d in retrieved_docs[:3]\n",
    "        ])\n",
    "        \n",
    "        print(f\"Retrieve: {retrieve_time:.3f}s | Answer: {answer_time:.3f}s | Total: {retrieve_time+answer_time:.3f}s\")\n",
    "        print(f\"Answer: {answer}\")\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    # Summary\n",
    "    avg_time = total_time / len(test_questions)\n",
    "    model_results[\"avg_time\"] = avg_time\n",
    "    print(f\"\\nSUMMARY {model_name}:\")\n",
    "    print(f\"Avg total time: {avg_time:.3f}s | Retrieve+Answer breakdown\")\n",
    "    \n",
    "    return model_results\n",
    "\n",
    "# Test Gemma3:1b with full transparency\n",
    "gemma_results = test_rag_with_sources(\"gemma3:1b\", gemma_llm, rag_chain_gemma_32k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72133609",
   "metadata": {},
   "source": [
    "### **Results**\n",
    "\n",
    "| Model | Avg Time | Model Last Update |\n",
    "|-------|----------|----------|\n",
    "| Gemma3:1b | 2.019s | 9 Months Ago |\n",
    "| Qwen2.5:1.5b | 1.735s | 1 Year Ago |\n",
    "| Llama2 | 12.5s | 56% | 1 Year Ago"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e0c099",
   "metadata": {},
   "source": [
    "## LangChain ColPali Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50aaa0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\The Leo Programmer\\Internships\\NRSC\\Assignments\\testing-models-huge-dataset\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Fetching 2 files: 100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.74it/s]\n",
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pdf2image import convert_from_path\n",
    "from colpali_engine.models import ColQwen2, ColQwen2Processor\n",
    "from chromadb import Client\n",
    "import numpy as np\n",
    "\n",
    "# Run on CPU (avoids offload issues)\n",
    "model = ColQwen2.from_pretrained(\n",
    "    \"vidore/colqwen2-v0.1\", \n",
    "    device_map=\"cpu\",\n",
    "    torch_dtype=torch.float32\n",
    ")\n",
    "processor = ColQwen2Processor.from_pretrained(\"vidore/colqwen2-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14176f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import PersistentClient\n",
    "\n",
    "# FIXED ChromaDB setup\n",
    "chroma_client = PersistentClient(path=\"./chroma_colpali_db\")\n",
    "collection = chroma_client.get_or_create_collection(\"kaggle_colpali_pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14c7cecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1076 Kaggle PDFs\n",
      "\n",
      "Batch 1/4\n",
      "Processing 08036c5a50a93da84c5c45ba468c58159d75281e.pdf\n",
      "  Page 1 OK\n",
      "  Page 2 OK\n",
      "Processing 0a29925ccc5e6299e132a73325956a3abef6dd26.pdf\n",
      "  Page 1 OK\n",
      "  Page 2 OK\n",
      "Processing 0e21835a42a6df2405496f62647058ff855743c1.pdf\n",
      "  Page 1 OK\n",
      "  Page 2 OK\n",
      "Processing 11613a97cef51ad28635fdd86915e74d94cff227.pdf\n",
      "  Page 1 OK\n",
      "  Page 2 OK\n",
      "Processing 12851f0053449570257ff3dfe552621a8dd63d53.pdf\n",
      "  Page 1 OK\n",
      "  Page 2 OK\n",
      "Batch complete: 10 pages indexed\n",
      "\n",
      "Batch 2/4\n",
      "Processing 17815074de3c9f8af9a5051978a72e2a83f1d18d.pdf\n",
      "  Page 1 OK\n",
      "  Page 2 OK\n",
      "Processing 183c0f6a2a452dabc05e8eeba962c7b49ad10a62.pdf\n",
      "  Page 1 OK\n",
      "  Page 2 OK\n",
      "Processing 1dcf57a5007b56254583423ba31107d22459bccf.pdf\n",
      "  Page 1 OK\n",
      "  Page 2 OK\n",
      "Processing 1e8c2332a461a3a142840fa477fa907c66c35dac.pdf\n",
      "  Page 1 OK\n",
      "  Page 2 OK\n",
      "Processing 201ab28823c4a10ca391e800642e9cf381737ed2.pdf\n",
      "  Page 1 OK\n",
      "  Page 2 OK\n",
      "Batch complete: 10 pages indexed\n",
      "\n",
      "Batch 3/4\n",
      "Processing 22ZOCVPAF2GSGXR357RM7UT4Z22RS2LH.pdf\n",
      "  Page 1 OK\n",
      "Processing 23JCEIKVL65X2RGSARNY2VOUNXBTJ5AS.pdf\n",
      "  Page 1 OK\n",
      "  Page 2 OK\n",
      "Processing 2544CYX3TC3T5QB2NTVXD3IUFM654GXK.pdf\n",
      "  Page 1 OK\n",
      "  Page 2 OK\n",
      "Processing 27UIROOYZ4IE3FKKNAPCKEQXWBKKN7XM.pdf\n",
      "  Page 1 OK\n",
      "Processing 281928eff64137efdd144a833c81ad0ee45284c1.pdf\n",
      "  Page 1 OK\n",
      "  Page 2 OK\n",
      "Batch complete: 8 pages indexed\n",
      "\n",
      "Batch 4/4\n",
      "Processing 2A2C2V4WI5YRDJHR26XUD4IAULIYGTMA.pdf\n",
      "  Page 1 OK\n",
      "  Page 2 OK\n",
      "Processing 2a85b52768ea5761b773be49b09d15f0b95415b0.pdf\n",
      "  Page 1 OK\n",
      "  Page 2 OK\n",
      "Processing 2c143c1675c174d0317c3a1f67b68b2b60047467.pdf\n",
      "  Page 1 OK\n",
      "  Page 2 OK\n",
      "Processing 2ED27NR7CISW7J4PHXXBZ6OFPVDFHMFB.pdf\n",
      "  Page 1 OK\n",
      "  Page 2 OK\n",
      "Processing 2EDEPZ4VHTLPTWSZR6FAVUJ3B2ZVSIPS.pdf\n",
      "  Page 1 OK\n",
      "Batch complete: 9 pages indexed\n",
      "Final: 37 pages in ChromaDB\n"
     ]
    }
   ],
   "source": [
    "from chromadb import PersistentClient\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "pdf_dir = Path(\"../data/pdf\")\n",
    "all_pdf_paths = list(pdf_dir.glob(\"*.pdf\"))\n",
    "print(f\"Found {len(all_pdf_paths)} Kaggle PDFs\")\n",
    "\n",
    "chroma_client = PersistentClient(path=\"./chroma_colpali_db\")\n",
    "collection = chroma_client.get_or_create_collection(\"visual_pages\")\n",
    "\n",
    "batch_size = 5\n",
    "for batch_start in range(0, len(all_pdf_paths[:20]), batch_size):\n",
    "    batch_paths = all_pdf_paths[batch_start:batch_start+batch_size]\n",
    "    batch_embeddings = []\n",
    "    batch_ids = []\n",
    "    batch_metadata = []\n",
    "    \n",
    "    print(f\"\\nBatch {batch_start//batch_size + 1}/4\")\n",
    "    \n",
    "    for pdf_path in batch_paths:\n",
    "        print(f\"Processing {pdf_path.name}\")\n",
    "        pages = convert_from_path(\n",
    "            str(pdf_path), \n",
    "            dpi=224,\n",
    "            poppler_path=r\"C:\\poppler\\poppler-25.12.0\\Library\\bin\"\n",
    "        )\n",
    "        \n",
    "        for i, page_img in enumerate(pages[:2]):\n",
    "            print(f\"  Page {i+1}\", end=\" \")\n",
    "            batch = processor.process_images([page_img]).to(\"cpu\")\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "                emb = outputs.mean(dim=1).cpu().numpy()[0]  # FIXED\n",
    "                batch_embeddings.append(emb.tolist())\n",
    "            \n",
    "            print(\"OK\")\n",
    "            batch_ids.append(f\"{pdf_path.stem}_p{i+1}\")\n",
    "            batch_metadata.append({\n",
    "                \"pdf\": pdf_path.name,\n",
    "                \"page\": i+1\n",
    "            })\n",
    "    \n",
    "    if batch_embeddings:\n",
    "        collection.add(embeddings=batch_embeddings, ids=batch_ids, metadatas=batch_metadata)\n",
    "        print(f\"Batch complete: {len(batch_embeddings)} pages indexed\")\n",
    "\n",
    "print(f\"Final: {collection.count()} pages in ChromaDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11944fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.5.1+cu121\n",
      "CUDA: True\n",
      "GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c41b5a",
   "metadata": {},
   "source": [
    "## Indexing the Pages as Images with GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c39247a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total VRAM: 6.4GB\n",
      "Used: 8.6GB\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(f\"Total VRAM: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB\")\n",
    "print(f\"Used: {torch.cuda.memory_allocated()/1e9:.1f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05594241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total VRAM: 6.4GB\n",
      "Used: 0.0GB\n",
      "GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Total VRAM: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB\")\n",
    "print(f\"Used: {torch.cuda.memory_allocated()/1e9:.1f}GB\")  # MUST be ~0.0GB\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd8fd5a",
   "metadata": {},
   "source": [
    "# Colpali Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "340a41b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Fetching 2 files: 100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.77s/it]\n",
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n"
     ]
    }
   ],
   "source": [
    "from colpali_engine.models import ColQwen2, ColQwen2Processor\n",
    "import torch\n",
    "\n",
    "# Load ColQwen2 for querying (same as indexing)\n",
    "model = ColQwen2.from_pretrained(\n",
    "    \"vidore/colqwen2-v0.1\",\n",
    "    device_map=\"cpu\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "processor = ColQwen2Processor.from_pretrained(\"vidore/colqwen2-v0.1\")\n",
    "\n",
    "# Create custom embedding function\n",
    "class ColQwen2Embeddings:\n",
    "    def embed_query(self, text):\n",
    "        # Convert text to image (or use text encoder)\n",
    "        inputs = processor.process_images([text_to_image(text)])  # Adjust\n",
    "        with torch.no_grad():\n",
    "            emb = model(**inputs).mean(dim=1).numpy()[0]\n",
    "        return emb.tolist()\n",
    "    \n",
    "    def embed_documents(self, texts):\n",
    "        return [self.embed_query(t) for t in texts]\n",
    "\n",
    "# Use with ChromaDB\n",
    "embeddings = ColQwen2Embeddings()\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=\"chroma_colqwen2_db\",\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"visual_pages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a8c20c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 2 files: 100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.29s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from colpali_engine.models import ColQwen2, ColQwen2Processor\n",
    "\n",
    "# Load model\n",
    "model = ColQwen2.from_pretrained(\n",
    "    \"vidore/colqwen2-v0.1\",\n",
    "    device_map=\"cpu\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "processor = ColQwen2Processor.from_pretrained(\"vidore/colqwen2-v0.1\")\n",
    "\n",
    "class ColQwen2Embeddings:\n",
    "    def embed_query(self, text):\n",
    "        \"\"\"Embed text query using ColQwen2's text encoder\"\"\"\n",
    "        # Use processor to encode text (not images)\n",
    "        inputs = processor.process_queries([text]).to('cpu')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            emb = model(**inputs).mean(dim=1).cpu().numpy()[0]\n",
    "        \n",
    "        return emb.tolist()\n",
    "    \n",
    "    def embed_documents(self, texts):\n",
    "        return [self.embed_query(t) for t in texts]\n",
    "\n",
    "# Use with ChromaDB\n",
    "embeddings = ColQwen2Embeddings()\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=\"chroma_colqwen2_db\",\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"visual_pages\"\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0352209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RAG with document-specific questions: Qwen 32K context limit model\n"
     ]
    }
   ],
   "source": [
    "# context_32k_limit_prompt - Enhanced for 32K context window\n",
    "\n",
    "# Qwen model for answering\n",
    "qwen_llm = OllamaLLM(model=\"qwen2.5:1.5b\")\n",
    "\n",
    "context_32k_limit_prompt = \"\"\"\n",
    "You are an expert research assistant analyzing a comprehensive dataset of multiple PDF documents.\n",
    "\n",
    "IMPORTANT INSTRUCTIONS:\n",
    "1. Answer using ONLY the provided context below - NO external knowledge or training data\n",
    "2. This dataset contains diverse technical, scientific, and professional PDF documents\n",
    "3. Cite sources inline with [1], [2], etc. after each relevant sentence/paragraph\n",
    "4. At the end, list ONLY the source filenames used (no full paths)\n",
    "\n",
    "EXTENDED CONTEXT (from multiple PDF documents):\n",
    "{context}\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "ANSWERING RULES:\n",
    "- Use [1], [2], etc. immediately after sentences referencing specific chunks\n",
    "- Extract precise numbers, dates, names, percentages from context only\n",
    "- Provide comprehensive answers using all relevant context available\n",
    "- If information not found: \"Not found in provided documents\"\n",
    "- Maintain factual accuracy - quote directly when possible\n",
    "\n",
    "REQUIRED OUTPUT FORMAT:\n",
    "\n",
    "Answer your question using ONLY the context above. Be thorough but concise.\n",
    "\n",
    "Sources used:\n",
    "[1] filename1.pdf\n",
    "[2] filename2.pdf\n",
    "[3] filename3.pdf\n",
    "etc.\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "# RAG chain for 32K model\n",
    "rag_chain_32k = (\n",
    "    {\"context\": retriever | format_docs, \"question\": lambda x: x}\n",
    "    | ChatPromptTemplate.from_template(context_32k_limit_prompt)\n",
    "    | qwen_llm  # Your 32K model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(\"Testing RAG with document-specific questions: Qwen 32K context limit model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6577c265",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions = [\n",
    "    '''\n",
    "        BOSTON - APPLES \n",
    "        RED DELICIOUS \n",
    "        cartons cell pack \n",
    "        U.S. Fcy\n",
    "    what is this mean?\n",
    "    ''',\n",
    "    \"How does the Medicare-Approved Drug Discount Card program help people with Medicare save on prescription drug costs, and what key steps should be followed to compare and enroll in the most suitable card?\",\n",
    "    \"What is the recommended dosage, route of administration, and indication for NAXCEL Sterile Powder in cattle?\",\n",
    "    \"What is the established pre-slaughter withdrawal period for NAXCEL Sterile Powder in cattle, and what are the safe residue concentrations for human food safety?\",\n",
    "    \"(***). Who is the filing officer responsible for the Statement of Economic Interests Form 700 Non-Filer Enforcement Referral, and which agency do they represent?\",\n",
    "    \"Based only on the figure legends in Figures 1–4, which colors or visual markers correspond to GHO countries and which correspond to HRP countries?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f238c19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RAG performance (qwen2.5:1.5b 32K context limit)...\n",
      "\n",
      "Q1: \n",
      "        BOSTON - APPLES \n",
      "        RED DELICIOUS \n",
      "        cartons cell pack \n",
      "        U.S. Fcy\n",
      "    what is this mean?\n",
      "    \n",
      "Time: 69.372s\n",
      "Answer: In the provided context, there is no clear definition or explanation of what \"BOSTON - APPLES - RED DELICIOUS - cartons cell pack U. S. Fcy\" means. The sentence appears to be a list without additional information that would clarify its meaning or significance.\n",
      "\n",
      "Sources used:\n",
      "[1] filename1.pdf\n",
      "[2] filename2.pdf\n",
      "[3] filename3.pdf\n",
      "\n",
      "Note: The source filenames provided in the instruction did not match any of the PDF documents mentioned, so no actual sources were cited.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Q2: How does the Medicare-Approved Drug Discount Card program help people with Medicare save on prescription drug costs, and what key steps should be followed to compare and enroll in the most suitable card?\n",
      "Time: 65.097s\n",
      "Answer: The Medicare-Approved Drug Discount Card program helps people with Medicare save on prescription drug costs by providing them with a card that allows them to receive discounts at retail pharmacies, which typically results in lower out-of-pocket expenses. To compare and enroll in the most suitable card, one should follow these key steps:\n",
      "\n",
      "1. **Identify Needs**: Understand your healthcare needs and the specific medications you require. Consider factors such as cost, availability, and insurance coverage.\n",
      "\n",
      "2. **Research Programs**: Look for programs approved by Medicare that offer discounts on prescription drugs. These include cards like the Medicare Part D Savings Card or other private pharmacy discount programs.\n",
      "\n",
      "3. **Compare Cards**: Compare different cards to see which one offers the best combination of savings (e.g., maximum dollar amount, percentage off), benefits, and coverage options.\n",
      "\n",
      "4. **Enroll Early**: Start enrolling in a card early in the year when many people are signing up for Medicare and other healthcare plans. This can help you get an earlier start on maximizing your discount benefits.\n",
      "\n",
      "5. **Monitor Renewal Periods**: Keep track of renewal periods to ensure you do not miss any opportunities to enroll in new cards that may be available.\n",
      "\n",
      "6. **Enroll with Ease**: Follow the enrollment process for each card carefully, which often involves downloading a prescription verification form and mailing it back along with necessary documentation such as your Medicare ID number and health insurance information.\n",
      "\n",
      "7. **Verify Benefits**: Once enrolled, verify if you are receiving discounts at pharmacies where you typically purchase medication. Keep receipts to ensure your spending is recorded accurately and can be used for potential reimbursement.\n",
      "\n",
      "Key steps to compare and enroll in the most suitable card:\n",
      "\n",
      "- [1] Medicare.gov (source)\n",
      "- [2] \"Medicare Prescription Drug Discount Cards: A Guide\" by Medicare\n",
      "- [3] \"Understanding Your Options: Choosing a Medicare Prescription Drug Plan\" by CMS\n",
      "\n",
      "Not found in provided documents\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Q3: What is the recommended dosage, route of administration, and indication for NAXCEL Sterile Powder in cattle?\n",
      "Time: 38.619s\n",
      "Answer: Not found in provided documents.\n",
      "\n",
      "**Explanation:** The dataset does not contain specific information about the recommended dosage, route of administration, and indications for NAXCEL Sterile Powder in cattle. This question would require direct access to pharmaceutical literature or a more extensive medical database that is not available in this context.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Q4: What is the established pre-slaughter withdrawal period for NAXCEL Sterile Powder in cattle, and what are the safe residue concentrations for human food safety?\n",
      "Time: 59.383s\n",
      "Answer: Not found in provided documents.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Q5: (***). Who is the filing officer responsible for the Statement of Economic Interests Form 700 Non-Filer Enforcement Referral, and which agency do they represent?\n",
      "Time: 65.871s\n",
      "Answer: To answer this specific question, we need to delve into a complex network of filing information across multiple documents, which requires detailed investigation and analysis. The Statement of Economic Interests Form 700 Non-Filer Enforcement Referral pertains to an individual's obligations under the Foreign Agents Regulations Act (FARA) or equivalent laws in different countries. This form is designed for individuals with substantial economic interests who may need to declare their activities.\n",
      "\n",
      "For such a detailed query, we would typically expect a specific filing officer assigned based on the context of this particular document, but without direct citation from that file, it's challenging to pinpoint an exact answer. The enforcement referral suggests there has been an issue or violation noted with this individual, and they have fallen under non-filer scrutiny.\n",
      "\n",
      "Given the complexity and breadth of data involved, we would need to examine a significant number of files to trace back to specific records or individuals responsible for such referrals. This process would likely involve examining personnel assignments within agencies that handle FARA compliance or equivalent regulations on economic interests disclosures in foreign affairs.\n",
      "\n",
      "Therefore, based on this information alone, it is difficult to definitively name an exact filing officer or identify the agency represented without additional direct references from documents within the dataset. The context provided does not contain sufficient information to answer the specific question about a particular individual's filing officer or their affiliated agency.\n",
      "\n",
      "Sources used:\n",
      "[1] filename1.pdf\n",
      "[2] filename2.pdf\n",
      "[3] filename3.pdf\n",
      "etc.\n",
      "\n",
      "Please note that this response is based on hypothetical information derived from general PDF document analysis practices, rather than actual direct references to the specified documents.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Q6: Based only on the figure legends in Figures 1–4, which colors or visual markers correspond to GHO countries and which correspond to HRP countries?\n",
      "Time: 53.296s\n",
      "Answer: Not found in provided documents.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "---> SUMMARY (qwen2.5:1.5b 3K):\n",
      "Average response time: 58.607 seconds\n",
      "Total time for 6 questions: 351.639 seconds\n",
      "Individual times: ['69.372s', '65.097s', '38.619s', '59.383s', '65.871s', '53.296s']\n",
      "\n",
      "Results saved to model_results dictionary\n",
      "Ready for 32K model comparison...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Dictionary to store results for model comparison\n",
    "model_results = {\n",
    "    \"model\": \"qwen2.5:1.5b\",\n",
    "    \"test_questions\": test_questions.copy(),\n",
    "    \"times\": [],\n",
    "    \"answers\": [],\n",
    "    \"avg_time\": None\n",
    "}\n",
    "\n",
    "print(\"Testing RAG performance (qwen2.5:1.5b 32K context limit)...\")\n",
    "total_time = 0\n",
    "\n",
    "for i, q in enumerate(test_questions, 1):\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    answer = rag_chain_32k.invoke(q)\n",
    "    \n",
    "    end_time = time.perf_counter()\n",
    "    question_time = end_time - start_time\n",
    "    \n",
    "    total_time += question_time\n",
    "    \n",
    "    model_results[\"times\"].append(question_time)\n",
    "    model_results[\"answers\"].append(answer)\n",
    "    \n",
    "    print(f\"\\nQ{i}: {q}\")\n",
    "    print(f\"Time: {question_time:.3f}s\")\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "# Calculate average\n",
    "avg_time = total_time / len(test_questions)\n",
    "model_results[\"avg_time\"] = avg_time\n",
    "\n",
    "print(f\"\\n---> SUMMARY (qwen2.5:1.5b 3K):\")\n",
    "print(f\"Average response time: {avg_time:.3f} seconds\")\n",
    "print(f\"Total time for {len(test_questions)} questions: {total_time:.3f} seconds\")\n",
    "print(f\"Individual times: {[f'{t:.3f}s' for t in model_results['times']]}\")\n",
    "\n",
    "# Save for later model comparison\n",
    "print(f\"\\nResults saved to model_results dictionary\")\n",
    "print(f\"Ready for 32K model comparison...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657c8c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
